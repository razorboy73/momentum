{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f90f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading equity curve ===\n",
      "Loaded 6789 return observations.\n",
      "\n",
      "=== TRUE STRATEGY RESULTS ===\n",
      "CAGR: 0.15575292794223938\n",
      "Sharpe: 1.221383001257762\n",
      "MaxDD: -0.19626913543183888\n",
      "\n",
      "=== Running Monte Carlo simulations ===\n",
      "\n",
      "=== SHARPE ESTIMATION UNCERTAINTY (bootstrap CI) ===\n",
      "Sharpe 95% CI (2.5/50/97.5): 0.841, 1.224, 1.610\n",
      "\n",
      "=== SHARPE SIGNIFICANCE (block-bootstrap null) ===\n",
      "Observed Sharpe: 1.2214\n",
      "p-value (H0: true Sharpe = 0, H1: Sharpe > 0): 0.0000\n",
      "p-value (H0: true Sharpe = 1.0, H1: Sharpe > 1.0): 0.1264\n",
      "\n",
      "=== MONTE CARLO STATISTICS ===\n",
      "CAGR_mean: 0.1561\n",
      "CAGR_median: 0.1557\n",
      "CAGR_5pct: 0.1110\n",
      "CAGR_95pct: 0.2036\n",
      "Sharpe_mean: 1.2227\n",
      "Sharpe_5pct: 0.9005\n",
      "Sharpe_95pct: 1.5432\n",
      "DD_mean: -0.2239\n",
      "DD_5pct: -0.3138\n",
      "DD_95pct: -0.1587\n",
      "Prob_MaxDD_ge_50pct: 0.0001\n",
      "Prob_CAGR_lt_0: 0.0000\n",
      "Prob_Sharpe_lt_1: 0.1280\n",
      "Prob_Sharpe_lt_0: 0.0000\n",
      "\n",
      "Percentile of True CAGR: 0.5009\n",
      "Percentile of True Sharpe: 0.497\n",
      "\n",
      "=== DOLLAR DRAWDOWN ANALYSIS ===\n",
      "\n",
      "Median max $ drawdown: $2,102,469\n",
      "95th pct max $ drawdown: $6,528,527\n",
      "Worst case max $ drawdown: $47,488,569\n",
      "\n",
      "Median DD vs start: 609.4%\n",
      "95th pct DD vs start: 1892.3%\n",
      "\n",
      "Prob(≥40% DD after +60% growth): 0.002\n",
      "\n",
      "=== WORST MONTE CARLO DRAWDOWN PATH ===\n",
      "\n",
      "Peak Equity:   $247,553,982\n",
      "Peak Step:     6522  (indexed date anchor: 2024-12-04)\n",
      "Trough Equity: $200,065,413\n",
      "Trough Step:   6610 (indexed date anchor: 2025-04-14)\n",
      "Max $ Drawdown: $47,488,569\n",
      "\n",
      "=== MEDIAN MONTE CARLO DRAWDOWN PATH ===\n",
      "\n",
      "Peak Equity:   $11,151,235\n",
      "Peak Step:     5959  (indexed date anchor: 2022-09-08)\n",
      "Trough Equity: $9,048,711\n",
      "Trough Step:   6004 (indexed date anchor: 2022-11-10)\n",
      "Max $ Drawdown: $2,102,524\n",
      "\n",
      "Saved Monte Carlo results → ./16-monte_carlo_output\\16-mc_results_20251231-120104.csv\n",
      "\n",
      "All plots saved.\n",
      "\n",
      "=== COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "STRAT_EQUITY_FILE = \"./13-trading_output_regression_insp500_spyfilter_cap15/13-equity_curve_regression_insp500_spyfilter_cap15.parquet\"\n",
    "OUT_DIR = \"./16-monte_carlo_output\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "N_SIMS = 10000\n",
    "BLOCK_SIZE = 25 # block bootstrap length\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ============================================================\n",
    "# METRIC FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def cagr_from_path(values, start_date, end_date):\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    if len(values) < 2:\n",
    "        return np.nan\n",
    "    years = (pd.Timestamp(end_date) - pd.Timestamp(start_date)).days / 365.25\n",
    "    if years <= 0:\n",
    "        return np.nan\n",
    "    if values[0] <= 0:\n",
    "        return np.nan\n",
    "    return (values[-1] / values[0]) ** (1 / years) - 1\n",
    "\n",
    "def sharpe(returns):\n",
    "    r = np.asarray(returns, dtype=float)\n",
    "    std = np.std(r, ddof=1)\n",
    "    if std == 0 or np.isnan(std):\n",
    "        return np.nan\n",
    "    return np.sqrt(252) * np.mean(r) / std\n",
    "\n",
    "def max_drawdown(values):\n",
    "    arr = np.asarray(values, dtype=float)\n",
    "    peaks = np.maximum.accumulate(arr)\n",
    "    dd = arr / peaks - 1\n",
    "    return float(dd.min())\n",
    "\n",
    "def prob_maxdd_ge_threshold(values, threshold=0.5):\n",
    "    return max_drawdown(values) <= -threshold\n",
    "\n",
    "# ============================================================\n",
    "# BLOCK BOOTSTRAP\n",
    "# ============================================================\n",
    "\n",
    "def block_bootstrap(returns, n, block_size):\n",
    "    r = np.asarray(returns, dtype=float)\n",
    "    L = len(r)\n",
    "    if L <= 0 or n <= 0:\n",
    "        return np.array([], dtype=float)\n",
    "    if block_size <= 0:\n",
    "        raise ValueError(\"BLOCK_SIZE must be > 0\")\n",
    "    if block_size > L:\n",
    "        raise ValueError(f\"BLOCK_SIZE ({block_size}) cannot exceed number of returns ({L})\")\n",
    "\n",
    "    out = []\n",
    "    while len(out) < n:\n",
    "        i = np.random.randint(0, L - block_size + 1)\n",
    "        out.extend(r[i:i + block_size])\n",
    "    return np.array(out[:n], dtype=float)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== Loading equity curve ===\")\n",
    "\n",
    "equity = pd.read_parquet(STRAT_EQUITY_FILE)\n",
    "equity[\"date\"] = pd.to_datetime(equity[\"date\"])\n",
    "equity[\"portfolio_value\"] = pd.to_numeric(equity[\"portfolio_value\"], errors=\"coerce\")\n",
    "equity = equity.dropna(subset=[\"date\", \"portfolio_value\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "equity = equity[equity[\"portfolio_value\"] > 0].reset_index(drop=True)\n",
    "\n",
    "if len(equity) < 3:\n",
    "    raise ValueError(\"Not enough equity observations after cleaning (need at least 3 rows).\")\n",
    "\n",
    "values = equity[\"portfolio_value\"].values  # length N\n",
    "dates = equity[\"date\"].values              # length N\n",
    "\n",
    "# returns are N-1\n",
    "rets = (values[1:] / values[:-1]) - 1.0\n",
    "n_rets = len(rets)\n",
    "\n",
    "start_date = equity[\"date\"].iloc[0]\n",
    "end_date   = equity[\"date\"].iloc[-1]\n",
    "initial_capital = float(values[0])\n",
    "\n",
    "print(f\"Loaded {n_rets} return observations.\")\n",
    "\n",
    "# ============================================================\n",
    "# TRUE METRICS\n",
    "# ============================================================\n",
    "\n",
    "true_equity = values\n",
    "true_cagr = cagr_from_path(true_equity, start_date, end_date)\n",
    "true_sharpe = sharpe(rets)\n",
    "true_dd = max_drawdown(true_equity)\n",
    "\n",
    "print(\"\\n=== TRUE STRATEGY RESULTS ===\")\n",
    "print(\"CAGR:\", true_cagr)\n",
    "print(\"Sharpe:\", true_sharpe)\n",
    "print(\"MaxDD:\", true_dd)\n",
    "\n",
    "# ============================================================\n",
    "# MONTE CARLO SIMULATION (UNCERTAINTY BOOTSTRAP)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Running Monte Carlo simulations ===\")\n",
    "\n",
    "sim_cagrs = np.zeros(N_SIMS, dtype=float)\n",
    "sim_sharpes = np.zeros(N_SIMS, dtype=float)\n",
    "sim_dds = np.zeros(N_SIMS, dtype=float)\n",
    "sim_dd50 = np.zeros(N_SIMS, dtype=float)\n",
    "\n",
    "sim_max_dd_dollars = np.zeros(N_SIMS, dtype=float)\n",
    "sim_peak_equity = np.zeros(N_SIMS, dtype=float)\n",
    "sim_trough_equity = np.zeros(N_SIMS, dtype=float)\n",
    "\n",
    "sim_peak_step = np.zeros(N_SIMS, dtype=int)\n",
    "sim_trough_step = np.zeros(N_SIMS, dtype=int)\n",
    "sim_peak_date_indexed = np.empty(N_SIMS, dtype=\"datetime64[ns]\")\n",
    "sim_trough_date_indexed = np.empty(N_SIMS, dtype=\"datetime64[ns]\")\n",
    "\n",
    "for i in range(N_SIMS):\n",
    "    sim_rets = block_bootstrap(rets, n_rets, BLOCK_SIZE)\n",
    "\n",
    "    sim_curve = np.cumprod(np.r_[1.0, 1.0 + sim_rets])      # normalized\n",
    "    sim_curve_dollars = sim_curve * initial_capital         # dollars\n",
    "\n",
    "    running_peak = np.maximum.accumulate(sim_curve_dollars)\n",
    "    drawdowns = running_peak - sim_curve_dollars\n",
    "\n",
    "    dd_idx = int(np.argmax(drawdowns))  # trough index\n",
    "    peak_idx = int(np.argmax(sim_curve_dollars[:dd_idx + 1])) if dd_idx >= 0 else 0\n",
    "\n",
    "    sim_peak_equity[i] = sim_curve_dollars[peak_idx]\n",
    "    sim_trough_equity[i] = sim_curve_dollars[dd_idx]\n",
    "    sim_max_dd_dollars[i] = drawdowns[dd_idx]\n",
    "\n",
    "    sim_peak_step[i] = peak_idx\n",
    "    sim_trough_step[i] = dd_idx\n",
    "    sim_peak_date_indexed[i] = dates[peak_idx]\n",
    "    sim_trough_date_indexed[i] = dates[dd_idx]\n",
    "\n",
    "    sim_cagrs[i]   = cagr_from_path(sim_curve_dollars, start_date, end_date)\n",
    "    sim_sharpes[i] = sharpe(sim_rets)\n",
    "    sim_dds[i]     = max_drawdown(sim_curve)\n",
    "    sim_dd50[i]    = prob_maxdd_ge_threshold(sim_curve, threshold=0.50)\n",
    "\n",
    "# ============================================================\n",
    "# SHARPE CONFIDENCE INTERVAL (ESTIMATION UNCERTAINTY)\n",
    "# ============================================================\n",
    "\n",
    "sharpe_ci_95 = np.percentile(sim_sharpes[~np.isnan(sim_sharpes)], [2.5, 50, 97.5])\n",
    "\n",
    "print(\"\\n=== SHARPE ESTIMATION UNCERTAINTY (bootstrap CI) ===\")\n",
    "print(f\"Sharpe 95% CI (2.5/50/97.5): {sharpe_ci_95[0]:.3f}, {sharpe_ci_95[1]:.3f}, {sharpe_ci_95[2]:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# SHARPE SIGNIFICANCE TEST (NULL: NO EDGE)\n",
    "#   Build a null by forcing mean=0, then block bootstrap.\n",
    "#   p-value = P(Sharpe_null >= Sharpe_observed)\n",
    "# ============================================================\n",
    "\n",
    "rets_centered = rets - np.mean(rets)  # remove estimated edge\n",
    "\n",
    "sim_sharpes_null0 = np.zeros(N_SIMS, dtype=float)\n",
    "for i in range(N_SIMS):\n",
    "    sim_rets0 = block_bootstrap(rets_centered, n_rets, BLOCK_SIZE)\n",
    "    sim_sharpes_null0[i] = sharpe(sim_rets0)\n",
    "\n",
    "p_sharpe_gt_0 = np.mean(sim_sharpes_null0 >= true_sharpe)  # one-sided\n",
    "\n",
    "print(\"\\n=== SHARPE SIGNIFICANCE (block-bootstrap null) ===\")\n",
    "print(f\"Observed Sharpe: {true_sharpe:.4f}\")\n",
    "print(f\"p-value (H0: true Sharpe = 0, H1: Sharpe > 0): {p_sharpe_gt_0:.4f}\")\n",
    "\n",
    "# Optional: test Sharpe > 1.0 by shifting returns so null Sharpe is ~1.0\n",
    "# (This uses the *observed* volatility as a plug-in, which is an approximation.)\n",
    "target_sharpe = 1.0\n",
    "obs_vol = np.std(rets, ddof=1)\n",
    "mu_target = (target_sharpe / np.sqrt(252)) * obs_vol  # daily mean that implies target Sharpe\n",
    "rets_shifted_to_sh1 = rets - np.mean(rets) + mu_target\n",
    "\n",
    "sim_sharpes_null1 = np.zeros(N_SIMS, dtype=float)\n",
    "for i in range(N_SIMS):\n",
    "    sim_rets1 = block_bootstrap(rets_shifted_to_sh1, n_rets, BLOCK_SIZE)\n",
    "    sim_sharpes_null1[i] = sharpe(sim_rets1)\n",
    "\n",
    "p_sharpe_gt_1 = np.mean(sim_sharpes_null1 >= true_sharpe)\n",
    "\n",
    "print(f\"p-value (H0: true Sharpe = {target_sharpe:.1f}, H1: Sharpe > {target_sharpe:.1f}): {p_sharpe_gt_1:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY STATS (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "stats = {\n",
    "    \"CAGR_mean\": np.mean(sim_cagrs),\n",
    "    \"CAGR_median\": np.median(sim_cagrs),\n",
    "    \"CAGR_5pct\": np.percentile(sim_cagrs, 5),\n",
    "    \"CAGR_95pct\": np.percentile(sim_cagrs, 95),\n",
    "\n",
    "    \"Sharpe_mean\": np.mean(sim_sharpes),\n",
    "    \"Sharpe_5pct\": np.percentile(sim_sharpes, 5),\n",
    "    \"Sharpe_95pct\": np.percentile(sim_sharpes, 95),\n",
    "\n",
    "    \"DD_mean\": np.mean(sim_dds),\n",
    "    \"DD_5pct\": np.percentile(sim_dds, 5),\n",
    "    \"DD_95pct\": np.percentile(sim_dds, 95),\n",
    "\n",
    "    \"Prob_MaxDD_ge_50pct\": sim_dd50.mean(),\n",
    "    \"Prob_CAGR_lt_0\": (sim_cagrs < 0).mean(),\n",
    "    \"Prob_Sharpe_lt_1\": (sim_sharpes < 1).mean(),\n",
    "    \"Prob_Sharpe_lt_0\": (sim_sharpes < 0).mean(),\n",
    "}\n",
    "\n",
    "print(\"\\n=== MONTE CARLO STATISTICS ===\")\n",
    "for k, v in stats.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nPercentile of True CAGR:\", (sim_cagrs <= true_cagr).mean())\n",
    "print(\"Percentile of True Sharpe:\", (sim_sharpes <= true_sharpe).mean())\n",
    "\n",
    "print(\"\\n=== DOLLAR DRAWDOWN ANALYSIS ===\\n\")\n",
    "print(f\"Median max $ drawdown: ${np.median(sim_max_dd_dollars):,.0f}\")\n",
    "print(f\"95th pct max $ drawdown: ${np.percentile(sim_max_dd_dollars, 95):,.0f}\")\n",
    "print(f\"Worst case max $ drawdown: ${sim_max_dd_dollars.max():,.0f}\")\n",
    "\n",
    "dd_vs_start = sim_max_dd_dollars / initial_capital\n",
    "print(f\"\\nMedian DD vs start: {np.median(dd_vs_start)*100:.1f}%\")\n",
    "print(f\"95th pct DD vs start: {np.percentile(dd_vs_start,95)*100:.1f}%\")\n",
    "\n",
    "late_bad_dd = [\n",
    "    sim_max_dd_dollars[i]\n",
    "    for i in range(N_SIMS)\n",
    "    if sim_peak_equity[i] >= 1.6 * initial_capital\n",
    "    and sim_max_dd_dollars[i] >= 0.4 * sim_peak_equity[i]\n",
    "]\n",
    "print(f\"\\nProb(≥40% DD after +60% growth): {len(late_bad_dd)/N_SIMS:.3f}\")\n",
    "\n",
    "worst_idx = int(np.argmax(sim_max_dd_dollars))\n",
    "print(\"\\n=== WORST MONTE CARLO DRAWDOWN PATH ===\\n\")\n",
    "print(f\"Peak Equity:   ${sim_peak_equity[worst_idx]:,.0f}\")\n",
    "print(f\"Peak Step:     {sim_peak_step[worst_idx]}  (indexed date anchor: {pd.Timestamp(sim_peak_date_indexed[worst_idx]).date()})\")\n",
    "print(f\"Trough Equity: ${sim_trough_equity[worst_idx]:,.0f}\")\n",
    "print(f\"Trough Step:   {sim_trough_step[worst_idx]} (indexed date anchor: {pd.Timestamp(sim_trough_date_indexed[worst_idx]).date()})\")\n",
    "print(f\"Max $ Drawdown: ${sim_max_dd_dollars[worst_idx]:,.0f}\")\n",
    "\n",
    "median_idx = int(np.argsort(sim_max_dd_dollars)[N_SIMS // 2])\n",
    "print(\"\\n=== MEDIAN MONTE CARLO DRAWDOWN PATH ===\\n\")\n",
    "print(f\"Peak Equity:   ${sim_peak_equity[median_idx]:,.0f}\")\n",
    "print(f\"Peak Step:     {sim_peak_step[median_idx]}  (indexed date anchor: {pd.Timestamp(sim_peak_date_indexed[median_idx]).date()})\")\n",
    "print(f\"Trough Equity: ${sim_trough_equity[median_idx]:,.0f}\")\n",
    "print(f\"Trough Step:   {sim_trough_step[median_idx]} (indexed date anchor: {pd.Timestamp(sim_trough_date_indexed[median_idx]).date()})\")\n",
    "print(f\"Max $ Drawdown: ${sim_max_dd_dollars[median_idx]:,.0f}\")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE CSV\n",
    "# ============================================================\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"sim_cagr\": sim_cagrs,\n",
    "    \"sim_sharpe\": sim_sharpes,\n",
    "    \"sim_maxdd\": sim_dds,\n",
    "    \"prob_maxdd_ge_50pct\": sim_dd50,\n",
    "    \"sim_sharpe_null_mean0\": sim_sharpes_null0,\n",
    "    \"sim_sharpe_null_target1\": sim_sharpes_null1,\n",
    "})\n",
    "\n",
    "out_csv = os.path.join(OUT_DIR, f\"16-mc_results_{timestamp}.csv\")\n",
    "results.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"\\nSaved Monte Carlo results → {out_csv}\")\n",
    "\n",
    "# ============================================================\n",
    "# PLOTS\n",
    "# ============================================================\n",
    "\n",
    "def save_hist(data, title, filename, true_value=None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(data, bins=60, alpha=0.7)\n",
    "    if true_value is not None:\n",
    "        plt.axvline(true_value, color=\"red\", linewidth=2, label=\"Actual\")\n",
    "        plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, filename))\n",
    "    plt.close()\n",
    "\n",
    "save_hist(sim_cagrs, \"CAGR Distribution\", f\"mc_cagr_{timestamp}.png\", true_cagr)\n",
    "save_hist(sim_sharpes, \"Sharpe Distribution\", f\"mc_sharpe_{timestamp}.png\", true_sharpe)\n",
    "save_hist(sim_dds, \"Max Drawdown Distribution\", f\"mc_dd_{timestamp}.png\", true_dd)\n",
    "save_hist(sim_sharpes_null0, \"Sharpe Null (mean=0) Distribution\", f\"mc_sharpe_null_mean0_{timestamp}.png\", true_sharpe)\n",
    "\n",
    "print(\"\\nAll plots saved.\")\n",
    "print(\"\\n=== COMPLETE ===\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8724aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed beta: 0.323\n",
      "Observed alpha (daily): 0.000478  | annualized: 0.1206\n",
      "\n",
      "=== ALPHA UNCERTAINTY (paired block bootstrap) ===\n",
      "Alpha daily 95% CI: 0.000298, 0.000470, 0.000651\n",
      "Alpha annualized 95% CI: 0.0750, 0.1185, 0.1641\n",
      "\n",
      "=== ALPHA SIGNIFICANCE ===\n",
      "p-value (H0: alpha=0, H1: alpha>0): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "\n",
    "def ols_alpha_beta(y, x):\n",
    "    \"\"\"y = alpha + beta*x + eps\"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "    X = np.column_stack([np.ones(len(x)), x])\n",
    "    # OLS: (X'X)^-1 X'y\n",
    "    b = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    alpha, beta = b[0], b[1]\n",
    "    return alpha, beta\n",
    "\n",
    "def block_bootstrap_pairs(strat_ret, spy_ret, block_size, n_sims=10000, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    strat_ret = np.asarray(strat_ret, float)\n",
    "    spy_ret   = np.asarray(spy_ret, float)\n",
    "    n = len(strat_ret)\n",
    "    assert len(spy_ret) == n\n",
    "    if block_size > n:\n",
    "        raise ValueError(\"block_size > number of observations\")\n",
    "\n",
    "    alphas = np.empty(n_sims, float)\n",
    "    betas  = np.empty(n_sims, float)\n",
    "\n",
    "    for i in range(n_sims):\n",
    "        idx = []\n",
    "        while len(idx) < n:\n",
    "            start = rng.integers(0, n - block_size + 1)\n",
    "            idx.extend(range(start, start + block_size))\n",
    "        idx = np.array(idx[:n])\n",
    "\n",
    "        y = strat_ret[idx]\n",
    "        x = spy_ret[idx]\n",
    "        a, b = ols_alpha_beta(y, x)\n",
    "        alphas[i] = a\n",
    "        betas[i]  = b\n",
    "\n",
    "    return alphas, betas\n",
    "\n",
    "# --- Load your data (edit paths) ---\n",
    "EQUITY_FILE = \"./13-trading_output_regression_insp500_spyfilter_cap15/13-equity_curve_regression_insp500_spyfilter_cap15.parquet\"\n",
    "SPY_FILE    = r\"C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\8-SPY_200DMA_market_regime\\8-SPY_200DMA_regime.parquet\"\n",
    "\n",
    "eq = pd.read_parquet(EQUITY_FILE).copy()\n",
    "eq[\"date\"] = pd.to_datetime(eq[\"date\"])\n",
    "eq = eq.sort_values(\"date\")\n",
    "eq[\"strat_ret\"] = eq[\"portfolio_value\"].pct_change()\n",
    "eq = eq.dropna(subset=[\"strat_ret\"])\n",
    "\n",
    "spy = pd.read_parquet(SPY_FILE).copy()\n",
    "spy = spy.reset_index().rename(columns={\"Date\":\"date\", \"index\":\"date\"}) if \"date\" not in spy.columns else spy\n",
    "spy[\"date\"] = pd.to_datetime(spy[\"date\"])\n",
    "spy = spy.sort_values(\"date\")\n",
    "spy[\"spy_ret\"] = spy[\"spy_close\"].pct_change()\n",
    "\n",
    "df = eq.merge(spy[[\"date\",\"spy_ret\"]], on=\"date\", how=\"inner\").dropna()\n",
    "strat_ret = df[\"strat_ret\"].to_numpy()\n",
    "spy_ret   = df[\"spy_ret\"].to_numpy()\n",
    "\n",
    "# --- Observed alpha/beta ---\n",
    "alpha_d, beta = ols_alpha_beta(strat_ret, spy_ret)\n",
    "alpha_ann = alpha_d * TRADING_DAYS\n",
    "print(f\"Observed beta: {beta:.3f}\")\n",
    "print(f\"Observed alpha (daily): {alpha_d:.6f}  | annualized: {alpha_ann:.4f}\")\n",
    "\n",
    "# --- Bootstrap uncertainty + significance ---\n",
    "BLOCK_SIZE = 60\n",
    "N_SIMS = 10000\n",
    "alphas, betas = block_bootstrap_pairs(strat_ret, spy_ret, BLOCK_SIZE, N_SIMS)\n",
    "\n",
    "alpha_ci = np.percentile(alphas, [2.5, 50, 97.5])\n",
    "print(\"\\n=== ALPHA UNCERTAINTY (paired block bootstrap) ===\")\n",
    "print(f\"Alpha daily 95% CI: {alpha_ci[0]:.6f}, {alpha_ci[1]:.6f}, {alpha_ci[2]:.6f}\")\n",
    "print(f\"Alpha annualized 95% CI: {(alpha_ci*TRADING_DAYS)[0]:.4f}, {(alpha_ci*TRADING_DAYS)[1]:.4f}, {(alpha_ci*TRADING_DAYS)[2]:.4f}\")\n",
    "\n",
    "# one-sided p-value for alpha > 0\n",
    "p_alpha_gt0 = (alphas <= 0).mean()\n",
    "print(\"\\n=== ALPHA SIGNIFICANCE ===\")\n",
    "print(f\"p-value (H0: alpha=0, H1: alpha>0): {p_alpha_gt0:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_quant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
