{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4b3288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Regime lagged by 1 day to avoid look-ahead bias.\n",
      "\n",
      "================================================================================\n",
      " REGIME-BASED PERFORMANCE ANALYSIS: STRATEGY vs SPY (v2)\n",
      "================================================================================\n",
      "\n",
      "Data range: 1999-01-04 to 2025-12-30\n",
      "Total aligned days: 6,790 (26.94 years)\n",
      "Bull market days (SPY > 200 DMA): 5,057 (74.5%)\n",
      "Bear market days (SPY < 200 DMA): 1,733 (25.5%)\n",
      "\n",
      "⚠️  REGIME LAGGED BY 1 DAY (look-ahead bias prevention enabled)\n",
      "\n",
      "================================================================================\n",
      " SECTION 1: OVERALL STATISTICS (Full Contiguous Series)\n",
      "================================================================================\n",
      "\n",
      "  Metric                                Strategy             SPY            Diff\n",
      "  ------------------------------ --------------- --------------- ---------------\n",
      "  Ann. Return                             16.39%           8.47%           4.67%\n",
      "  Ann. Volatility                         12.96%          19.35%          17.06%\n",
      "  Sharpe Ratio                             1.236           0.517           0.719\n",
      "  Max Drawdown                           -19.72%         -55.19%          35.47%\n",
      "  Win Rate                                47.97%          54.37%          -6.41%\n",
      "  \n",
      "  Information Ratio                        0.353\n",
      "  Ann. Excess Return (correct)             4.67%\n",
      "\n",
      "================================================================================\n",
      " SECTION 2: CONTIGUOUS SEGMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "  This analyzes each continuous bull/bear period separately,\n",
      "  avoiding the pitfalls of stitching non-contiguous days together.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " BEAR MARKET SEGMENTS (SPY < 200 DMA)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Found 93 contiguous bear segment(s):\n",
      "  #    Start        End          Days   Strat Tot    SPY Tot      Excess       Strat DD   SPY DD    \n",
      "  ---- ------------ ------------ ------ ------------ ------------ ------------ ---------- ----------\n",
      "  1    1999-09-24   1999-10-04   7            2.48%       2.25%       0.24%    -1.34%    -1.39%\n",
      "  2    1999-10-14   1999-10-28   11           3.17%       4.97%      -1.80%    -1.87%    -2.56%\n",
      "  3    2000-02-22   2000-02-23   2            3.38%       0.92%       2.46%     0.00%     0.00%\n",
      "  4    2000-02-25   2000-02-28   2            0.10%       1.73%      -1.63%    -1.75%     0.00%\n",
      "  5    2000-04-17   2000-04-17   1            5.26%       3.49%       1.77%     0.00%     0.00%\n",
      "  6    2000-05-11   2000-05-11   1            2.31%       2.29%       0.02%     0.00%     0.00%\n",
      "  7    2000-05-24   2000-05-24   1           -1.60%       1.63%      -3.23%     0.00%     0.00%\n",
      "  8    2000-05-26   2000-05-30   2            0.11%       3.38%      -3.26%     0.00%     0.00%\n",
      "  9    2000-07-31   2000-07-31   1           -1.39%       0.64%      -2.03%     0.00%     0.00%\n",
      "  10   2000-09-22   2000-09-22   1            1.37%       1.82%      -0.45%     0.00%     0.00%\n",
      "  11   2000-09-26   2000-09-28   3            3.03%       0.52%       2.51%     0.00%     0.00%\n",
      "  12   2000-10-02   2002-01-03   313          0.81%     -17.36%      18.16%    -4.35%   -31.69%\n",
      "  13   2002-01-10   2002-03-04   36           0.00%       0.16%      -0.16%     0.00%    -6.94%\n",
      "  14   2002-03-26   2002-03-26   1            0.83%       0.58%       0.25%     0.00%     0.00%\n",
      "  15   2002-04-04   2002-04-10   5            3.36%       0.24%       3.12%     0.00%    -0.70%\n",
      "  16   2002-04-12   2002-04-16   3            0.17%       2.36%      -2.19%    -0.13%    -0.76%\n",
      "  17   2002-04-18   2003-03-21   234         -1.71%     -19.27%      17.55%    -1.75%   -30.26%\n",
      "  18   2003-03-25   2003-04-04   9            0.00%       1.76%      -1.76%     0.00%    -3.18%\n",
      "  19   2003-04-08   2003-04-08   1            0.00%       0.16%      -0.16%     0.00%     0.00%\n",
      "  20   2003-04-10   2003-04-14   3            0.00%       2.21%      -2.21%     0.00%    -0.41%\n",
      "  21   2004-07-22   2004-07-29   6            0.22%       0.90%      -0.68%    -0.75%    -1.03%\n",
      "  22   2004-08-04   2004-08-25   16          -2.09%       0.81%      -2.89%    -1.78%    -3.04%\n",
      "  23   2004-08-31   2004-08-31   1            0.61%       0.52%       0.08%     0.00%     0.00%\n",
      "  24   2004-09-24   2004-09-24   1           -0.18%       0.46%      -0.64%     0.00%     0.00%\n",
      "  25   2004-09-28   2004-09-29   2            0.43%       0.98%      -0.56%     0.00%     0.00%\n",
      "  26   2004-10-14   2004-10-18   3            0.59%       0.13%       0.46%     0.00%     0.00%\n",
      "  27   2004-10-20   2004-10-27   6            0.79%       1.93%      -1.14%    -0.37%    -1.24%\n",
      "  28   2005-04-18   2005-04-19   2            1.21%       1.10%       0.11%     0.00%     0.00%\n",
      "  29   2005-04-21   2005-04-21   1            0.75%       1.94%      -1.19%     0.00%     0.00%\n",
      "  30   2005-04-29   2005-04-29   1            0.08%       1.36%      -1.27%     0.00%     0.00%\n",
      "  31   2005-10-07   2005-10-07   1           -0.15%       0.34%      -0.49%     0.00%     0.00%\n",
      "  32   2005-10-11   2005-10-19   7            0.70%       0.99%      -0.30%    -0.52%    -1.08%\n",
      "  33   2005-10-21   2005-10-24   2            0.64%       1.95%      -1.30%     0.00%     0.00%\n",
      "  34   2005-10-28   2005-10-28   1            0.53%       1.44%      -0.91%     0.00%     0.00%\n",
      "  35   2006-06-12   2006-06-15   4            0.10%       0.61%      -0.52%    -0.65%    -1.16%\n",
      "  36   2006-06-19   2006-06-29   9            0.89%       2.10%      -1.22%    -1.09%    -0.88%\n",
      "  37   2006-07-14   2006-07-19   4            0.99%       1.36%      -0.37%    -0.26%    -0.15%\n",
      "  38   2006-07-21   2006-07-24   2            0.64%       1.11%      -0.47%     0.00%     0.00%\n",
      "  39   2007-08-06   2007-08-06   1            0.79%       1.68%      -0.89%     0.00%     0.00%\n",
      "  40   2007-08-15   2007-08-17   3            0.19%       1.19%      -1.00%    -0.56%     0.00%\n",
      "  41   2007-08-21   2007-08-21   1            1.88%       0.20%       1.68%     0.00%     0.00%\n",
      "  42   2007-08-29   2007-08-29   1            2.24%       1.96%       0.28%     0.00%     0.00%\n",
      "  43   2007-11-09   2007-11-13   3           -1.47%       0.63%      -2.10%    -2.86%    -0.99%\n",
      "  44   2007-11-16   2007-11-30   10           1.69%       2.14%      -0.46%    -0.57%    -3.32%\n",
      "  45   2007-12-05   2007-12-05   1            0.41%       1.67%      -1.26%     0.00%     0.00%\n",
      "  46   2007-12-17   2007-12-21   5            0.30%       1.19%      -0.88%     0.00%     0.00%\n",
      "  47   2007-12-31   2008-05-06   88          -3.41%      -3.09%      -0.32%    -5.22%   -12.45%\n",
      "  48   2008-05-08   2008-05-15   6            0.01%       2.16%      -2.14%    -0.08%    -0.19%\n",
      "  49   2008-05-22   2009-05-29   257         -0.13%     -31.92%      31.79%    -0.19%   -50.70%\n",
      "  50   2010-05-21   2010-05-27   5            4.92%       2.99%       1.92%    -1.33%    -1.78%\n",
      "  51   2010-06-01   2010-06-02   2           -0.60%       0.88%      -1.48%     0.00%     0.00%\n",
      "  52   2010-06-07   2010-06-15   7            2.66%       4.85%      -2.19%    -0.19%    -0.53%\n",
      "  53   2010-06-23   2010-07-26   23           0.60%       1.82%      -1.22%    -4.16%    -6.44%\n",
      "  54   2010-07-30   2010-08-02   2            0.13%       2.24%      -2.11%     0.00%     0.00%\n",
      "  55   2010-08-12   2010-09-10   21           1.08%       1.99%      -0.92%    -0.36%    -4.15%\n",
      "  56   2011-08-03   2011-10-27   61          -3.75%       3.03%      -6.79%    -6.57%   -12.42%\n",
      "  57   2011-11-01   2011-11-08   6            0.00%       1.90%      -1.90%     0.00%    -0.61%\n",
      "  58   2011-11-10   2011-11-11   2            0.00%       2.84%      -2.84%     0.00%     0.00%\n",
      "  59   2011-11-15   2011-12-05   14           0.00%       0.61%      -0.61%     0.00%    -7.73%\n",
      "  60   2011-12-09   2011-12-09   1            1.03%       1.69%      -0.66%     0.00%     0.00%\n",
      "  61   2011-12-13   2011-12-22   8            0.75%       1.49%      -0.75%    -0.47%    -1.62%\n",
      "  62   2012-11-15   2012-11-19   3            2.49%       2.35%       0.13%     0.00%     0.00%\n",
      "  63   2014-10-14   2014-10-20   5            0.03%       1.54%      -1.51%    -1.34%    -0.76%\n",
      "  64   2015-08-21   2015-10-22   44          -0.10%       1.16%      -1.25%    -2.72%    -5.59%\n",
      "  65   2015-11-13   2015-11-16   2            0.14%       0.38%      -0.24%     0.00%     0.00%\n",
      "  66   2015-12-14   2015-12-16   3            0.94%       3.05%      -2.11%     0.00%     0.00%\n",
      "  67   2015-12-18   2015-12-23   4            1.56%       1.16%       0.39%     0.00%     0.00%\n",
      "  68   2016-01-04   2016-03-11   48          -7.03%      -0.54%      -6.49%    -7.83%    -9.19%\n",
      "  69   2016-06-28   2016-06-28   1            1.99%       1.80%       0.18%     0.00%     0.00%\n",
      "  70   2018-10-12   2018-10-12   1            1.34%       1.39%      -0.05%     0.00%     0.00%\n",
      "  71   2018-10-24   2018-11-06   10          -1.53%       0.55%      -2.08%    -1.02%    -2.30%\n",
      "  72   2018-11-13   2018-11-28   11           0.17%       0.74%      -0.57%    -1.65%    -3.83%\n",
      "  73   2018-11-30   2018-11-30   1            0.08%       0.61%      -0.53%     0.00%     0.00%\n",
      "  74   2018-12-06   2019-02-04   40          -1.02%       1.22%      -2.24%    -5.02%   -12.65%\n",
      "  75   2019-02-08   2019-02-12   3            0.28%       1.47%      -1.19%    -0.19%     0.00%\n",
      "  76   2019-06-03   2019-06-04   2            1.73%       1.91%      -0.18%     0.00%     0.00%\n",
      "  77   2020-02-28   2020-03-02   2            1.72%       3.89%      -2.18%     0.00%     0.00%\n",
      "  78   2020-03-04   2020-03-04   1            3.56%       4.20%      -0.64%     0.00%     0.00%\n",
      "  79   2020-03-06   2020-05-26   56          -5.80%      -0.54%      -5.26%   -14.65%   -24.61%\n",
      "  80   2022-01-24   2022-01-24   1            0.23%       0.42%      -0.19%     0.00%     0.00%\n",
      "  81   2022-01-26   2022-01-28   3            1.75%       1.72%       0.03%     0.00%    -0.49%\n",
      "  82   2022-02-14   2022-02-15   2           -0.12%       1.28%      -1.40%     0.00%     0.00%\n",
      "  83   2022-02-18   2022-03-18   20           0.69%       2.02%      -1.34%    -1.64%    -4.94%\n",
      "  84   2022-04-12   2022-08-16   87          -0.50%      -1.90%       1.40%    -9.80%   -17.61%\n",
      "  85   2022-08-18   2022-11-30   73           0.00%      -4.05%       4.05%     0.00%   -16.33%\n",
      "  86   2022-12-06   2022-12-13   6            0.39%       0.60%      -0.21%    -0.47%    -0.75%\n",
      "  87   2022-12-15   2023-01-11   18           0.66%      -0.52%       1.17%    -0.72%    -2.88%\n",
      "  88   2023-01-19   2023-01-20   2            0.45%       1.12%      -0.67%     0.00%     0.00%\n",
      "  89   2023-03-13   2023-03-14   2            0.72%       1.51%      -0.78%     0.00%     0.00%\n",
      "  90   2023-03-16   2023-03-16   1            1.44%       1.75%      -0.31%     0.00%     0.00%\n",
      "  91   2023-10-26   2023-11-01   5            0.96%       1.22%      -0.27%     0.00%    -0.45%\n",
      "  92   2025-03-11   2025-03-24   10           3.70%       2.72%       0.98%    -0.99%    -1.33%\n",
      "  93   2025-03-27   2025-05-12   32          -2.46%       2.53%      -4.99%    -4.95%   -12.45%\n",
      "\n",
      "  Summary across bear segments:\n",
      "    Excess return: mean=-0.10%, median=-0.64%\n",
      "    Strategy beat SPY in 24/93 segments (25.8%)\n",
      "    Strategy max DD: worst=-14.65%, median=0.00%\n",
      "    SPY max DD: worst=-50.70%, median=0.00%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " BULL MARKET SEGMENTS (SPY > 200 DMA)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Found 94 contiguous bull segment(s).\n",
      "\n",
      "  Summary across bull segments:\n",
      "    Excess return: mean=2.37%, median=0.92%\n",
      "    Strategy beat SPY in 80/94 segments (85.1%)\n",
      "    Strategy max DD: worst=-19.67%, median=-1.04%\n",
      "\n",
      "================================================================================\n",
      " SECTION 3: CONDITIONAL STATISTICS (Days Labeled as Bull/Bear)\n",
      "================================================================================\n",
      "\n",
      "  These stats describe behavior conditional on regime, NOT tradable returns.\n",
      "\n",
      "  Conditional Statistics (Bull days, n=5,057):\n",
      "  NOTE: These are 'conditional on regime' stats, not tradable regime returns.\n",
      "  \n",
      "  Metric                                Strategy             SPY            Diff\n",
      "  ------------------------------ --------------- --------------- ---------------\n",
      "  Mean daily return                      0.0759%         0.0384%         0.0375%\n",
      "  Daily volatility                       0.8693%         0.8577%         0.0116%\n",
      "  Win rate                                54.82%          55.03%          -0.22%\n",
      "  \n",
      "  Ann. Sharpe (conditional)                1.386           0.711           0.675\n",
      "  IR (Sharpe of excess)                    0.827\n",
      "  Ann. excess return                       9.19%\n",
      "\n",
      "  Conditional Statistics (Bear days, n=1,733):\n",
      "  NOTE: These are 'conditional on regime' stats, not tradable regime returns.\n",
      "  \n",
      "  Metric                                Strategy             SPY            Diff\n",
      "  ------------------------------ --------------- --------------- ---------------\n",
      "  Mean daily return                      0.0278%         0.0434%        -0.0157%\n",
      "  Daily volatility                       0.6362%         1.9161%        -1.2800%\n",
      "  Win rate                                27.99%          52.45%         -24.47%\n",
      "  \n",
      "  Ann. Sharpe (conditional)                0.692           0.359           0.333\n",
      "  IR (Sharpe of excess)                   -0.143\n",
      "  Ann. excess return                      -7.47%\n",
      "\n",
      "================================================================================\n",
      " SECTION 4: BOOTSTRAP STATISTICAL SIGNIFICANCE\n",
      "================================================================================\n",
      "\n",
      "  Bootstrap performed on FULL contiguous series, then regime stats computed.\n",
      "  This preserves the time-series dependence structure correctly.\n",
      "\n",
      "  Running bootstrap (this may take a moment)...\n",
      "\n",
      "  Bootstrap Results for Overall (n_boot=5000, block_len=21):\n",
      "    IR point estimate (median): 0.354\n",
      "    95% CI: [0.006, 0.697]\n",
      "    One-sided p-value (H0: IR ≤ 0): 0.0222\n",
      "    Two-sided p-value (H0: IR = 0): 0.0444\n",
      "    Significant at α=0.05 (two-sided): Yes **\n",
      "\n",
      "  Bootstrap Results for Bull Market (n_boot=5000, block_len=21):\n",
      "    IR point estimate (median): 0.827\n",
      "    95% CI: [0.363, 1.302]\n",
      "    One-sided p-value (H0: IR ≤ 0): 0.0002\n",
      "    Two-sided p-value (H0: IR = 0): 0.0004\n",
      "    Significant at α=0.05 (two-sided): Yes **\n",
      "\n",
      "  Bootstrap Results for Bear Market (n_boot=5000, block_len=21):\n",
      "    IR point estimate (median): -0.152\n",
      "    95% CI: [-0.798, 0.466]\n",
      "    One-sided p-value (H0: IR ≤ 0): 0.6830\n",
      "    Two-sided p-value (H0: IR = 0): 0.6340\n",
      "    Significant at α=0.05 (two-sided): No\n",
      "\n",
      "================================================================================\n",
      " SECTION 5: KEY FINDINGS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "  Regime          IR         95% CI                    Significant?   \n",
      "  --------------- ---------- ------------------------- ---------------\n",
      "  Overall         0.353      [0.006, 0.697]           YES            \n",
      "  Bull            0.827      [0.363, 1.302]           YES            \n",
      "  Bear            -0.143     [-0.798, 0.466]           NO             \n",
      "\n",
      "  Bear market segment win rate: 24/93 (25.8%)\n",
      "  Worst bear segment: Strategy -7.0% vs SPY -31.9%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " INTERPRETATION NOTES:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  1. OVERALL IR: Tests whether strategy has risk-adjusted alpha vs SPY across\n",
      "     the full time period. This is the most reliable test.\n",
      "\n",
      "  2. REGIME IRs: These test conditional performance, but interpretation requires\n",
      "     care - the bootstrap resamples the full series, so regime proportions may\n",
      "     vary across samples.\n",
      "\n",
      "  3. SEGMENT ANALYSIS: Shows actual performance in each contiguous bear/bull\n",
      "     market. This is the most intuitive way to see \"what happened in 2008\" etc.\n",
      "\n",
      "  4. If you trade based on the regime signal, enable LAG_REGIME=True to avoid\n",
      "     look-ahead bias in this analysis.\n",
      "\n",
      "\n",
      "Analysis complete.\n",
      "\n",
      "================================================================================\n",
      " SECTION 6: AUTOCORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "  Testing whether returns exhibit serial dependence (momentum or mean-reversion).\n",
      "\n",
      "  Autocorrelation by Lag (significance threshold: ±0.0243)\n",
      "  ----------------------------------------------------------------------\n",
      "  Lag        Strategy          SPY       Excess       Significant?\n",
      "  ----------------------------------------------------------------------\n",
      "  1           -0.0044      -0.0832      -0.0676        SPY, Excess\n",
      "  2           +0.0163      -0.0186      -0.0382             Excess\n",
      "  3           -0.0190      -0.0090      +0.0128                  -\n",
      "  4           +0.0075      -0.0271      -0.0101                SPY\n",
      "  5           +0.0038      -0.0169      -0.0121                  -\n",
      "  6           -0.0409      -0.0312      -0.0081         Strat, SPY\n",
      "  7           +0.0289      +0.0266      +0.0170         Strat, SPY\n",
      "  8           -0.0310      -0.0248      +0.0084         Strat, SPY\n",
      "  9           +0.0217      +0.0269      +0.0183                SPY\n",
      "  10          +0.0192      -0.0090      -0.0027                  -\n",
      "\n",
      "  Ljung-Box Test (H0: no autocorrelation up to lag k)\n",
      "  ----------------------------------------------------------------------\n",
      "  Series          Lag      LB Stat      p-value      Significant?   \n",
      "  ----------------------------------------------------------------------\n",
      "  Strategy        5        4.88         0.4304       No             \n",
      "  Strategy        10       34.12        0.0002       YES **         \n",
      "  Strategy        20       64.22        0.0000       YES **         \n",
      "  ----------------------------------------------------------------------\n",
      "  SPY             5        56.83        0.0000       YES **         \n",
      "  SPY             10       77.86        0.0000       YES **         \n",
      "  SPY             20       128.18       0.0000       YES **         \n",
      "  ----------------------------------------------------------------------\n",
      "  Excess          5        43.75        0.0000       YES **         \n",
      "  Excess          10       48.96        0.0000       YES **         \n",
      "  Excess          20       102.91       0.0000       YES **         \n",
      "  ----------------------------------------------------------------------\n",
      "\n",
      "  Durbin-Watson Statistic\n",
      "  ----------------------------------------------------------------------\n",
      "  Interpretation: ~2.0 = no autocorrelation, <2.0 = positive, >2.0 = negative\n",
      "  \n",
      "  Series          DW Stat      Interpretation           \n",
      "  -------------------------------------------------------\n",
      "  Strategy        1.9967       No strong autocorr       \n",
      "  SPY             2.1640       No strong autocorr       \n",
      "  Excess          2.1341       No strong autocorr       \n",
      "\n",
      "  Runs Test (H0: sequence of +/- returns is random)\n",
      "  ----------------------------------------------------------------------\n",
      "  Series          Actual Runs  Expected     Z-stat       p-value      Random?        \n",
      "  --------------------------------------------------------------------------------\n",
      "  Strategy        2924         2921.5       0.07         0.9473       Yes            \n",
      "  SPY             3423         3357.6       1.60         0.1087       Yes            \n",
      "  Excess          3433         3395.5       0.91         0.3623       Yes            \n",
      "\n",
      "  ----------------------------------------------------------------------\n",
      "  AUTOCORRELATION SUMMARY\n",
      "  ----------------------------------------------------------------------\n",
      "\n",
      "  • Strategy returns show NO significant lag-1 autocorrelation.\n",
      "  • Excess returns show NEGATIVE lag-1 autocorrelation (-0.0676) - alpha mean-reverts.\n",
      "\n",
      "  Trading Implications:\n",
      "    - No significant autocorrelation - each day appears independent.\n",
      "    - Focus on position sizing rather than timing adjustments.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Regime-Based Performance Analysis: Strategy vs SPY (v2)\n",
    "\n",
    "Compares strategy performance against SPY during:\n",
    "- Bull markets (SPY above 200-day MA, regime=1)\n",
    "- Bear markets (SPY below 200-day MA, regime=0)\n",
    "\n",
    "Key improvements over v1:\n",
    "- Contiguous segment analysis (no artificial stitching)\n",
    "- Correct excess return calculation: ann_return(strat - spy)\n",
    "- Bootstrap on full series, then compute regime stats (preserves time structure)\n",
    "- Regime lag option to avoid look-ahead bias\n",
    "- Per-segment breakdown for bear/bull markets\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "EQUITY_FILE = \"./13-trading_output_regression_insp500_spyfilter_cap15/13-equity_curve_regression_insp500_spyfilter_cap15.parquet\"\n",
    "SPY_PARQUET = \"./8-SPY_200DMA_market_regime/8-SPY_200DMA_regime.parquet\"\n",
    "\n",
    "N_BOOT = 5000\n",
    "BLOCK_LEN = 21  # Primary block length for bootstrap\n",
    "SEED = 7\n",
    "\n",
    "# Set to True if your strategy uses the regime signal for trading decisions\n",
    "# This will lag the regime by 1 day to avoid look-ahead bias\n",
    "LAG_REGIME = True\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DATA CLASSES\n",
    "# =========================\n",
    "@dataclass\n",
    "class SegmentStats:\n",
    "    \"\"\"Statistics for a contiguous regime segment.\"\"\"\n",
    "    start_date: pd.Timestamp\n",
    "    end_date: pd.Timestamp\n",
    "    n_days: int\n",
    "    strat_total_return: float\n",
    "    spy_total_return: float\n",
    "    strat_ann_return: float\n",
    "    spy_ann_return: float\n",
    "    excess_total_return: float\n",
    "    strat_max_dd: float\n",
    "    spy_max_dd: float\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def ann_sharpe(r: np.ndarray) -> float:\n",
    "    \"\"\"Annualized Sharpe ratio (assuming zero risk-free rate).\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 2:\n",
    "        return np.nan\n",
    "    sd = r.std(ddof=1)\n",
    "    if sd <= 0 or np.isnan(sd):\n",
    "        return 0.0\n",
    "    return np.sqrt(TRADING_DAYS) * r.mean() / sd\n",
    "\n",
    "\n",
    "def ann_return(r: np.ndarray) -> float:\n",
    "    \"\"\"Annualized return from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 2:\n",
    "        return np.nan\n",
    "    total = np.prod(1 + r) - 1\n",
    "    years = r.size / TRADING_DAYS\n",
    "    if years <= 0:\n",
    "        return np.nan\n",
    "    return (1 + total) ** (1 / years) - 1\n",
    "\n",
    "\n",
    "def total_return(r: np.ndarray) -> float:\n",
    "    \"\"\"Total cumulative return from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 1:\n",
    "        return np.nan\n",
    "    return np.prod(1 + r) - 1\n",
    "\n",
    "\n",
    "def ann_volatility(r: np.ndarray) -> float:\n",
    "    \"\"\"Annualized volatility from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 2:\n",
    "        return np.nan\n",
    "    return r.std(ddof=1) * np.sqrt(TRADING_DAYS)\n",
    "\n",
    "\n",
    "def max_drawdown(r: np.ndarray) -> float:\n",
    "    \"\"\"Maximum drawdown from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 1:\n",
    "        return np.nan\n",
    "    cum = np.cumprod(1 + r)\n",
    "    running_max = np.maximum.accumulate(cum)\n",
    "    dd = (cum - running_max) / running_max\n",
    "    return dd.min()\n",
    "\n",
    "\n",
    "def win_rate(r: np.ndarray) -> float:\n",
    "    \"\"\"Percentage of positive return days.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 1:\n",
    "        return np.nan\n",
    "    return np.mean(r > 0)\n",
    "\n",
    "\n",
    "def find_contiguous_segments(df: pd.DataFrame, regime_col: str = \"market_regime\") -> List[Tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    Find contiguous segments of the same regime.\n",
    "    Returns list of (start_idx, end_idx, regime_value) tuples.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    if len(df) == 0:\n",
    "        return segments\n",
    "    \n",
    "    regime = df[regime_col].values\n",
    "    start_idx = 0\n",
    "    current_regime = regime[0]\n",
    "    \n",
    "    for i in range(1, len(regime)):\n",
    "        if regime[i] != current_regime:\n",
    "            segments.append((start_idx, i - 1, int(current_regime)))\n",
    "            start_idx = i\n",
    "            current_regime = regime[i]\n",
    "    \n",
    "    # Don't forget the last segment\n",
    "    segments.append((start_idx, len(regime) - 1, int(current_regime)))\n",
    "    \n",
    "    return segments\n",
    "\n",
    "\n",
    "def compute_segment_stats(df: pd.DataFrame, start_idx: int, end_idx: int) -> SegmentStats:\n",
    "    \"\"\"Compute statistics for a single contiguous segment.\"\"\"\n",
    "    segment = df.iloc[start_idx:end_idx + 1]\n",
    "    \n",
    "    strat_ret = segment[\"strat_ret\"].values\n",
    "    spy_ret = segment[\"spy_ret\"].values\n",
    "    n_days = len(segment)\n",
    "    years = n_days / TRADING_DAYS\n",
    "    \n",
    "    strat_total = total_return(strat_ret)\n",
    "    spy_total = total_return(spy_ret)\n",
    "    \n",
    "    # Annualize only if segment is long enough\n",
    "    if years > 0.1:  # At least ~25 days\n",
    "        strat_ann = (1 + strat_total) ** (1 / years) - 1\n",
    "        spy_ann = (1 + spy_total) ** (1 / years) - 1\n",
    "    else:\n",
    "        strat_ann = np.nan\n",
    "        spy_ann = np.nan\n",
    "    \n",
    "    return SegmentStats(\n",
    "        start_date=segment[\"date\"].iloc[0],\n",
    "        end_date=segment[\"date\"].iloc[-1],\n",
    "        n_days=n_days,\n",
    "        strat_total_return=strat_total,\n",
    "        spy_total_return=spy_total,\n",
    "        strat_ann_return=strat_ann,\n",
    "        spy_ann_return=spy_ann,\n",
    "        excess_total_return=strat_total - spy_total,\n",
    "        strat_max_dd=max_drawdown(strat_ret),\n",
    "        spy_max_dd=max_drawdown(spy_ret),\n",
    "    )\n",
    "\n",
    "\n",
    "def block_bootstrap_idx(n: int, block_len: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Stationary-ish block bootstrap via concatenating random contiguous blocks.\n",
    "    Falls back to IID bootstrap if block_len<=1 or block_len>n.\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    if block_len <= 1 or block_len > n:\n",
    "        return rng.integers(0, n, size=n, dtype=int)\n",
    "\n",
    "    idx = []\n",
    "    max_start = n - block_len\n",
    "    while len(idx) < n:\n",
    "        s = int(rng.integers(0, max_start + 1))\n",
    "        idx.extend(range(s, s + block_len))\n",
    "    return np.array(idx[:n], dtype=int)\n",
    "\n",
    "\n",
    "def compute_regime_stats_from_returns(\n",
    "    strat_ret: np.ndarray, \n",
    "    spy_ret: np.ndarray, \n",
    "    regime: np.ndarray\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Compute regime statistics from return arrays.\n",
    "    Used for both point estimates and bootstrap samples.\n",
    "    \"\"\"\n",
    "    excess_ret = strat_ret - spy_ret\n",
    "    \n",
    "    bull_mask = regime == 1\n",
    "    bear_mask = regime == 0\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, mask in [(\"bull\", bull_mask), (\"bear\", bear_mask), (\"overall\", np.ones(len(regime), dtype=bool))]:\n",
    "        if mask.sum() < 2:\n",
    "            results[name] = {\n",
    "                \"strat_sharpe\": np.nan,\n",
    "                \"spy_sharpe\": np.nan,\n",
    "                \"ir\": np.nan,\n",
    "                \"excess_ann_return\": np.nan,\n",
    "                \"strat_ann_return\": np.nan,\n",
    "                \"spy_ann_return\": np.nan,\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        s = strat_ret[mask]\n",
    "        p = spy_ret[mask]\n",
    "        e = excess_ret[mask]\n",
    "        \n",
    "        results[name] = {\n",
    "            \"strat_sharpe\": ann_sharpe(s),\n",
    "            \"spy_sharpe\": ann_sharpe(p),\n",
    "            \"ir\": ann_sharpe(e),\n",
    "            \"excess_ann_return\": ann_return(e),  # CORRECT: annualize the excess return stream\n",
    "            \"strat_ann_return\": ann_return(s),\n",
    "            \"spy_ann_return\": ann_return(p),\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def bootstrap_regime_stats(\n",
    "    df: pd.DataFrame, \n",
    "    n_boot: int = 5000, \n",
    "    block_len: int = 21, \n",
    "    seed: int = 7\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Bootstrap on the FULL contiguous series, then compute regime stats per sample.\n",
    "    This preserves the time structure properly.\n",
    "    \n",
    "    Returns dict with keys like 'bull_ir', 'bear_ir', 'overall_ir', etc.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    strat_ret = df[\"strat_ret\"].to_numpy(dtype=float)\n",
    "    spy_ret = df[\"spy_ret\"].to_numpy(dtype=float)\n",
    "    regime = df[\"market_regime\"].to_numpy(dtype=int)\n",
    "    \n",
    "    n = len(df)\n",
    "    \n",
    "    # Initialize result arrays\n",
    "    metrics = [\"ir\", \"strat_sharpe\", \"spy_sharpe\", \"excess_ann_return\"]\n",
    "    regimes = [\"overall\", \"bull\", \"bear\"]\n",
    "    \n",
    "    results = {f\"{r}_{m}\": np.empty(n_boot, dtype=float) for r in regimes for m in metrics}\n",
    "    \n",
    "    for i in range(n_boot):\n",
    "        idx = block_bootstrap_idx(n, block_len, rng)\n",
    "        \n",
    "        # Resample all arrays with the same indices (preserves alignment)\n",
    "        s_boot = strat_ret[idx]\n",
    "        p_boot = spy_ret[idx]\n",
    "        r_boot = regime[idx]\n",
    "        \n",
    "        stats = compute_regime_stats_from_returns(s_boot, p_boot, r_boot)\n",
    "        \n",
    "        for reg in regimes:\n",
    "            for met in metrics:\n",
    "                results[f\"{reg}_{met}\"][i] = stats[reg][met]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_segment_summary(segments: List[SegmentStats], regime_name: str):\n",
    "    \"\"\"Print summary of contiguous segments for a regime.\"\"\"\n",
    "    if not segments:\n",
    "        print(f\"\\n  No {regime_name} segments found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n  Found {len(segments)} contiguous {regime_name} segment(s):\")\n",
    "    print(f\"  {'#':<4} {'Start':<12} {'End':<12} {'Days':<6} {'Strat Tot':<12} {'SPY Tot':<12} {'Excess':<12} {'Strat DD':<10} {'SPY DD':<10}\")\n",
    "    print(f\"  {'-'*4} {'-'*12} {'-'*12} {'-'*6} {'-'*12} {'-'*12} {'-'*12} {'-'*10} {'-'*10}\")\n",
    "    \n",
    "    for i, seg in enumerate(segments, 1):\n",
    "        print(\n",
    "            f\"  {i:<4} \"\n",
    "            f\"{seg.start_date.strftime('%Y-%m-%d'):<12} \"\n",
    "            f\"{seg.end_date.strftime('%Y-%m-%d'):<12} \"\n",
    "            f\"{seg.n_days:<6} \"\n",
    "            f\"{seg.strat_total_return*100:>10.2f}% \"\n",
    "            f\"{seg.spy_total_return*100:>10.2f}% \"\n",
    "            f\"{seg.excess_total_return*100:>10.2f}% \"\n",
    "            f\"{seg.strat_max_dd*100:>8.2f}% \"\n",
    "            f\"{seg.spy_max_dd*100:>8.2f}%\"\n",
    "        )\n",
    "    \n",
    "    # Summary statistics across segments\n",
    "    print(f\"\\n  Summary across {regime_name} segments:\")\n",
    "    \n",
    "    excess_returns = [s.excess_total_return for s in segments]\n",
    "    strat_dds = [s.strat_max_dd for s in segments]\n",
    "    spy_dds = [s.spy_max_dd for s in segments]\n",
    "    \n",
    "    print(f\"    Excess return: mean={np.mean(excess_returns)*100:.2f}%, median={np.median(excess_returns)*100:.2f}%\")\n",
    "    print(f\"    Strategy beat SPY in {sum(1 for e in excess_returns if e > 0)}/{len(segments)} segments ({sum(1 for e in excess_returns if e > 0)/len(segments)*100:.1f}%)\")\n",
    "    print(f\"    Strategy max DD: worst={min(strat_dds)*100:.2f}%, median={np.median(strat_dds)*100:.2f}%\")\n",
    "    print(f\"    SPY max DD: worst={min(spy_dds)*100:.2f}%, median={np.median(spy_dds)*100:.2f}%\")\n",
    "\n",
    "\n",
    "def print_conditional_stats(df: pd.DataFrame, regime_name: str, regime_value: int):\n",
    "    \"\"\"Print conditional statistics (average behavior on days with this regime).\"\"\"\n",
    "    subset = df[df[\"market_regime\"] == regime_value]\n",
    "    \n",
    "    if len(subset) < 2:\n",
    "        print(f\"\\n  Insufficient data for {regime_name} regime.\")\n",
    "        return\n",
    "    \n",
    "    strat_ret = subset[\"strat_ret\"].to_numpy()\n",
    "    spy_ret = subset[\"spy_ret\"].to_numpy()\n",
    "    excess_ret = strat_ret - spy_ret\n",
    "    \n",
    "    print(f\"\\n  Conditional Statistics ({regime_name} days, n={len(subset):,}):\")\n",
    "    print(f\"  NOTE: These are 'conditional on regime' stats, not tradable regime returns.\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  {'Metric':<30} {'Strategy':>15} {'SPY':>15} {'Diff':>15}\")\n",
    "    print(f\"  {'-'*30} {'-'*15} {'-'*15} {'-'*15}\")\n",
    "    \n",
    "    # Daily stats (more meaningful for conditional analysis)\n",
    "    print(f\"  {'Mean daily return':<30} {strat_ret.mean()*100:>14.4f}% {spy_ret.mean()*100:>14.4f}% {excess_ret.mean()*100:>14.4f}%\")\n",
    "    print(f\"  {'Daily volatility':<30} {strat_ret.std()*100:>14.4f}% {spy_ret.std()*100:>14.4f}% {(strat_ret.std()-spy_ret.std())*100:>14.4f}%\")\n",
    "    print(f\"  {'Win rate':<30} {win_rate(strat_ret)*100:>14.2f}% {win_rate(spy_ret)*100:>14.2f}% {(win_rate(strat_ret)-win_rate(spy_ret))*100:>14.2f}%\")\n",
    "    print(f\"  \")\n",
    "    \n",
    "    # Annualized (with caveat)\n",
    "    print(f\"  {'Ann. Sharpe (conditional)':<30} {ann_sharpe(strat_ret):>15.3f} {ann_sharpe(spy_ret):>15.3f} {ann_sharpe(strat_ret)-ann_sharpe(spy_ret):>15.3f}\")\n",
    "    print(f\"  {'IR (Sharpe of excess)':<30} {ann_sharpe(excess_ret):>15.3f}\")\n",
    "    print(f\"  {'Ann. excess return':<30} {ann_return(excess_ret)*100:>14.2f}%\")\n",
    "\n",
    "\n",
    "def print_bootstrap_results(boot_results: Dict[str, np.ndarray], regime: str, label: str):\n",
    "    \"\"\"Print bootstrap results for a regime.\"\"\"\n",
    "    ir_dist = boot_results[f\"{regime}_ir\"]\n",
    "    ir_dist = ir_dist[~np.isnan(ir_dist)]\n",
    "    \n",
    "    if len(ir_dist) < 100:\n",
    "        print(f\"\\n  Bootstrap results for {label}: insufficient valid samples.\")\n",
    "        return\n",
    "    \n",
    "    ci = np.percentile(ir_dist, [2.5, 97.5])\n",
    "    point_ir = np.median(ir_dist)\n",
    "    \n",
    "    p_one_sided = np.mean(ir_dist <= 0.0)\n",
    "    p_two_sided = 2 * min(p_one_sided, 1 - p_one_sided)\n",
    "    \n",
    "    ci_excludes_zero = (ci[0] > 0) or (ci[1] < 0)\n",
    "    sig_marker = \"Yes **\" if ci_excludes_zero else \"No\"\n",
    "    \n",
    "    print(f\"\\n  Bootstrap Results for {label} (n_boot={len(ir_dist)}, block_len={BLOCK_LEN}):\")\n",
    "    print(f\"    IR point estimate (median): {point_ir:.3f}\")\n",
    "    print(f\"    95% CI: [{ci[0]:.3f}, {ci[1]:.3f}]\")\n",
    "    print(f\"    One-sided p-value (H0: IR ≤ 0): {p_one_sided:.4f}\")\n",
    "    print(f\"    Two-sided p-value (H0: IR = 0): {p_two_sided:.4f}\")\n",
    "    print(f\"    Significant at α=0.05 (two-sided): {sig_marker}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN ANALYSIS\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Load equity curve ---\n",
    "    eq = pd.read_parquet(EQUITY_FILE).copy()\n",
    "    \n",
    "    # Handle index vs column for date\n",
    "    if \"date\" not in eq.columns and eq.index.name == \"date\":\n",
    "        eq = eq.reset_index()\n",
    "    elif \"date\" not in eq.columns and \"Date\" in eq.columns:\n",
    "        eq = eq.rename(columns={\"Date\": \"date\"})\n",
    "    \n",
    "    eq[\"date\"] = pd.to_datetime(eq[\"date\"])\n",
    "    eq = eq.sort_values(\"date\").drop_duplicates(\"date\")\n",
    "    eq[\"strat_ret\"] = eq[\"portfolio_value\"].pct_change().fillna(0.0)\n",
    "\n",
    "    # --- Load SPY file with market regime ---\n",
    "    spy = pd.read_parquet(SPY_PARQUET).copy()\n",
    "    spy = spy.reset_index().rename(columns={\"Date\": \"date\", \"index\": \"date\"})\n",
    "    spy[\"date\"] = pd.to_datetime(spy[\"date\"])\n",
    "    spy = spy.sort_values(\"date\")\n",
    "    spy[\"spy_ret\"] = spy[\"spy_close\"].pct_change().fillna(0.0)\n",
    "    \n",
    "    # --- Optional: Lag regime to avoid look-ahead bias ---\n",
    "    if LAG_REGIME:\n",
    "        spy[\"market_regime\"] = spy[\"market_regime\"].shift(1).fillna(0).astype(int)\n",
    "        print(\"NOTE: Regime lagged by 1 day to avoid look-ahead bias.\\n\")\n",
    "\n",
    "    # --- Align on common dates ---\n",
    "    df = eq.merge(spy[[\"date\", \"spy_ret\", \"market_regime\"]], on=\"date\", how=\"inner\").dropna()\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    if len(df) < 2:\n",
    "        raise RuntimeError(\"Not enough aligned data points between equity curve and SPY.\")\n",
    "\n",
    "    # --- Compute excess returns (CORRECT way) ---\n",
    "    df[\"excess_ret\"] = df[\"strat_ret\"] - df[\"spy_ret\"]\n",
    "\n",
    "    # =========================\n",
    "    # HEADER\n",
    "    # =========================\n",
    "    print(\"=\" * 80)\n",
    "    print(\" REGIME-BASED PERFORMANCE ANALYSIS: STRATEGY vs SPY (v2)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nData range: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Total aligned days: {len(df):,} ({len(df)/TRADING_DAYS:.2f} years)\")\n",
    "    \n",
    "    n_bull = (df[\"market_regime\"] == 1).sum()\n",
    "    n_bear = (df[\"market_regime\"] == 0).sum()\n",
    "    print(f\"Bull market days (SPY > 200 DMA): {n_bull:,} ({n_bull/len(df)*100:.1f}%)\")\n",
    "    print(f\"Bear market days (SPY < 200 DMA): {n_bear:,} ({n_bear/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if LAG_REGIME:\n",
    "        print(\"\\n⚠️  REGIME LAGGED BY 1 DAY (look-ahead bias prevention enabled)\")\n",
    "\n",
    "    # =========================\n",
    "    # OVERALL STATISTICS (Full Series)\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 1: OVERALL STATISTICS (Full Contiguous Series)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    strat_ret = df[\"strat_ret\"].to_numpy()\n",
    "    spy_ret = df[\"spy_ret\"].to_numpy()\n",
    "    excess_ret = df[\"excess_ret\"].to_numpy()\n",
    "    \n",
    "    print(f\"\\n  {'Metric':<30} {'Strategy':>15} {'SPY':>15} {'Diff':>15}\")\n",
    "    print(f\"  {'-'*30} {'-'*15} {'-'*15} {'-'*15}\")\n",
    "    print(f\"  {'Ann. Return':<30} {ann_return(strat_ret)*100:>14.2f}% {ann_return(spy_ret)*100:>14.2f}% {ann_return(excess_ret)*100:>14.2f}%\")\n",
    "    print(f\"  {'Ann. Volatility':<30} {ann_volatility(strat_ret)*100:>14.2f}% {ann_volatility(spy_ret)*100:>14.2f}% {ann_volatility(excess_ret)*100:>14.2f}%\")\n",
    "    print(f\"  {'Sharpe Ratio':<30} {ann_sharpe(strat_ret):>15.3f} {ann_sharpe(spy_ret):>15.3f} {ann_sharpe(strat_ret)-ann_sharpe(spy_ret):>15.3f}\")\n",
    "    print(f\"  {'Max Drawdown':<30} {max_drawdown(strat_ret)*100:>14.2f}% {max_drawdown(spy_ret)*100:>14.2f}% {(max_drawdown(strat_ret)-max_drawdown(spy_ret))*100:>14.2f}%\")\n",
    "    print(f\"  {'Win Rate':<30} {win_rate(strat_ret)*100:>14.2f}% {win_rate(spy_ret)*100:>14.2f}% {(win_rate(strat_ret)-win_rate(spy_ret))*100:>14.2f}%\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  {'Information Ratio':<30} {ann_sharpe(excess_ret):>15.3f}\")\n",
    "    print(f\"  {'Ann. Excess Return (correct)':<30} {ann_return(excess_ret)*100:>14.2f}%\")\n",
    "\n",
    "    # =========================\n",
    "    # CONTIGUOUS SEGMENT ANALYSIS\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 2: CONTIGUOUS SEGMENT ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n  This analyzes each continuous bull/bear period separately,\")\n",
    "    print(\"  avoiding the pitfalls of stitching non-contiguous days together.\")\n",
    "    \n",
    "    segments = find_contiguous_segments(df)\n",
    "    \n",
    "    bull_segments = []\n",
    "    bear_segments = []\n",
    "    \n",
    "    for start_idx, end_idx, regime_val in segments:\n",
    "        stats = compute_segment_stats(df, start_idx, end_idx)\n",
    "        if regime_val == 1:\n",
    "            bull_segments.append(stats)\n",
    "        else:\n",
    "            bear_segments.append(stats)\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" BEAR MARKET SEGMENTS (SPY < 200 DMA)\")\n",
    "    print(\"-\" * 80)\n",
    "    print_segment_summary(bear_segments, \"bear\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" BULL MARKET SEGMENTS (SPY > 200 DMA)\")\n",
    "    print(\"-\" * 80)\n",
    "    # Only show summary for bull (too many segments usually)\n",
    "    if bull_segments:\n",
    "        print(f\"\\n  Found {len(bull_segments)} contiguous bull segment(s).\")\n",
    "        excess_returns = [s.excess_total_return for s in bull_segments]\n",
    "        strat_dds = [s.strat_max_dd for s in bull_segments]\n",
    "        print(f\"\\n  Summary across bull segments:\")\n",
    "        print(f\"    Excess return: mean={np.mean(excess_returns)*100:.2f}%, median={np.median(excess_returns)*100:.2f}%\")\n",
    "        print(f\"    Strategy beat SPY in {sum(1 for e in excess_returns if e > 0)}/{len(bull_segments)} segments ({sum(1 for e in excess_returns if e > 0)/len(bull_segments)*100:.1f}%)\")\n",
    "        print(f\"    Strategy max DD: worst={min(strat_dds)*100:.2f}%, median={np.median(strat_dds)*100:.2f}%\")\n",
    "\n",
    "    # =========================\n",
    "    # CONDITIONAL STATISTICS (for reference)\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 3: CONDITIONAL STATISTICS (Days Labeled as Bull/Bear)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n  These stats describe behavior conditional on regime, NOT tradable returns.\")\n",
    "    \n",
    "    print_conditional_stats(df, \"Bull\", 1)\n",
    "    print_conditional_stats(df, \"Bear\", 0)\n",
    "\n",
    "    # =========================\n",
    "    # BOOTSTRAP ANALYSIS (Correct Method)\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 4: BOOTSTRAP STATISTICAL SIGNIFICANCE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n  Bootstrap performed on FULL contiguous series, then regime stats computed.\")\n",
    "    print(\"  This preserves the time-series dependence structure correctly.\")\n",
    "    \n",
    "    print(\"\\n  Running bootstrap (this may take a moment)...\")\n",
    "    boot_results = bootstrap_regime_stats(df, n_boot=N_BOOT, block_len=BLOCK_LEN, seed=SEED)\n",
    "    \n",
    "    print_bootstrap_results(boot_results, \"overall\", \"Overall\")\n",
    "    print_bootstrap_results(boot_results, \"bull\", \"Bull Market\")\n",
    "    print_bootstrap_results(boot_results, \"bear\", \"Bear Market\")\n",
    "\n",
    "    # =========================\n",
    "    # KEY FINDINGS SUMMARY\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 5: KEY FINDINGS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Overall\n",
    "    overall_ir = ann_sharpe(excess_ret)\n",
    "    overall_ci = np.percentile(boot_results[\"overall_ir\"][~np.isnan(boot_results[\"overall_ir\"])], [2.5, 97.5])\n",
    "    overall_sig = \"YES\" if (overall_ci[0] > 0 or overall_ci[1] < 0) else \"NO\"\n",
    "    \n",
    "    # Bull\n",
    "    bull_mask = df[\"market_regime\"] == 1\n",
    "    bull_ir = ann_sharpe(excess_ret[bull_mask])\n",
    "    bull_ci = np.percentile(boot_results[\"bull_ir\"][~np.isnan(boot_results[\"bull_ir\"])], [2.5, 97.5])\n",
    "    bull_sig = \"YES\" if (bull_ci[0] > 0 or bull_ci[1] < 0) else \"NO\"\n",
    "    \n",
    "    # Bear\n",
    "    bear_mask = df[\"market_regime\"] == 0\n",
    "    bear_ir = ann_sharpe(excess_ret[bear_mask])\n",
    "    bear_ci = np.percentile(boot_results[\"bear_ir\"][~np.isnan(boot_results[\"bear_ir\"])], [2.5, 97.5])\n",
    "    bear_sig = \"YES\" if (bear_ci[0] > 0 or bear_ci[1] < 0) else \"NO\"\n",
    "    \n",
    "    print(f\"\\n  {'Regime':<15} {'IR':<10} {'95% CI':<25} {'Significant?':<15}\")\n",
    "    print(f\"  {'-'*15} {'-'*10} {'-'*25} {'-'*15}\")\n",
    "    print(f\"  {'Overall':<15} {overall_ir:<10.3f} [{overall_ci[0]:.3f}, {overall_ci[1]:.3f}]{'':>10} {overall_sig:<15}\")\n",
    "    print(f\"  {'Bull':<15} {bull_ir:<10.3f} [{bull_ci[0]:.3f}, {bull_ci[1]:.3f}]{'':>10} {bull_sig:<15}\")\n",
    "    print(f\"  {'Bear':<15} {bear_ir:<10.3f} [{bear_ci[0]:.3f}, {bear_ci[1]:.3f}]{'':>10} {bear_sig:<15}\")\n",
    "    \n",
    "    # Segment-based insights\n",
    "    if bear_segments:\n",
    "        bear_wins = sum(1 for s in bear_segments if s.excess_total_return > 0)\n",
    "        bear_total = len(bear_segments)\n",
    "        print(f\"\\n  Bear market segment win rate: {bear_wins}/{bear_total} ({bear_wins/bear_total*100:.1f}%)\")\n",
    "        \n",
    "        worst_bear_strat = min(s.strat_total_return for s in bear_segments)\n",
    "        worst_bear_spy = min(s.spy_total_return for s in bear_segments)\n",
    "        print(f\"  Worst bear segment: Strategy {worst_bear_strat*100:.1f}% vs SPY {worst_bear_spy*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" INTERPRETATION NOTES:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"\"\"\n",
    "  1. OVERALL IR: Tests whether strategy has risk-adjusted alpha vs SPY across\n",
    "     the full time period. This is the most reliable test.\n",
    "  \n",
    "  2. REGIME IRs: These test conditional performance, but interpretation requires\n",
    "     care - the bootstrap resamples the full series, so regime proportions may\n",
    "     vary across samples.\n",
    "  \n",
    "  3. SEGMENT ANALYSIS: Shows actual performance in each contiguous bear/bull\n",
    "     market. This is the most intuitive way to see \"what happened in 2008\" etc.\n",
    "  \n",
    "  4. If you trade based on the regime signal, enable LAG_REGIME=True to avoid\n",
    "     look-ahead bias in this analysis.\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete.\")\n",
    "    \n",
    "# =========================\n",
    "# SECTION 6: AUTOCORRELATION ANALYSIS\n",
    "# =========================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" SECTION 6: AUTOCORRELATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n  Testing whether returns exhibit serial dependence (momentum or mean-reversion).\")\n",
    "\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "# --- 6.1 Autocorrelation at different lags ---\n",
    "max_lags = 10\n",
    "strat_autocorrs = [pd.Series(strat_ret).autocorr(lag=i) for i in range(1, max_lags + 1)]\n",
    "spy_autocorrs = [pd.Series(spy_ret).autocorr(lag=i) for i in range(1, max_lags + 1)]\n",
    "excess_autocorrs = [pd.Series(excess_ret).autocorr(lag=i) for i in range(1, max_lags + 1)]\n",
    "\n",
    "# Significance threshold (approximate 95% CI for white noise)\n",
    "sig_threshold = 2 / np.sqrt(len(strat_ret))\n",
    "\n",
    "print(f\"\\n  Autocorrelation by Lag (significance threshold: ±{sig_threshold:.4f})\")\n",
    "print(f\"  {'-'*70}\")\n",
    "print(f\"  {'Lag':<6} {'Strategy':>12} {'SPY':>12} {'Excess':>12} {'Significant?':>18}\")\n",
    "print(f\"  {'-'*70}\")\n",
    "\n",
    "for i, (s_ac, p_ac, e_ac) in enumerate(zip(strat_autocorrs, spy_autocorrs, excess_autocorrs), 1):\n",
    "    sig_flags = []\n",
    "    if abs(s_ac) > sig_threshold:\n",
    "        sig_flags.append(\"Strat\")\n",
    "    if abs(p_ac) > sig_threshold:\n",
    "        sig_flags.append(\"SPY\")\n",
    "    if abs(e_ac) > sig_threshold:\n",
    "        sig_flags.append(\"Excess\")\n",
    "    sig_str = \", \".join(sig_flags) if sig_flags else \"-\"\n",
    "    print(f\"  {i:<6} {s_ac:>+12.4f} {p_ac:>+12.4f} {e_ac:>+12.4f} {sig_str:>18}\")\n",
    "\n",
    "# --- 6.2 Ljung-Box Test ---\n",
    "print(f\"\\n  Ljung-Box Test (H0: no autocorrelation up to lag k)\")\n",
    "print(f\"  {'-'*70}\")\n",
    "\n",
    "try:\n",
    "    from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "    \n",
    "    lb_lags = [5, 10, 20]\n",
    "    \n",
    "    print(f\"  {'Series':<15} {'Lag':<8} {'LB Stat':<12} {'p-value':<12} {'Significant?':<15}\")\n",
    "    print(f\"  {'-'*70}\")\n",
    "    \n",
    "    for series_name, series_data in [(\"Strategy\", strat_ret), (\"SPY\", spy_ret), (\"Excess\", excess_ret)]:\n",
    "        lb_results = acorr_ljungbox(series_data, lags=lb_lags, return_df=True)\n",
    "        for lag in lb_lags:\n",
    "            lb_stat = lb_results.loc[lag, \"lb_stat\"]\n",
    "            lb_pval = lb_results.loc[lag, \"lb_pvalue\"]\n",
    "            sig = \"YES **\" if lb_pval < 0.05 else \"No\"\n",
    "            print(f\"  {series_name:<15} {lag:<8} {lb_stat:<12.2f} {lb_pval:<12.4f} {sig:<15}\")\n",
    "        print(f\"  {'-'*70}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"  [statsmodels not available - skipping Ljung-Box test]\")\n",
    "\n",
    "# --- 6.3 Durbin-Watson Statistic ---\n",
    "print(f\"\\n  Durbin-Watson Statistic\")\n",
    "print(f\"  {'-'*70}\")\n",
    "print(f\"  Interpretation: ~2.0 = no autocorrelation, <2.0 = positive, >2.0 = negative\")\n",
    "print(f\"  \")\n",
    "\n",
    "try:\n",
    "    from statsmodels.stats.stattools import durbin_watson\n",
    "    \n",
    "    dw_strat = durbin_watson(strat_ret)\n",
    "    dw_spy = durbin_watson(spy_ret)\n",
    "    dw_excess = durbin_watson(excess_ret)\n",
    "    \n",
    "    def interpret_dw(dw):\n",
    "        if dw < 1.5:\n",
    "            return \"Positive autocorr\"\n",
    "        elif dw > 2.5:\n",
    "            return \"Negative autocorr\"\n",
    "        else:\n",
    "            return \"No strong autocorr\"\n",
    "    \n",
    "    print(f\"  {'Series':<15} {'DW Stat':<12} {'Interpretation':<25}\")\n",
    "    print(f\"  {'-'*55}\")\n",
    "    print(f\"  {'Strategy':<15} {dw_strat:<12.4f} {interpret_dw(dw_strat):<25}\")\n",
    "    print(f\"  {'SPY':<15} {dw_spy:<12.4f} {interpret_dw(dw_spy):<25}\")\n",
    "    print(f\"  {'Excess':<15} {dw_excess:<12.4f} {interpret_dw(dw_excess):<25}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"  [statsmodels not available - skipping Durbin-Watson test]\")\n",
    "\n",
    "# --- 6.4 Runs Test (Non-parametric) ---\n",
    "print(f\"\\n  Runs Test (H0: sequence of +/- returns is random)\")\n",
    "print(f\"  {'-'*70}\")\n",
    "\n",
    "def runs_test(series):\n",
    "    \"\"\"Test if sequence of +/- returns is random.\"\"\"\n",
    "    signs = np.sign(series)\n",
    "    signs = signs[signs != 0]  # Remove zeros\n",
    "    \n",
    "    if len(signs) < 10:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    n_pos = int((signs > 0).sum())\n",
    "    n_neg = int((signs < 0).sum())\n",
    "    n = len(signs)\n",
    "    \n",
    "    # Count runs\n",
    "    runs = 1\n",
    "    for i in range(1, len(signs)):\n",
    "        if signs[i] != signs[i-1]:\n",
    "            runs += 1\n",
    "    \n",
    "    # Expected runs and std under null (use float64 to avoid overflow)\n",
    "    n_pos_f = float(n_pos)\n",
    "    n_neg_f = float(n_neg)\n",
    "    n_f = float(n)\n",
    "    \n",
    "    expected_runs = (2.0 * n_pos_f * n_neg_f) / n_f + 1.0\n",
    "    \n",
    "    numerator = 2.0 * n_pos_f * n_neg_f * (2.0 * n_pos_f * n_neg_f - n_f)\n",
    "    denominator = (n_f ** 2) * (n_f - 1.0)\n",
    "    \n",
    "    if denominator <= 0 or numerator < 0:\n",
    "        return runs, expected_runs, np.nan, np.nan\n",
    "    \n",
    "    var_runs = numerator / denominator\n",
    "    \n",
    "    if var_runs <= 0:\n",
    "        return runs, expected_runs, np.nan, np.nan\n",
    "        \n",
    "    std_runs = np.sqrt(var_runs)\n",
    "    z_stat = (float(runs) - expected_runs) / std_runs\n",
    "    p_value = 2.0 * (1.0 - scipy_stats.norm.cdf(abs(z_stat)))\n",
    "    \n",
    "    return runs, expected_runs, z_stat, p_value\n",
    "\n",
    "print(f\"  {'Series':<15} {'Actual Runs':<12} {'Expected':<12} {'Z-stat':<12} {'p-value':<12} {'Random?':<15}\")\n",
    "print(f\"  {'-'*80}\")\n",
    "\n",
    "for series_name, series_data in [(\"Strategy\", strat_ret), (\"SPY\", spy_ret), (\"Excess\", excess_ret)]:\n",
    "    runs, expected, z, p = runs_test(series_data)\n",
    "    if np.isnan(p):\n",
    "        random_str = \"N/A\"\n",
    "    elif p < 0.05:\n",
    "        random_str = \"NO **\"\n",
    "    else:\n",
    "        random_str = \"Yes\"\n",
    "    \n",
    "    print(f\"  {series_name:<15} {runs:<12.0f} {expected:<12.1f} {z:<12.2f} {p:<12.4f} {random_str:<15}\")\n",
    "\n",
    "# --- 6.5 Autocorrelation Summary ---\n",
    "print(f\"\\n  {'-'*70}\")\n",
    "print(f\"  AUTOCORRELATION SUMMARY\")\n",
    "print(f\"  {'-'*70}\")\n",
    "\n",
    "lag1_strat = strat_autocorrs[0]\n",
    "lag1_excess = excess_autocorrs[0]\n",
    "\n",
    "# Strategy interpretation\n",
    "if abs(lag1_strat) < sig_threshold:\n",
    "    strat_interp = \"Strategy returns show NO significant lag-1 autocorrelation.\"\n",
    "elif lag1_strat > 0:\n",
    "    strat_interp = f\"Strategy returns show POSITIVE lag-1 autocorrelation ({lag1_strat:+.4f}) - momentum/trending.\"\n",
    "else:\n",
    "    strat_interp = f\"Strategy returns show NEGATIVE lag-1 autocorrelation ({lag1_strat:+.4f}) - mean reversion.\"\n",
    "\n",
    "# Excess interpretation  \n",
    "if abs(lag1_excess) < sig_threshold:\n",
    "    excess_interp = \"Excess returns show NO significant lag-1 autocorrelation.\"\n",
    "elif lag1_excess > 0:\n",
    "    excess_interp = f\"Excess returns show POSITIVE lag-1 autocorrelation ({lag1_excess:+.4f}) - alpha persists.\"\n",
    "else:\n",
    "    excess_interp = f\"Excess returns show NEGATIVE lag-1 autocorrelation ({lag1_excess:+.4f}) - alpha mean-reverts.\"\n",
    "\n",
    "print(f\"\\n  • {strat_interp}\")\n",
    "print(f\"  • {excess_interp}\")\n",
    "\n",
    "# Trading implications\n",
    "print(f\"\\n  Trading Implications:\")\n",
    "if lag1_strat > sig_threshold:\n",
    "    print(f\"    - Positive autocorrelation suggests winners tend to follow winners.\")\n",
    "    print(f\"    - Consider holding winning positions longer or adding to winners.\")\n",
    "elif lag1_strat < -sig_threshold:\n",
    "    print(f\"    - Negative autocorrelation suggests mean reversion behavior.\")\n",
    "    print(f\"    - Consider taking profits more quickly after strong moves.\")\n",
    "else:\n",
    "    print(f\"    - No significant autocorrelation - each day appears independent.\")\n",
    "    print(f\"    - Focus on position sizing rather than timing adjustments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417349ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      " REGIME CONFIRMATION ANALYSIS: TESTING DIFFERENT CONFIRMATION PERIODS\n",
      "==========================================================================================\n",
      "\n",
      "Data range: 1999-01-04 to 2025-12-30\n",
      "Total days: 6,790\n",
      "\n",
      "Testing confirmation periods: [1, 3, 5, 10, 15, 21]\n",
      "\n",
      "A confirmation period of N means the SPY must stay above/below the 200 DMA\n",
      "for N consecutive days before the regime officially changes.\n",
      "\n",
      "==========================================================================================\n",
      " SUMMARY: REGIME METRICS BY CONFIRMATION PERIOD\n",
      "==========================================================================================\n",
      "\n",
      "Confirm  Bull   Bear   Bull   Bear   Overall  Bull     Bear     Bear Seg   Bull Seg  \n",
      "Days     Days   Days   Segs   Segs   IR       IR       IR       Win %      Win %     \n",
      "------------------------------------------------------------------------------------------\n",
      "1        5057   1733   94     93     0.353    0.115    0.718    82.8     % 27.7     %\n",
      "3        5070   1720   37     36     0.353    0.723    -0.022   27.8     % 78.4     %\n",
      "5        5065   1725   24     23     0.353    0.720    -0.019   21.7     % 87.5     %\n",
      "10       5133   1657   15     14     0.353    0.692    -0.024   35.7     % 93.3     %\n",
      "15       5214   1576   14     13     0.353    0.748    -0.168   30.8     % 92.9     %\n",
      "21       5175   1615   10     9      0.353    0.628    -0.004   22.2     % 80.0     %\n",
      "\n",
      "==========================================================================================\n",
      " DETAILED COMPARISON: 1-DAY vs 5-DAY CONFIRMATION\n",
      "==========================================================================================\n",
      "\n",
      "--- 1-Day Confirmation ---\n",
      "  Regime segments: 94 bull, 93 bear\n",
      "  Days in bear: 1,733 (25.5%)\n",
      "  \n",
      "  Overall IR: 0.353\n",
      "  Bull IR:    0.115\n",
      "  Bear IR:    0.718\n",
      "  \n",
      "  Bear segment win rate: 82.8%\n",
      "  Bull segment win rate: 27.7%\n",
      "  Bear segment avg excess: 1.63%\n",
      "  Bull segment avg excess: 0.61%\n",
      "\n",
      "--- 5-Day Confirmation ---\n",
      "  Regime segments: 24 bull, 23 bear\n",
      "  Days in bear: 1,725 (25.4%)\n",
      "  \n",
      "  Overall IR: 0.353\n",
      "  Bull IR:    0.720\n",
      "  Bear IR:    -0.019\n",
      "  \n",
      "  Bear segment win rate: 21.7%\n",
      "  Bull segment win rate: 87.5%\n",
      "  Bear segment avg excess: 0.50%\n",
      "  Bull segment avg excess: 8.94%\n",
      "\n",
      "==========================================================================================\n",
      " BOOTSTRAP SIGNIFICANCE TESTS (1-Day vs 5-Day vs 10-Day)\n",
      "==========================================================================================\n",
      "\n",
      "--- 1-Day Confirmation ---\n",
      "  Overall  IR: 0.354  95% CI: [0.016, 0.695]  p=0.0400 **\n",
      "  Bull     IR: 0.124  95% CI: [-0.354, 0.573]  p=0.6190 \n",
      "  Bear     IR: 0.713  95% CI: [0.103, 1.338]  p=0.0190 **\n",
      "\n",
      "--- 5-Day Confirmation ---\n",
      "  Overall  IR: 0.354  95% CI: [0.016, 0.695]  p=0.0400 **\n",
      "  Bull     IR: 0.724  95% CI: [0.266, 1.174]  p=0.0010 **\n",
      "  Bear     IR: -0.024  95% CI: [-0.677, 0.584]  p=0.9380 \n",
      "\n",
      "--- 10-Day Confirmation ---\n",
      "  Overall  IR: 0.354  95% CI: [0.016, 0.695]  p=0.0400 **\n",
      "  Bull     IR: 0.698  95% CI: [0.249, 1.132]  p=0.0010 **\n",
      "  Bear     IR: -0.030  95% CI: [-0.695, 0.603]  p=0.9050 \n",
      "\n",
      "==========================================================================================\n",
      " BEAR MARKET SEGMENTS WITH 5-DAY CONFIRMATION\n",
      "==========================================================================================\n",
      "\n",
      "  Found 23 bear market segments (vs 93 with 1-day confirmation)\n",
      "\n",
      "  #    Start        End          Days   Strat Tot    SPY Tot      Excess      \n",
      "  ---- ------------ ------------ ------ ------------ ------------ ------------\n",
      "  1    1999-09-29   1999-10-07   7            2.65%       2.75%      -0.10%\n",
      "  2    1999-10-19   1999-11-02   11           6.07%       7.01%      -0.94%\n",
      "  3    2000-10-05   2002-03-07   353         -1.81%     -17.63%      15.82%\n",
      "  4    2002-04-09   2003-04-17   260          0.64%     -19.34%      19.98%\n",
      "  5    2004-07-27   2004-09-03   29           0.60%       3.10%      -2.50%\n",
      "  6    2004-10-25   2004-11-01   6            1.89%       3.20%      -1.31%\n",
      "  7    2005-10-14   2005-11-02   14           4.67%       3.68%       0.99%\n",
      "  8    2006-06-22   2006-07-05   9            0.58%       1.65%      -1.06%\n",
      "  9    2007-11-21   2007-12-10   13           3.83%       5.14%      -1.31%\n",
      "  10   2007-12-20   2009-06-03   365         -2.07%     -33.44%      31.37%\n",
      "  11   2010-05-26   2010-06-18   17          -0.68%       4.12%      -4.80%\n",
      "  12   2010-06-28   2010-08-05   28          -1.15%       4.62%      -5.77%\n",
      "  13   2010-08-17   2010-09-15   21           1.38%       4.45%      -3.07%\n",
      "  14   2011-08-08   2011-12-28   100          0.06%       5.16%      -5.09%\n",
      "  15   2014-10-17   2014-10-23   5            1.71%       4.65%      -2.94%\n",
      "  16   2015-08-26   2015-10-27   44           4.64%      10.90%      -6.26%\n",
      "  17   2016-01-07   2016-03-16   48          -4.46%       2.27%      -6.74%\n",
      "  18   2018-10-29   2019-02-15   75           2.27%       5.15%      -2.88%\n",
      "  19   2020-03-11   2020-05-29   56          -1.00%       6.13%      -7.13%\n",
      "  20   2022-02-24   2022-03-23   20           2.71%       5.51%      -2.79%\n",
      "  21   2022-04-18   2023-01-25   195         -2.48%      -7.36%       4.87%\n",
      "  22   2023-10-31   2023-11-06   5            2.63%       4.84%      -2.21%\n",
      "  23   2025-03-14   2025-05-15   44           2.87%       7.40%      -4.53%\n",
      "\n",
      "  Summary:\n",
      "    Strategy beat SPY in 5/23 bear segments (21.7%)\n",
      "    Mean excess return: 0.50%\n",
      "    Median excess return: -2.50%\n",
      "\n",
      "==========================================================================================\n",
      " RECOMMENDATIONS\n",
      "==========================================================================================\n",
      "\n",
      "  Based on the analysis:\n",
      "\n",
      "  1. NOISE REDUCTION: A 5-day confirmation reduces bear segments from 93 to ~20-30,\n",
      "     filtering out the 1-3 day noise around the 200 DMA crossovers.\n",
      "\n",
      "  2. STATISTICAL POWER: The IR estimates become more stable with fewer, longer\n",
      "     segments. However, significance levels may change.\n",
      "\n",
      "  3. TRADE-OFF: Longer confirmation periods:\n",
      "     - PRO: Fewer whipsaw signals, cleaner regime classification\n",
      "     - CON: Delayed regime detection (you're 5+ days late to recognize the shift)\n",
      "     - CON: Fewer bear days to analyze, potentially less statistical power\n",
      "\n",
      "  4. PRACTICAL USE: If you're using this regime signal for trading decisions,\n",
      "     a 5-10 day confirmation is reasonable. If it's just for performance\n",
      "     attribution, 1-day is fine (with the caveat about choppy periods).\n",
      "\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Regime Confirmation Analysis: Testing Different Confirmation Periods\n",
    "\n",
    "This script tests how the strategy performs under different regime confirmation\n",
    "thresholds. Instead of flipping regime on each day SPY crosses the 200 DMA,\n",
    "we require N consecutive days above/below before confirming a regime change.\n",
    "\n",
    "This reduces whipsaw signals and creates cleaner bull/bear classifications.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "EQUITY_FILE = \"./13-trading_output_regression_insp500_spyfilter_cap15/13-equity_curve_regression_insp500_spyfilter_cap15.parquet\"\n",
    "SPY_PARQUET = \"./8-SPY_200DMA_market_regime/8-SPY_200DMA_regime.parquet\"\n",
    "\n",
    "# Confirmation periods to test\n",
    "CONFIRMATION_DAYS = [1, 3, 5, 10, 15, 21]\n",
    "\n",
    "N_BOOT = 2000  # Reduced for speed since we're testing multiple thresholds\n",
    "BLOCK_LEN = 21\n",
    "SEED = 7\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def ann_sharpe(r: np.ndarray) -> float:\n",
    "    \"\"\"Annualized Sharpe ratio.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 2:\n",
    "        return np.nan\n",
    "    sd = r.std(ddof=1)\n",
    "    if sd <= 0 or np.isnan(sd):\n",
    "        return 0.0\n",
    "    return np.sqrt(TRADING_DAYS) * r.mean() / sd\n",
    "\n",
    "\n",
    "def ann_return(r: np.ndarray) -> float:\n",
    "    \"\"\"Annualized return from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 2:\n",
    "        return np.nan\n",
    "    total = np.prod(1 + r) - 1\n",
    "    years = r.size / TRADING_DAYS\n",
    "    if years <= 0:\n",
    "        return np.nan\n",
    "    return (1 + total) ** (1 / years) - 1\n",
    "\n",
    "\n",
    "def total_return(r: np.ndarray) -> float:\n",
    "    \"\"\"Total cumulative return.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 1:\n",
    "        return np.nan\n",
    "    return np.prod(1 + r) - 1\n",
    "\n",
    "\n",
    "def max_drawdown(r: np.ndarray) -> float:\n",
    "    \"\"\"Maximum drawdown from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 1:\n",
    "        return np.nan\n",
    "    cum = np.cumprod(1 + r)\n",
    "    running_max = np.maximum.accumulate(cum)\n",
    "    dd = (cum - running_max) / running_max\n",
    "    return dd.min()\n",
    "\n",
    "\n",
    "def create_confirmed_regime(raw_regime: np.ndarray, confirm_days: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a confirmed regime signal that requires N consecutive days\n",
    "    above/below the 200 DMA before flipping the regime.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_regime : array of 0/1 (0 = below 200 DMA, 1 = above 200 DMA)\n",
    "    confirm_days : number of consecutive days required to confirm regime change\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    confirmed_regime : array of 0/1 with smoothed regime signal\n",
    "    \"\"\"\n",
    "    if confirm_days <= 1:\n",
    "        return raw_regime.copy()\n",
    "    \n",
    "    n = len(raw_regime)\n",
    "    confirmed = np.zeros(n, dtype=int)\n",
    "    \n",
    "    # Start with the initial regime (use first value)\n",
    "    current_regime = raw_regime[0]\n",
    "    consecutive_count = 1\n",
    "    \n",
    "    for i in range(n):\n",
    "        if raw_regime[i] == current_regime:\n",
    "            # Same as current confirmed regime\n",
    "            consecutive_count = 0  # Reset counter for opposite regime\n",
    "            confirmed[i] = current_regime\n",
    "        else:\n",
    "            # Different from current confirmed regime\n",
    "            # Check how many consecutive days we've been in the new regime\n",
    "            consecutive_count += 1\n",
    "            \n",
    "            if consecutive_count >= confirm_days:\n",
    "                # Confirm the regime change\n",
    "                current_regime = raw_regime[i]\n",
    "                consecutive_count = 0\n",
    "            \n",
    "            confirmed[i] = current_regime\n",
    "    \n",
    "    return confirmed\n",
    "\n",
    "\n",
    "def find_contiguous_segments(regime: np.ndarray) -> List[Tuple[int, int, int]]:\n",
    "    \"\"\"Find contiguous segments of the same regime.\"\"\"\n",
    "    segments = []\n",
    "    if len(regime) == 0:\n",
    "        return segments\n",
    "    \n",
    "    start_idx = 0\n",
    "    current_regime = regime[0]\n",
    "    \n",
    "    for i in range(1, len(regime)):\n",
    "        if regime[i] != current_regime:\n",
    "            segments.append((start_idx, i - 1, int(current_regime)))\n",
    "            start_idx = i\n",
    "            current_regime = regime[i]\n",
    "    \n",
    "    segments.append((start_idx, len(regime) - 1, int(current_regime)))\n",
    "    \n",
    "    return segments\n",
    "\n",
    "\n",
    "def compute_regime_metrics(\n",
    "    df: pd.DataFrame, \n",
    "    regime_col: str = \"regime\"\n",
    ") -> Dict:\n",
    "    \"\"\"Compute comprehensive metrics for a given regime column.\"\"\"\n",
    "    \n",
    "    strat_ret = df[\"strat_ret\"].to_numpy()\n",
    "    spy_ret = df[\"spy_ret\"].to_numpy()\n",
    "    excess_ret = strat_ret - spy_ret\n",
    "    regime = df[regime_col].to_numpy()\n",
    "    \n",
    "    bull_mask = regime == 1\n",
    "    bear_mask = regime == 0\n",
    "    \n",
    "    # Find segments\n",
    "    segments = find_contiguous_segments(regime)\n",
    "    bull_segments = [(s, e) for s, e, r in segments if r == 1]\n",
    "    bear_segments = [(s, e) for s, e, r in segments if r == 0]\n",
    "    \n",
    "    # Compute segment-level stats for bear markets\n",
    "    bear_wins = 0\n",
    "    bear_excess_returns = []\n",
    "    for start, end in bear_segments:\n",
    "        seg_strat = total_return(strat_ret[start:end+1])\n",
    "        seg_spy = total_return(spy_ret[start:end+1])\n",
    "        seg_excess = seg_strat - seg_spy\n",
    "        bear_excess_returns.append(seg_excess)\n",
    "        if seg_excess > 0:\n",
    "            bear_wins += 1\n",
    "    \n",
    "    # Bull segment stats\n",
    "    bull_wins = 0\n",
    "    bull_excess_returns = []\n",
    "    for start, end in bull_segments:\n",
    "        seg_strat = total_return(strat_ret[start:end+1])\n",
    "        seg_spy = total_return(spy_ret[start:end+1])\n",
    "        seg_excess = seg_strat - seg_spy\n",
    "        bull_excess_returns.append(seg_excess)\n",
    "        if seg_excess > 0:\n",
    "            bull_wins += 1\n",
    "    \n",
    "    return {\n",
    "        # Counts\n",
    "        \"n_bull_days\": bull_mask.sum(),\n",
    "        \"n_bear_days\": bear_mask.sum(),\n",
    "        \"n_bull_segments\": len(bull_segments),\n",
    "        \"n_bear_segments\": len(bear_segments),\n",
    "        \n",
    "        # Overall\n",
    "        \"overall_ir\": ann_sharpe(excess_ret),\n",
    "        \"overall_excess_return\": ann_return(excess_ret),\n",
    "        \n",
    "        # Bull conditional\n",
    "        \"bull_ir\": ann_sharpe(excess_ret[bull_mask]) if bull_mask.sum() > 1 else np.nan,\n",
    "        \"bull_excess_return\": ann_return(excess_ret[bull_mask]) if bull_mask.sum() > 1 else np.nan,\n",
    "        \"bull_strat_sharpe\": ann_sharpe(strat_ret[bull_mask]) if bull_mask.sum() > 1 else np.nan,\n",
    "        \"bull_spy_sharpe\": ann_sharpe(spy_ret[bull_mask]) if bull_mask.sum() > 1 else np.nan,\n",
    "        \n",
    "        # Bear conditional\n",
    "        \"bear_ir\": ann_sharpe(excess_ret[bear_mask]) if bear_mask.sum() > 1 else np.nan,\n",
    "        \"bear_excess_return\": ann_return(excess_ret[bear_mask]) if bear_mask.sum() > 1 else np.nan,\n",
    "        \"bear_strat_sharpe\": ann_sharpe(strat_ret[bear_mask]) if bear_mask.sum() > 1 else np.nan,\n",
    "        \"bear_spy_sharpe\": ann_sharpe(spy_ret[bear_mask]) if bear_mask.sum() > 1 else np.nan,\n",
    "        \n",
    "        # Segment-level\n",
    "        \"bear_segment_win_rate\": bear_wins / len(bear_segments) if bear_segments else np.nan,\n",
    "        \"bull_segment_win_rate\": bull_wins / len(bull_segments) if bull_segments else np.nan,\n",
    "        \"bear_segment_excess_mean\": np.mean(bear_excess_returns) if bear_excess_returns else np.nan,\n",
    "        \"bull_segment_excess_mean\": np.mean(bull_excess_returns) if bull_excess_returns else np.nan,\n",
    "    }\n",
    "\n",
    "\n",
    "def block_bootstrap_idx(n: int, block_len: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Block bootstrap indices.\"\"\"\n",
    "    if n <= 0:\n",
    "        return np.array([], dtype=int)\n",
    "    if block_len <= 1 or block_len > n:\n",
    "        return rng.integers(0, n, size=n, dtype=int)\n",
    "    \n",
    "    idx = []\n",
    "    max_start = n - block_len\n",
    "    while len(idx) < n:\n",
    "        s = int(rng.integers(0, max_start + 1))\n",
    "        idx.extend(range(s, s + block_len))\n",
    "    return np.array(idx[:n], dtype=int)\n",
    "\n",
    "\n",
    "def bootstrap_ir(\n",
    "    strat_ret: np.ndarray,\n",
    "    spy_ret: np.ndarray,\n",
    "    regime: np.ndarray,\n",
    "    n_boot: int,\n",
    "    block_len: int,\n",
    "    seed: int\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Bootstrap IR distributions for overall, bull, and bear.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(strat_ret)\n",
    "    \n",
    "    results = {\n",
    "        \"overall_ir\": np.empty(n_boot, dtype=float),\n",
    "        \"bull_ir\": np.empty(n_boot, dtype=float),\n",
    "        \"bear_ir\": np.empty(n_boot, dtype=float),\n",
    "    }\n",
    "    \n",
    "    for i in range(n_boot):\n",
    "        idx = block_bootstrap_idx(n, block_len, rng)\n",
    "        s_boot = strat_ret[idx]\n",
    "        p_boot = spy_ret[idx]\n",
    "        r_boot = regime[idx]\n",
    "        excess = s_boot - p_boot\n",
    "        \n",
    "        results[\"overall_ir\"][i] = ann_sharpe(excess)\n",
    "        \n",
    "        bull_mask = r_boot == 1\n",
    "        bear_mask = r_boot == 0\n",
    "        \n",
    "        results[\"bull_ir\"][i] = ann_sharpe(excess[bull_mask]) if bull_mask.sum() > 1 else np.nan\n",
    "        results[\"bear_ir\"][i] = ann_sharpe(excess[bear_mask]) if bear_mask.sum() > 1 else np.nan\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN ANALYSIS\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Load data ---\n",
    "    eq = pd.read_parquet(EQUITY_FILE).copy()\n",
    "    if \"date\" not in eq.columns and eq.index.name == \"date\":\n",
    "        eq = eq.reset_index()\n",
    "    elif \"date\" not in eq.columns and \"Date\" in eq.columns:\n",
    "        eq = eq.rename(columns={\"Date\": \"date\"})\n",
    "    eq[\"date\"] = pd.to_datetime(eq[\"date\"])\n",
    "    eq = eq.sort_values(\"date\").drop_duplicates(\"date\")\n",
    "    eq[\"strat_ret\"] = eq[\"portfolio_value\"].pct_change().fillna(0.0)\n",
    "\n",
    "    spy = pd.read_parquet(SPY_PARQUET).copy()\n",
    "    spy = spy.reset_index().rename(columns={\"Date\": \"date\", \"index\": \"date\"})\n",
    "    spy[\"date\"] = pd.to_datetime(spy[\"date\"])\n",
    "    spy = spy.sort_values(\"date\")\n",
    "    spy[\"spy_ret\"] = spy[\"spy_close\"].pct_change().fillna(0.0)\n",
    "\n",
    "    # Align\n",
    "    df = eq.merge(spy[[\"date\", \"spy_ret\", \"market_regime\"]], on=\"date\", how=\"inner\").dropna()\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    \n",
    "    raw_regime = df[\"market_regime\"].to_numpy()\n",
    "\n",
    "    print(\"=\" * 90)\n",
    "    print(\" REGIME CONFIRMATION ANALYSIS: TESTING DIFFERENT CONFIRMATION PERIODS\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"\\nData range: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Total days: {len(df):,}\")\n",
    "    print(f\"\\nTesting confirmation periods: {CONFIRMATION_DAYS}\")\n",
    "    print(\"\\nA confirmation period of N means the SPY must stay above/below the 200 DMA\")\n",
    "    print(\"for N consecutive days before the regime officially changes.\")\n",
    "\n",
    "    # =========================\n",
    "    # SUMMARY TABLE\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\" SUMMARY: REGIME METRICS BY CONFIRMATION PERIOD\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    header = (\n",
    "        f\"{'Confirm':<8} \"\n",
    "        f\"{'Bull':<6} {'Bear':<6} \"\n",
    "        f\"{'Bull':<6} {'Bear':<6} \"\n",
    "        f\"{'Overall':<8} \"\n",
    "        f\"{'Bull':<8} {'Bear':<8} \"\n",
    "        f\"{'Bear Seg':<10} {'Bull Seg':<10}\"\n",
    "    )\n",
    "    subheader = (\n",
    "        f\"{'Days':<8} \"\n",
    "        f\"{'Days':<6} {'Days':<6} \"\n",
    "        f\"{'Segs':<6} {'Segs':<6} \"\n",
    "        f\"{'IR':<8} \"\n",
    "        f\"{'IR':<8} {'IR':<8} \"\n",
    "        f\"{'Win %':<10} {'Win %':<10}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{header}\")\n",
    "    print(f\"{subheader}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for confirm_days in CONFIRMATION_DAYS:\n",
    "        # Create confirmed regime\n",
    "        confirmed_regime = create_confirmed_regime(raw_regime, confirm_days)\n",
    "        df[f\"regime_{confirm_days}d\"] = confirmed_regime\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics = compute_regime_metrics(df, f\"regime_{confirm_days}d\")\n",
    "        all_results[confirm_days] = metrics\n",
    "        \n",
    "        print(\n",
    "            f\"{confirm_days:<8} \"\n",
    "            f\"{metrics['n_bull_days']:<6} {metrics['n_bear_days']:<6} \"\n",
    "            f\"{metrics['n_bull_segments']:<6} {metrics['n_bear_segments']:<6} \"\n",
    "            f\"{metrics['overall_ir']:<8.3f} \"\n",
    "            f\"{metrics['bull_ir']:<8.3f} {metrics['bear_ir']:<8.3f} \"\n",
    "            f\"{metrics['bear_segment_win_rate']*100:<9.1f}% {metrics['bull_segment_win_rate']*100:<9.1f}%\"\n",
    "        )\n",
    "\n",
    "    # =========================\n",
    "    # DETAILED COMPARISON\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\" DETAILED COMPARISON: 1-DAY vs 5-DAY CONFIRMATION\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    for confirm_days in [1, 5]:\n",
    "        metrics = all_results[confirm_days]\n",
    "        print(f\"\\n--- {confirm_days}-Day Confirmation ---\")\n",
    "        print(f\"  Regime segments: {metrics['n_bull_segments']} bull, {metrics['n_bear_segments']} bear\")\n",
    "        print(f\"  Days in bear: {metrics['n_bear_days']:,} ({metrics['n_bear_days']/len(df)*100:.1f}%)\")\n",
    "        print(f\"  \")\n",
    "        print(f\"  Overall IR: {metrics['overall_ir']:.3f}\")\n",
    "        print(f\"  Bull IR:    {metrics['bull_ir']:.3f}\")\n",
    "        print(f\"  Bear IR:    {metrics['bear_ir']:.3f}\")\n",
    "        print(f\"  \")\n",
    "        print(f\"  Bear segment win rate: {metrics['bear_segment_win_rate']*100:.1f}%\")\n",
    "        print(f\"  Bull segment win rate: {metrics['bull_segment_win_rate']*100:.1f}%\")\n",
    "        print(f\"  Bear segment avg excess: {metrics['bear_segment_excess_mean']*100:.2f}%\")\n",
    "        print(f\"  Bull segment avg excess: {metrics['bull_segment_excess_mean']*100:.2f}%\")\n",
    "\n",
    "    # =========================\n",
    "    # BOOTSTRAP FOR KEY THRESHOLDS\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\" BOOTSTRAP SIGNIFICANCE TESTS (1-Day vs 5-Day vs 10-Day)\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    key_thresholds = [1, 5, 10]\n",
    "    \n",
    "    for confirm_days in key_thresholds:\n",
    "        print(f\"\\n--- {confirm_days}-Day Confirmation ---\")\n",
    "        \n",
    "        confirmed_regime = create_confirmed_regime(raw_regime, confirm_days)\n",
    "        \n",
    "        boot_results = bootstrap_ir(\n",
    "            df[\"strat_ret\"].to_numpy(),\n",
    "            df[\"spy_ret\"].to_numpy(),\n",
    "            confirmed_regime,\n",
    "            N_BOOT,\n",
    "            BLOCK_LEN,\n",
    "            SEED\n",
    "        )\n",
    "        \n",
    "        for regime_name, key in [(\"Overall\", \"overall_ir\"), (\"Bull\", \"bull_ir\"), (\"Bear\", \"bear_ir\")]:\n",
    "            dist = boot_results[key]\n",
    "            dist = dist[~np.isnan(dist)]\n",
    "            \n",
    "            if len(dist) < 100:\n",
    "                print(f\"  {regime_name}: insufficient data\")\n",
    "                continue\n",
    "            \n",
    "            ci = np.percentile(dist, [2.5, 97.5])\n",
    "            p_two_sided = 2 * min(np.mean(dist <= 0), np.mean(dist >= 0))\n",
    "            sig = \"**\" if (ci[0] > 0 or ci[1] < 0) else \"\"\n",
    "            \n",
    "            print(f\"  {regime_name:<8} IR: {np.median(dist):.3f}  95% CI: [{ci[0]:.3f}, {ci[1]:.3f}]  p={p_two_sided:.4f} {sig}\")\n",
    "\n",
    "    # =========================\n",
    "    # BEAR MARKET SEGMENT DETAILS (5-Day Confirmation)\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\" BEAR MARKET SEGMENTS WITH 5-DAY CONFIRMATION\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    confirmed_5d = create_confirmed_regime(raw_regime, 5)\n",
    "    df[\"regime_5d\"] = confirmed_5d\n",
    "    \n",
    "    segments = find_contiguous_segments(confirmed_5d)\n",
    "    bear_segments = [(s, e) for s, e, r in segments if r == 0]\n",
    "    \n",
    "    print(f\"\\n  Found {len(bear_segments)} bear market segments (vs 93 with 1-day confirmation)\")\n",
    "    print(f\"\\n  {'#':<4} {'Start':<12} {'End':<12} {'Days':<6} {'Strat Tot':<12} {'SPY Tot':<12} {'Excess':<12}\")\n",
    "    print(f\"  {'-'*4} {'-'*12} {'-'*12} {'-'*6} {'-'*12} {'-'*12} {'-'*12}\")\n",
    "    \n",
    "    strat_ret = df[\"strat_ret\"].to_numpy()\n",
    "    spy_ret = df[\"spy_ret\"].to_numpy()\n",
    "    \n",
    "    for i, (start, end) in enumerate(bear_segments, 1):\n",
    "        n_days = end - start + 1\n",
    "        strat_tot = total_return(strat_ret[start:end+1])\n",
    "        spy_tot = total_return(spy_ret[start:end+1])\n",
    "        excess = strat_tot - spy_tot\n",
    "        \n",
    "        start_date = df.iloc[start][\"date\"].strftime(\"%Y-%m-%d\")\n",
    "        end_date = df.iloc[end][\"date\"].strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        print(\n",
    "            f\"  {i:<4} {start_date:<12} {end_date:<12} {n_days:<6} \"\n",
    "            f\"{strat_tot*100:>10.2f}% {spy_tot*100:>10.2f}% {excess*100:>10.2f}%\"\n",
    "        )\n",
    "    \n",
    "    # Summary\n",
    "    bear_excess = []\n",
    "    bear_wins = 0\n",
    "    for start, end in bear_segments:\n",
    "        strat_tot = total_return(strat_ret[start:end+1])\n",
    "        spy_tot = total_return(spy_ret[start:end+1])\n",
    "        excess = strat_tot - spy_tot\n",
    "        bear_excess.append(excess)\n",
    "        if excess > 0:\n",
    "            bear_wins += 1\n",
    "    \n",
    "    print(f\"\\n  Summary:\")\n",
    "    print(f\"    Strategy beat SPY in {bear_wins}/{len(bear_segments)} bear segments ({bear_wins/len(bear_segments)*100:.1f}%)\")\n",
    "    print(f\"    Mean excess return: {np.mean(bear_excess)*100:.2f}%\")\n",
    "    print(f\"    Median excess return: {np.median(bear_excess)*100:.2f}%\")\n",
    "\n",
    "    # =========================\n",
    "    # FINAL RECOMMENDATIONS\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\" RECOMMENDATIONS\")\n",
    "    print(\"=\" * 90)\n",
    "    print(\"\"\"\n",
    "  Based on the analysis:\n",
    "  \n",
    "  1. NOISE REDUCTION: A 5-day confirmation reduces bear segments from 93 to ~20-30,\n",
    "     filtering out the 1-3 day noise around the 200 DMA crossovers.\n",
    "  \n",
    "  2. STATISTICAL POWER: The IR estimates become more stable with fewer, longer\n",
    "     segments. However, significance levels may change.\n",
    "  \n",
    "  3. TRADE-OFF: Longer confirmation periods:\n",
    "     - PRO: Fewer whipsaw signals, cleaner regime classification\n",
    "     - CON: Delayed regime detection (you're 5+ days late to recognize the shift)\n",
    "     - CON: Fewer bear days to analyze, potentially less statistical power\n",
    "  \n",
    "  4. PRACTICAL USE: If you're using this regime signal for trading decisions,\n",
    "     a 5-10 day confirmation is reasonable. If it's just for performance\n",
    "     attribution, 1-day is fine (with the caveat about choppy periods).\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5a864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_quant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
