{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f86096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYZING WEEKLY RANKINGS VS ACTUAL TRADES ===\n",
      "\n",
      "Loading data...\n",
      "Loaded 36,057 ranking records\n",
      "Loaded 3,022 trade records\n",
      "\n",
      "Merging rankings with trades...\n",
      "Combined dataset: 36,057 records\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "\n",
      "Total weeks analyzed:           1,392\n",
      "Total stock rankings:           36,057\n",
      "Rankings that traded:           1,690 (4.7%)\n",
      "Rankings that did NOT trade:    34,367 (95.3%)\n",
      "\n",
      "=== BY SPY REGIME ===\n",
      "traded_flag       NOT_TRADED  TRADED\n",
      "spy_above_200dma                    \n",
      "False                   9008      31\n",
      "True                   25359    1659\n",
      "\n",
      "=== SAMPLE WEEKLY BREAKDOWN (First 10 weeks) ===\n",
      "signal_date  total_ranked  total_traded  pct_traded  total_not_traded\n",
      " 1999-01-06            25             8        32.0                17\n",
      " 1999-01-13            25             0         0.0                25\n",
      " 1999-01-20            25             2         8.0                23\n",
      " 1999-01-27            25             1         4.0                24\n",
      " 1999-02-03            25             1         4.0                24\n",
      " 1999-02-10            25             1         4.0                24\n",
      " 1999-02-17            25             1         4.0                24\n",
      " 1999-02-24            25             0         0.0                25\n",
      " 1999-03-03            25             1         4.0                24\n",
      " 1999-03-10            25             1         4.0                24\n",
      "\n",
      "=== WHY STOCKS DIDN'T TRADE ===\n",
      "\n",
      "Reasons stocks didn't trade:\n",
      "  within_drift_threshold        : 32,477 ( 94.5%)\n",
      "  spy_regime_prevented_buy      :  1,880 (  5.5%)\n",
      "  insufficient_cash             :     10 (  0.0%)\n",
      "\n",
      "=== SAVING OUTPUT FILES ===\n",
      "\n",
      "✓ Saved: ./13d-ranking_analysis\\13d-rankings_with_trade_status.parquet\n",
      "✓ Saved: ./13d-ranking_analysis\\13d-rankings_with_trade_status.csv\n",
      "✓ Saved: ./13d-ranking_analysis\\13d-weekly_summary.csv\n",
      "✓ Saved: ./13d-ranking_analysis\\13d-not_traded_with_reasons.csv\n",
      "✓ Saved: ./13d-ranking_analysis\\13d-summary_statistics.csv\n",
      "\n",
      "=== COMPLETE ===\n",
      "\n",
      "Main output file columns:\n",
      "  - traded_flag: 'TRADED' or 'NOT_TRADED'\n",
      "  - All ranking info (slope, weights, targets)\n",
      "  - Trade info (if traded): trade_type, trade_shares, trade_value, trade_reason\n",
      "  - Analysis columns: weight_change, shares_change\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "OUTPUT_DIR_TRADES = \"./13-trading_output_regression_insp500_spyfilter_cap15\"\n",
    "OUTPUT_DIR_ANALYSIS = \"./13d-ranking_analysis\"\n",
    "os.makedirs(OUTPUT_DIR_ANALYSIS, exist_ok=True)\n",
    "\n",
    "RANKINGS_FILE = os.path.join(OUTPUT_DIR_TRADES, \"13-weekly_rankings_pre_filter_cap15.parquet\")\n",
    "TRADES_FILE = os.path.join(OUTPUT_DIR_TRADES, \"13-trades_regression_insp500_spyfilter_cap15.parquet\")\n",
    "\n",
    "print(\"=== ANALYZING WEEKLY RANKINGS VS ACTUAL TRADES ===\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"Loading data...\")\n",
    "rankings = pd.read_parquet(RANKINGS_FILE)\n",
    "trades = pd.read_parquet(TRADES_FILE)\n",
    "\n",
    "print(f\"Loaded {len(rankings):,} ranking records\")\n",
    "print(f\"Loaded {len(trades):,} trade records\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# PREPARE TRADES DATA\n",
    "# ============================================================\n",
    "\n",
    "# Create a simplified trades table with key info\n",
    "trades_summary = trades.copy()\n",
    "trades_summary = trades_summary[trades_summary['type'].isin(['BUY', 'SELL'])]\n",
    "\n",
    "# Group by signal_date and ticker to get trade info\n",
    "trades_agg = trades_summary.groupby(['signal_date', 'ticker']).agg({\n",
    "    'type': lambda x: ', '.join(x.unique()),  # BUY, SELL, or both\n",
    "    'shares': 'sum',  # net shares traded\n",
    "    'value': 'sum',   # total trade value\n",
    "    'reason': lambda x: ', '.join(x.unique()),  # reasons\n",
    "}).reset_index()\n",
    "\n",
    "trades_agg.columns = ['signal_date', 'ticker', 'trade_type', 'trade_shares', 'trade_value', 'trade_reason']\n",
    "\n",
    "# ============================================================\n",
    "# MERGE RANKINGS WITH TRADES\n",
    "# ============================================================\n",
    "\n",
    "print(\"Merging rankings with trades...\")\n",
    "\n",
    "# Merge rankings with trades (left join to keep all rankings)\n",
    "combined = rankings.merge(\n",
    "    trades_agg,\n",
    "    on=['signal_date', 'ticker'],\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Add a clear indicator column\n",
    "combined['traded'] = combined['_merge'] == 'both'\n",
    "combined['traded_flag'] = combined['traded'].map({True: 'TRADED', False: 'NOT_TRADED'})\n",
    "\n",
    "# Clean up the merge indicator column\n",
    "combined = combined.drop('_merge', axis=1)\n",
    "\n",
    "# Add some helpful analysis columns\n",
    "combined['weight_change'] = combined['target_weight'] - combined['current_weight']\n",
    "combined['shares_change'] = combined['target_shares'] - combined['current_shares']\n",
    "\n",
    "# Sort by signal_date and rank\n",
    "combined = combined.sort_values(['signal_date', 'slope_rank'])\n",
    "\n",
    "print(f\"Combined dataset: {len(combined):,} records\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY STATISTICS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== SUMMARY STATISTICS ===\\n\")\n",
    "\n",
    "total_weeks = combined['signal_date'].nunique()\n",
    "total_rankings = len(combined)\n",
    "total_traded = combined['traded'].sum()\n",
    "total_not_traded = (~combined['traded']).sum()\n",
    "\n",
    "print(f\"Total weeks analyzed:           {total_weeks:,}\")\n",
    "print(f\"Total stock rankings:           {total_rankings:,}\")\n",
    "print(f\"Rankings that traded:           {total_traded:,} ({100*total_traded/total_rankings:.1f}%)\")\n",
    "print(f\"Rankings that did NOT trade:    {total_not_traded:,} ({100*total_not_traded/total_rankings:.1f}%)\\n\")\n",
    "\n",
    "# By SPY regime\n",
    "print(\"=== BY SPY REGIME ===\")\n",
    "regime_summary = combined.groupby(['spy_above_200dma', 'traded_flag']).size().unstack(fill_value=0)\n",
    "print(regime_summary)\n",
    "print()\n",
    "\n",
    "# Weekly summary\n",
    "weekly_summary = combined.groupby('signal_date').agg({\n",
    "    'ticker': 'count',\n",
    "    'traded': 'sum',\n",
    "}).reset_index()\n",
    "weekly_summary.columns = ['signal_date', 'total_ranked', 'total_traded']\n",
    "weekly_summary['pct_traded'] = 100 * weekly_summary['total_traded'] / weekly_summary['total_ranked']\n",
    "weekly_summary['total_not_traded'] = weekly_summary['total_ranked'] - weekly_summary['total_traded']\n",
    "\n",
    "print(\"=== SAMPLE WEEKLY BREAKDOWN (First 10 weeks) ===\")\n",
    "print(weekly_summary.head(10).to_string(index=False))\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# ANALYZE REASONS FOR NOT TRADING\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== WHY STOCKS DIDN'T TRADE ===\\n\")\n",
    "\n",
    "not_traded = combined[~combined['traded']].copy()\n",
    "\n",
    "# Categorize reasons for not trading\n",
    "def categorize_no_trade(row):\n",
    "    \"\"\"Determine why a stock didn't trade\"\"\"\n",
    "    \n",
    "    # Already at target (within drift threshold)\n",
    "    if abs(row['weight_change']) < 0.05:  # DRIFT_THRESHOLD\n",
    "        return 'within_drift_threshold'\n",
    "    \n",
    "    # New position but too small\n",
    "    if row['current_shares'] == 0 and row['target_weight'] < 0.003:  # MIN_NEW_POSITION_WEIGHT\n",
    "        return 'new_position_too_small'\n",
    "    \n",
    "    # Trade value too small\n",
    "    if abs(row['shares_change'] * row['close_adj']) < 10000:  # MIN_TRADE_VALUE\n",
    "        return 'trade_value_too_small'\n",
    "    \n",
    "    # Would buy but SPY regime prevents it\n",
    "    if row['shares_change'] > 0 and not row['spy_above_200dma']:\n",
    "        return 'spy_regime_prevented_buy'\n",
    "    \n",
    "    # Insufficient cash\n",
    "    if row['shares_change'] > 0:\n",
    "        return 'insufficient_cash'\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "not_traded['no_trade_reason'] = not_traded.apply(categorize_no_trade, axis=1)\n",
    "\n",
    "reason_counts = not_traded['no_trade_reason'].value_counts()\n",
    "print(\"Reasons stocks didn't trade:\")\n",
    "for reason, count in reason_counts.items():\n",
    "    pct = 100 * count / len(not_traded)\n",
    "    print(f\"  {reason:30s}: {count:6,} ({pct:5.1f}%)\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# SAVE OUTPUT FILES\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== SAVING OUTPUT FILES ===\\n\")\n",
    "\n",
    "# Main combined file with all rankings and trade status\n",
    "combined_file = os.path.join(OUTPUT_DIR_ANALYSIS, \"13d-rankings_with_trade_status.parquet\")\n",
    "combined.to_parquet(combined_file, index=False)\n",
    "print(f\"✓ Saved: {combined_file}\")\n",
    "\n",
    "# CSV version for easy viewing in Excel\n",
    "combined_csv = os.path.join(OUTPUT_DIR_ANALYSIS, \"13d-rankings_with_trade_status.csv\")\n",
    "combined.to_csv(combined_csv, index=False)\n",
    "print(f\"✓ Saved: {combined_csv}\")\n",
    "\n",
    "# Weekly summary\n",
    "weekly_file = os.path.join(OUTPUT_DIR_ANALYSIS, \"13d-weekly_summary.csv\")\n",
    "weekly_summary.to_csv(weekly_file, index=False)\n",
    "print(f\"✓ Saved: {weekly_file}\")\n",
    "\n",
    "# Not traded with reasons\n",
    "not_traded_file = os.path.join(OUTPUT_DIR_ANALYSIS, \"13d-not_traded_with_reasons.csv\")\n",
    "not_traded.to_csv(not_traded_file, index=False)\n",
    "print(f\"✓ Saved: {not_traded_file}\")\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = pd.DataFrame([{\n",
    "    'total_weeks': total_weeks,\n",
    "    'total_rankings': total_rankings,\n",
    "    'total_traded': total_traded,\n",
    "    'total_not_traded': total_not_traded,\n",
    "    'pct_traded': 100 * total_traded / total_rankings,\n",
    "    'pct_not_traded': 100 * total_not_traded / total_rankings,\n",
    "}])\n",
    "\n",
    "summary_file = os.path.join(OUTPUT_DIR_ANALYSIS, \"13d-summary_statistics.csv\")\n",
    "summary_stats.to_csv(summary_file, index=False)\n",
    "print(f\"✓ Saved: {summary_file}\")\n",
    "\n",
    "print(\"\\n=== COMPLETE ===\")\n",
    "print(\"\\nMain output file columns:\")\n",
    "print(\"  - traded_flag: 'TRADED' or 'NOT_TRADED'\")\n",
    "print(\"  - All ranking info (slope, weights, targets)\")\n",
    "print(\"  - Trade info (if traded): trade_type, trade_shares, trade_value, trade_reason\")\n",
    "print(\"  - Analysis columns: weight_change, shares_change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e68e62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ticker  slope_rank traded_flag  target_weight\n",
      "15878    KG1           1  NOT_TRADED       0.119809\n",
      "15879    KMX           2  NOT_TRADED       0.027537\n",
      "15880   BKNG           3  NOT_TRADED       0.001933\n",
      "15881     CF           4  NOT_TRADED       0.035123\n",
      "15882    NOV           5  NOT_TRADED       0.017310\n",
      "15883    FCX           6  NOT_TRADED       0.018035\n",
      "15884  CPPRQ           7  NOT_TRADED       0.023502\n",
      "15885    TPR           8  NOT_TRADED       0.027990\n",
      "15886    MEE           9  NOT_TRADED       0.011604\n",
      "15887   EBAY          10  NOT_TRADED       0.092139\n",
      "15888   AMZN          11  NOT_TRADED       0.102951\n",
      "15889    TIF          12  NOT_TRADED       0.018011\n",
      "15890    EMN          13  NOT_TRADED       0.040486\n",
      "15891    MWW          14  NOT_TRADED       0.023961\n",
      "15892    RIG          15  NOT_TRADED       0.015092\n",
      "15893  BEAM2          16  NOT_TRADED       0.023003\n",
      "15894    GGP          17  NOT_TRADED       0.053921\n",
      "15895   NVDA          18      TRADED       0.119809\n",
      "15896    PXD          19  NOT_TRADED       0.014783\n",
      "15897   TMUS          20  NOT_TRADED       0.049485\n",
      "15898    RHT          21  NOT_TRADED       0.022551\n",
      "15899     PH          22  NOT_TRADED       0.015606\n",
      "15900    BBY          23  NOT_TRADED       0.041039\n",
      "15901    HES          24  NOT_TRADED       0.015999\n",
      "15902      M          25  NOT_TRADED       0.055005\n",
      "15903     RL          26  NOT_TRADED       0.011406\n",
      "               count      mean       std       min       25%       50%  \\\n",
      "traded_flag                                                              \n",
      "NOT_TRADED   34367.0  0.036411  0.028640  0.000155  0.016264  0.027974   \n",
      "TRADED        1690.0  0.081164  0.027574  0.016811  0.056502  0.072514   \n",
      "\n",
      "                  75%       max  \n",
      "traded_flag                      \n",
      "NOT_TRADED   0.046222  0.119977  \n",
      "TRADED       0.114344  0.119977  \n"
     ]
    }
   ],
   "source": [
    "# After running the analysis script\n",
    "import pandas as pd\n",
    "\n",
    "# Load the main output\n",
    "df = pd.read_parquet(\"./13d-ranking_analysis/13d-rankings_with_trade_status.parquet\")\n",
    "\n",
    "# Filter specific week\n",
    "week = df[df['signal_date'] == '2010-11-24']\n",
    "print(week[['ticker', 'slope_rank', 'traded_flag', 'target_weight']])\n",
    "\n",
    "# See only stocks that didn't trade\n",
    "not_traded = df[df['traded_flag'] == 'NOT_TRADED']\n",
    "\n",
    "# Compare traded vs not traded\n",
    "print(df.groupby('traded_flag')['target_weight'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_quant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
