{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2b531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REGRESSION-ONLY WEEKLY TREND STRATEGY (VOL-BASED SIZING, WITH RANKS + SPY REGIME + TURNOVER FILTERS + CASH FLOOR) ===\n",
      "SPY Regime Confirmation Period: 1 day(s)\n",
      "Loaded universe: 3,590,957 rows\n",
      "Universe with ATR20 merged: 3,590,957 rows\n",
      "\n",
      "SPY Regime Statistics:\n",
      "  Raw regime:       5,107 bull days, 1,935 bear days\n",
      "  Confirmed regime: 5,107 bull days, 1,935 bear days\n",
      "\n",
      "Running trading engine...\n",
      "\n",
      "=== DEBUG 2010-11-24 PLAN ===\n",
      "trade_date: 2010-11-26 00:00:00\n",
      "spy_above_200: True\n",
      "positions_before: 6\n",
      "top_group_size: 26\n",
      "exit_tickers: 1\n",
      "planned_trades: 2\n",
      "planned sample: [{'ticker': 'MFE', 'side': 'SELL', 'shares': 5840, 'reason': 'not_in_top_quintile', 'rank': 9999}, {'ticker': 'NVDA', 'side': 'BUY', 'shares': 905570, 'reason': 'new_entry', 'rank': 18}]\n",
      "\n",
      "=== DEBUG 2010-11-26 EXEC ===\n",
      "planned_trades: 2\n",
      "missing_open_count: 0\n",
      "=== TRADING COMPLETE ===\n",
      "Final portfolio value: 20526005.661441874\n",
      "Final cash balance: 8616796.431441873\n",
      "Total trades: 2993\n",
      "Total weekly rankings: 36079\n",
      "Trades saved to:    ./13-trading_output_regression_insp500_spyfilter_cap15\\13-trades_regression_insp500_spyfilter_cap15.parquet\n",
      "Equity saved to:    ./13-trading_output_regression_insp500_spyfilter_cap15\\13-equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "Rankings saved to:  ./13-trading_output_regression_insp500_spyfilter_cap15\\13-weekly_rankings_pre_filter_cap15.parquet\n",
      "\n",
      "Diagnostics:\n",
      "  orders_seen (planned):        2993\n",
      "  orders_executed (fills):      2993\n",
      "  dropped_missing_open:         0\n",
      "  dropped_cash_floor_buy(plan): 10\n",
      "  warn_exec_cash_breach:        0\n",
      "\n",
      "=== PERFORMANCE ANALYSIS (Regression-Only System) ===\n",
      "Loaded equity curve: 6,790 rows\n",
      "Loaded SPY file:     7,042 rows\n",
      "Merged dataset:      6,790 rows\n",
      "\n",
      "=== Strategy Performance ===\n",
      "CAGR:            0.1635\n",
      "Volatility:      0.1294\n",
      "Sharpe:          1.2370\n",
      "Sortino:         1.5394\n",
      "MaxDD:          -0.1971\n",
      "Calmar:          0.8292\n",
      "\n",
      "=== SPY Benchmark ===\n",
      "CAGR:            0.0846\n",
      "Volatility:      0.1935\n",
      "Sharpe:          0.5175\n",
      "Sortino:         0.6630\n",
      "MaxDD:          -0.5519\n",
      "Calmar:          0.1534\n",
      "\n",
      "=== Year-by-Year Comparison ===\n",
      "       start_value     end_value  strat_return  strat_maxdd  strat_sharpe  \\\n",
      "year                                                                        \n",
      "1999  3.450000e+05  5.480859e+05      0.588655    -0.058203      3.222928   \n",
      "2000  5.498325e+05  7.500208e+05      0.364090    -0.195985      1.399524   \n",
      "2001  7.496244e+05  7.468231e+05     -0.003737    -0.006721     -0.963339   \n",
      "2002  7.468231e+05  7.305323e+05     -0.021813    -0.031469     -0.658295   \n",
      "2003  7.305323e+05  9.006539e+05      0.232873    -0.097053      1.684220   \n",
      "2004  9.051585e+05  1.084530e+06      0.198166    -0.046600      2.153781   \n",
      "2005  1.071809e+06  1.239706e+06      0.156649    -0.082853      1.349839   \n",
      "2006  1.246912e+06  1.392084e+06      0.116425    -0.101739      1.246610   \n",
      "2007  1.383861e+06  1.620095e+06      0.170707    -0.091113      1.316694   \n",
      "2008  1.615846e+06  1.572050e+06     -0.027104    -0.051489     -0.755448   \n",
      "2009  1.572050e+06  2.165204e+06      0.377312    -0.104356      1.929126   \n",
      "2010  2.181538e+06  2.452983e+06      0.124428    -0.149395      0.893122   \n",
      "2011  2.474490e+06  2.535967e+06      0.024844    -0.130701      0.319359   \n",
      "2012  2.539429e+06  3.088327e+06      0.216150    -0.090299      1.788645   \n",
      "2013  3.124290e+06  4.135889e+06      0.323785    -0.062070      2.268980   \n",
      "2014  4.115408e+06  4.439664e+06      0.078791    -0.069276      0.832202   \n",
      "2015  4.430009e+06  5.124892e+06      0.156858    -0.067936      1.526920   \n",
      "2016  5.061650e+06  6.444281e+06      0.273158    -0.078555      1.912869   \n",
      "2017  6.427855e+06  6.865844e+06      0.068139    -0.045510      0.780213   \n",
      "2018  6.923413e+06  7.448461e+06      0.075837    -0.085167      0.762551   \n",
      "2019  7.373533e+06  8.493812e+06      0.151932    -0.057424      1.439252   \n",
      "2020  8.537221e+06  1.139210e+07      0.334403    -0.197143      1.495280   \n",
      "2021  1.142758e+07  1.402245e+07      0.227071    -0.083631      1.179202   \n",
      "2022  1.418149e+07  1.435098e+07      0.011951    -0.103838      0.243085   \n",
      "2023  1.424832e+07  1.522492e+07      0.068542    -0.129416      0.561859   \n",
      "2024  1.504059e+07  1.667447e+07      0.108632    -0.067061      0.855415   \n",
      "2025  1.670080e+07  2.052601e+07      0.229043    -0.102743      1.615884   \n",
      "\n",
      "      strat_sortino  strat_calmar  spy_return  spy_maxdd  spy_sharpe  \\\n",
      "year                                                                   \n",
      "1999       5.245887     10.113793    0.206646  -0.116955    1.127902   \n",
      "2000       1.791199      1.857744   -0.088494  -0.171319   -0.309949   \n",
      "2001      -0.414443     -0.556000   -0.101315  -0.288144   -0.465205   \n",
      "2002      -0.485096     -0.693163   -0.224195  -0.329717   -0.787701   \n",
      "2003       2.413420      2.399440    0.241843  -0.137255    1.585190   \n",
      "2004       3.615182      4.252518    0.107477  -0.075305    0.967758   \n",
      "2005       2.082022      1.890672    0.053249  -0.069574    0.508351   \n",
      "2006       1.818907      1.144352    0.138429  -0.075931    1.525612   \n",
      "2007       1.807116      1.873569    0.053322  -0.099246    0.396259   \n",
      "2008      -0.497845     -0.526407   -0.362368  -0.471166   -0.901136   \n",
      "2009       2.286927      3.615628    0.226548  -0.271317    1.011113   \n",
      "2010       1.064963      0.832880    0.131373  -0.156996    0.871807   \n",
      "2011       0.385711      0.190086    0.008524  -0.186055    0.196714   \n",
      "2012       2.927958      2.393723    0.141709  -0.096870    1.237661   \n",
      "2013       3.618006      5.216480    0.290014  -0.055506    2.584688   \n",
      "2014       1.230439      1.137353    0.145617  -0.072735    1.179661   \n",
      "2015       2.260925      2.308907    0.012885  -0.119103    0.156472   \n",
      "2016       2.634771      3.477306    0.135858  -0.091875    0.932880   \n",
      "2017       1.036122      1.497222    0.207814  -0.026101    2.959132   \n",
      "2018       1.004946      0.890440   -0.052471  -0.193489   -0.190445   \n",
      "2019       1.987630      2.645792    0.310875  -0.066184    2.235597   \n",
      "2020       1.848815      1.696245    0.172352  -0.337173    0.670112   \n",
      "2021       1.699354      2.715165    0.305055  -0.051142    2.009996   \n",
      "2022       0.241405      0.115097   -0.186464  -0.244964   -0.709589   \n",
      "2023       0.924324      0.529620    0.267092  -0.099743    1.858299   \n",
      "2024       1.264415      1.619902    0.255893  -0.084056    1.831620   \n",
      "2025       2.051013      2.229292    0.188899  -0.187552    0.981222   \n",
      "\n",
      "      spy_sortino  spy_calmar  \n",
      "year                           \n",
      "1999     1.945490    1.766882  \n",
      "2000    -0.530308   -0.516546  \n",
      "2001    -0.688696   -0.351614  \n",
      "2002    -1.395947   -0.679961  \n",
      "2003     2.562162    1.761997  \n",
      "2004     1.443250    1.427223  \n",
      "2005     0.798996    0.765359  \n",
      "2006     2.256278    1.823080  \n",
      "2007     0.497639    0.537270  \n",
      "2008    -1.249254   -0.769087  \n",
      "2009     1.422102    0.834992  \n",
      "2010     1.150665    0.836793  \n",
      "2011     0.252342    0.045813  \n",
      "2012     1.923797    1.462881  \n",
      "2013     3.661329    5.224897  \n",
      "2014     1.534347    2.002028  \n",
      "2015     0.222416    0.108184  \n",
      "2016     1.213762    1.478717  \n",
      "2017     3.993274    7.961941  \n",
      "2018    -0.232471   -0.271186  \n",
      "2019     2.742741    4.697150  \n",
      "2020     0.755250    0.511169  \n",
      "2021     2.871862    5.964905  \n",
      "2022    -1.139982   -0.761190  \n",
      "2023     3.068499    2.677800  \n",
      "2024     2.403117    3.044315  \n",
      "2025     1.247063    1.007178  \n",
      "\n",
      "Saved:\n",
      "  → ./14-trading_output_regression_insp500_spyfilter_performance_output_cap15\\14-regression_insp500_spyfilter-performance_summary_cap15.csv\n",
      "  → ./14-trading_output_regression_insp500_spyfilter_performance_output_cap15\\14-regression_insp500_spyfilter-yearly_comparison_cap15.csv\n",
      "\n",
      "=== COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\"\"\"_summary_\n",
    "\n",
    "    What's New\n",
    "1. Weekly Rankings Storage\n",
    "Added a new list weekly_rankings = [] that captures all top-ranked stocks before any turnover filters are applied.\n",
    "2. Pre-Filter Data Captured (lines 409-436)\n",
    "For each stock in the top group, the system now records:\n",
    "\n",
    "Signal and execution dates\n",
    "Ticker and rank\n",
    "Slope and ATR20 values\n",
    "Raw and capped weights\n",
    "Target vs current positions (shares, values, weights)\n",
    "SPY regime status\n",
    "Portfolio value\n",
    "\n",
    "This happens before the drift threshold, minimum trade value, and minimum position weight filters are applied.\n",
    "3. New Output File\n",
    "The script now saves three files instead of two:\n",
    "\n",
    "13-trades_regression_insp500_spyfilter_cap15.parquet - Actual executed trades\n",
    "13-equity_curve_regression_insp500_spyfilter_cap15.parquet - Daily portfolio values\n",
    "13-weekly_rankings_pre_filter_cap15.parquet - NEW: All top-ranked stocks each week\n",
    "\n",
    "4. Enhanced Console Output\n",
    "The script now reports:\n",
    "Total trades: X\n",
    "Total weekly rankings: Y\n",
    "Rankings saved to: ...\n",
    "\n",
    "5. SPY REGIME CONFIRMATION PERIOD (NEW)\n",
    "Added SPY_REGIME_CONFIRM_DAYS parameter to reduce whipsaw signals around the 200 DMA.\n",
    "Set to 1 for original behavior (immediate regime flip on crossover).\n",
    "Set to 5+ to require N consecutive days above/below before confirming regime change.\n",
    "    \"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "UNIVERSE_FILE   = \"./12-tradable_sp500_universe/12-tradable_sp500_universe.parquet\"\n",
    "ATR20_DIR       = \"./4-ATR20_adjusted_All_Prices\"\n",
    "SPY_FILE        = \"./8-SPY_200DMA_market_regime/8-SPY_200DMA_regime.parquet\"\n",
    "\n",
    "OUTPUT_DIR_TRADES   = \"./13-trading_output_regression_insp500_spyfilter_cap15\"\n",
    "OUTPUT_DIR_PERF     = \"./14-trading_output_regression_insp500_spyfilter_performance_output_cap15\"\n",
    "os.makedirs(OUTPUT_DIR_TRADES, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_PERF, exist_ok=True)\n",
    "\n",
    "START_TRADING         = pd.Timestamp(\"1999-1-1\")\n",
    "INITIAL_CAPITAL       = 345000\n",
    "TOP_PERCENTILE        = 0.95        # top 5% by regression slope\n",
    "REBALANCE_DAY         = \"Wednesday\"  # weekly signal day\n",
    "TRADING_DAYS_PER_YEAR = 252\n",
    "\n",
    "# --- Position cap ---\n",
    "MAX_POSITION_WEIGHT = 0.12   # 12% max position (by proxy portfolio value)\n",
    "\n",
    "# --- Cash floor (Option A planned alignment) ---\n",
    "MIN_CASH_RESERVE = 20000.0\n",
    "\n",
    "# --- SPY REGIME CONFIRMATION PERIOD ---\n",
    "# Number of consecutive days SPY must stay above/below 200 DMA before confirming regime change\n",
    "# Set to 1 for original behavior (immediate flip on crossover)\n",
    "# Set to 5, 10, etc. to filter out whipsaw signals around the 200 DMA\n",
    "SPY_REGIME_CONFIRM_DAYS = 1\n",
    "\n",
    "# --- DEBUG CONTROLS ---\n",
    "DEBUG_TICKER = \"TWX\"\n",
    "DEBUG_SIGNAL_DATE    = pd.Timestamp(\"1999-01-06\")\n",
    "DEBUG_REBALANCE_DATE = pd.Timestamp(\"1999-01-07\")\n",
    "\n",
    "# Turnover / trade filters (MODEL A)\n",
    "DRIFT_THRESHOLD          = 0.05\n",
    "MIN_TRADE_VALUE          = 10000\n",
    "MIN_NEW_POSITION_WEIGHT  = 0.005\n",
    "\n",
    "print(\"=== REGRESSION-ONLY WEEKLY TREND STRATEGY \"\n",
    "      \"(VOL-BASED SIZING, WITH RANKS + SPY REGIME + TURNOVER FILTERS + CASH FLOOR) ===\")\n",
    "print(f\"SPY Regime Confirmation Period: {SPY_REGIME_CONFIRM_DAYS} day(s)\")\n",
    "\n",
    "# ============================================================\n",
    "# EXECUTION DIAGNOSTICS (kept, but not fully wired)\n",
    "# ============================================================\n",
    "\n",
    "exec_diag = {\n",
    "    \"orders_seen\": 0,\n",
    "    \"orders_executed\": 0,\n",
    "    \"dropped_missing_open\": 0,\n",
    "    \"dropped_cash_floor_buy\": 0,\n",
    "    \"dropped_zero_shares\": 0,\n",
    "    \"dropped_missing_ticker\": 0,\n",
    "    \"warn_exec_cash_breach\": 0,  # open moved; execution may breach reserve\n",
    "}\n",
    "exec_diag[\"dropped_cash_floor_buy_exec\"] = 0\n",
    "exec_diag[\"clipped_cash_floor_buy_exec\"] = 0\n",
    "\n",
    "# ============================================================\n",
    "# SPY REGIME CONFIRMATION FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def create_confirmed_regime(raw_regime: np.ndarray, confirm_days: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a confirmed regime signal that requires N consecutive days\n",
    "    above/below the 200 DMA before flipping the regime.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_regime : array of 0/1 (0 = below 200 DMA, 1 = above 200 DMA)\n",
    "    confirm_days : number of consecutive days required to confirm regime change\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    confirmed_regime : array of 0/1 with smoothed regime signal\n",
    "    \"\"\"\n",
    "    if confirm_days <= 1:\n",
    "        return raw_regime.copy()\n",
    "    \n",
    "    n = len(raw_regime)\n",
    "    confirmed = np.zeros(n, dtype=int)\n",
    "    \n",
    "    # Start with the initial regime (use first value)\n",
    "    current_regime = raw_regime[0]\n",
    "    consecutive_count = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        if raw_regime[i] == current_regime:\n",
    "            # Same as current confirmed regime\n",
    "            consecutive_count = 0  # Reset counter for opposite regime\n",
    "            confirmed[i] = current_regime\n",
    "        else:\n",
    "            # Different from current confirmed regime\n",
    "            consecutive_count += 1\n",
    "            \n",
    "            if consecutive_count >= confirm_days:\n",
    "                # Confirm the regime change\n",
    "                current_regime = raw_regime[i]\n",
    "                consecutive_count = 0\n",
    "            \n",
    "            confirmed[i] = current_regime\n",
    "    \n",
    "    return confirmed\n",
    "\n",
    "# ============================================================\n",
    "# FAST PRICE LOOKUP\n",
    "# ============================================================\n",
    "\n",
    "def fast_price_lookup(px_array, date_val):\n",
    "    \"\"\"\n",
    "    Given a structured array with fields ['date', 'px'] and a date,\n",
    "    return the last known price at or before that date.\n",
    "    \"\"\"\n",
    "    date_val = np.datetime64(date_val, \"ns\")\n",
    "    dates = px_array[\"date\"]\n",
    "    idx = np.searchsorted(dates, date_val, side=\"right\") - 1\n",
    "    if idx < 0:\n",
    "        return np.nan\n",
    "    return px_array[\"px\"][idx]\n",
    "\n",
    "# ============================================================\n",
    "# SNAPSHOT PORTFOLIO\n",
    "# ============================================================\n",
    "\n",
    "def snapshot_portfolio_close(date, cash, positions, px_by_ticker):\n",
    "    \"\"\"\n",
    "    Snapshot using CLOSE prices (your px_by_ticker is close_adj).\n",
    "    Used for end-of-day equity curve.\n",
    "    \"\"\"\n",
    "    equity = 0.0\n",
    "    for t, pos in positions.items():\n",
    "        px = fast_price_lookup(px_by_ticker[t], date)\n",
    "        if not np.isnan(px):\n",
    "            equity += pos[\"shares\"] * px\n",
    "    portfolio_value = cash + equity\n",
    "    return equity, portfolio_value, len(positions)\n",
    "\n",
    "def snapshot_portfolio_open(exec_date, cash, positions, open_px_map, px_by_ticker_fallback):\n",
    "    \"\"\"\n",
    "    Snapshot using OPEN prices for exec_date when available, fallback to last known close.\n",
    "    Used for execution-time snapshots (reporting).\n",
    "    \"\"\"\n",
    "    equity = 0.0\n",
    "    for t, pos in positions.items():\n",
    "        if t in open_px_map and pd.notna(open_px_map[t]) and open_px_map[t] > 0:\n",
    "            px = float(open_px_map[t])\n",
    "        else:\n",
    "            px = fast_price_lookup(px_by_ticker_fallback[t], exec_date)\n",
    "        if not np.isnan(px):\n",
    "            equity += pos[\"shares\"] * px\n",
    "    portfolio_value = cash + equity\n",
    "    return equity, portfolio_value, len(positions)\n",
    "\n",
    "def snapshot_portfolio_exec_proxy(asof_date, cash, positions, exec_px_map, px_by_ticker_fallback):\n",
    "    \"\"\"\n",
    "    Snapshot using \"execution proxy\" prices (Wednesday close_adj).\n",
    "    Used for sizing / weights with no lookahead.\n",
    "    \"\"\"\n",
    "    equity = 0.0\n",
    "    for t, pos in positions.items():\n",
    "        px = exec_px_map.get(t, np.nan)\n",
    "        if pd.isna(px) or px <= 0:\n",
    "            px = fast_price_lookup(px_by_ticker_fallback[t], asof_date)\n",
    "        if pd.notna(px) and px > 0:\n",
    "            equity += int(pos[\"shares\"]) * float(px)\n",
    "    return equity, cash + equity, len(positions)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD UNIVERSE\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_parquet(UNIVERSE_FILE)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "df[\"slope_adj\"] = pd.to_numeric(df[\"slope_adj\"], errors=\"coerce\")\n",
    "df[\"close_adj\"] = pd.to_numeric(df[\"close_adj\"], errors=\"coerce\")\n",
    "df[\"open_adj\"]  = pd.to_numeric(df[\"open_adj\"],  errors=\"coerce\")\n",
    "\n",
    "print(f\"Loaded universe: {len(df):,} rows\")\n",
    "\n",
    "# ============================================================\n",
    "# MERGE ATR20 PER-TICKER (IN-MEMORY ONLY)\n",
    "# ============================================================\n",
    "\n",
    "atr20_map = {}\n",
    "for f in os.listdir(ATR20_DIR):\n",
    "    if not f.endswith(\".parquet\"):\n",
    "        continue\n",
    "    t = f.replace(\".parquet\", \"\")\n",
    "    tmp = pd.read_parquet(os.path.join(ATR20_DIR, f))\n",
    "    if \"atr20\" not in tmp:\n",
    "        continue\n",
    "    tmp[\"date\"] = pd.to_datetime(tmp[\"date\"])\n",
    "    atr20_map[t] = tmp[[\"date\", \"atr20\"]]\n",
    "\n",
    "rows = []\n",
    "for t, sub in df.groupby(\"ticker\", sort=False):\n",
    "    if t in atr20_map:\n",
    "        rows.append(sub.merge(atr20_map[t], on=\"date\", how=\"left\"))\n",
    "    else:\n",
    "        sub = sub.copy()\n",
    "        sub[\"atr20\"] = np.nan\n",
    "        rows.append(sub)\n",
    "\n",
    "df = pd.concat(rows, ignore_index=True)\n",
    "print(f\"Universe with ATR20 merged: {len(df):,} rows\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD SPY 200DMA REGIME FILE\n",
    "# ============================================================\n",
    "\n",
    "spy = pd.read_parquet(SPY_FILE)\n",
    "\n",
    "# Reset index → ensure a \"date\" column exists\n",
    "if spy.index.name in [\"Date\", \"date\", None]:\n",
    "    spy = spy.reset_index().rename(columns={\"index\": \"date\", \"Date\": \"date\"})\n",
    "\n",
    "spy[\"date\"] = pd.to_datetime(spy[\"date\"])\n",
    "\n",
    "if \"spy_close\" not in spy.columns:\n",
    "    raise ValueError(\"SPY file missing 'spy_close' column\")\n",
    "\n",
    "# Get raw regime signal (1 = above 200 DMA, 0 = below)\n",
    "raw_regime = spy[\"market_regime\"].astype(int).values\n",
    "\n",
    "# Apply confirmation period filter\n",
    "confirmed_regime = create_confirmed_regime(raw_regime, SPY_REGIME_CONFIRM_DAYS)\n",
    "spy[\"spy_above_200dma\"] = confirmed_regime == 1\n",
    "\n",
    "# Report regime statistics\n",
    "n_bull_raw = (raw_regime == 1).sum()\n",
    "n_bear_raw = (raw_regime == 0).sum()\n",
    "n_bull_confirmed = (confirmed_regime == 1).sum()\n",
    "n_bear_confirmed = (confirmed_regime == 0).sum()\n",
    "\n",
    "print(f\"\\nSPY Regime Statistics:\")\n",
    "print(f\"  Raw regime:       {n_bull_raw:,} bull days, {n_bear_raw:,} bear days\")\n",
    "print(f\"  Confirmed regime: {n_bull_confirmed:,} bull days, {n_bear_confirmed:,} bear days\")\n",
    "if SPY_REGIME_CONFIRM_DAYS > 1:\n",
    "    regime_changes_raw = np.sum(np.diff(raw_regime) != 0)\n",
    "    regime_changes_confirmed = np.sum(np.diff(confirmed_regime) != 0)\n",
    "    print(f\"  Regime changes:   {regime_changes_raw} raw → {regime_changes_confirmed} confirmed\")\n",
    "\n",
    "spy_regime_map = spy.set_index(\"date\")[\"spy_above_200dma\"].to_dict()\n",
    "\n",
    "# ============================================================\n",
    "# PREP GROUPED DATA\n",
    "# ============================================================\n",
    "\n",
    "df_by_date = {d: sub for d, sub in df.groupby(\"date\")}\n",
    "\n",
    "# close price history (fallback)\n",
    "px_by_ticker = {}\n",
    "for t, sub in df.groupby(\"ticker\", sort=False):\n",
    "    sub = sub.sort_values(\"date\")\n",
    "    arr = np.zeros(len(sub), dtype=[(\"date\", \"datetime64[ns]\"), (\"px\", \"float64\")])\n",
    "    arr[\"date\"] = sub[\"date\"].values.astype(\"datetime64[ns]\")\n",
    "    arr[\"px\"]   = sub[\"close_adj\"].astype(float).values\n",
    "    px_by_ticker[t] = arr\n",
    "\n",
    "dates = sorted(df_by_date.keys())\n",
    "\n",
    "# ============================================================\n",
    "# BUILD NEXT-TRADING-DAY (T+1) MAP\n",
    "# ============================================================\n",
    "\n",
    "next_date_map = {d: dates[i + 1] if i + 1 < len(dates) else None for i, d in enumerate(dates)}\n",
    "\n",
    "# ============================================================\n",
    "# UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "def is_rebalance_day(date: pd.Timestamp) -> bool:\n",
    "    return date.day_name() == REBALANCE_DAY\n",
    "\n",
    "def get_signal_close(day_df, ticker):\n",
    "    row = day_df.loc[day_df[\"ticker\"] == ticker, \"close_adj\"]\n",
    "    if row.empty:\n",
    "        return np.nan\n",
    "    return float(row.iloc[0])\n",
    "\n",
    "def cap_and_redistribute_weights(w: np.ndarray, cap: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Caps weights at `cap` and redistributes any excess proportionally\n",
    "    to the remaining (uncapped) names.\n",
    "\n",
    "    If not feasible to fully invest under cap (N*cap < 1), it will cap\n",
    "    and leave leftover unallocated (cash drag).\n",
    "    \"\"\"\n",
    "    w = np.asarray(w, dtype=float).copy()\n",
    "    if w.size == 0:\n",
    "        return w\n",
    "\n",
    "    s = w.sum()\n",
    "    if s > 0:\n",
    "        w /= s\n",
    "\n",
    "    # Not feasible to be fully invested under cap\n",
    "    if w.size * cap < 1.0:\n",
    "        return np.minimum(w, cap)\n",
    "\n",
    "    # Iteratively cap and redistribute\n",
    "    for _ in range(10_000):\n",
    "        over = w > cap\n",
    "        if not over.any():\n",
    "            break\n",
    "        excess = (w[over] - cap).sum()\n",
    "        w[over] = cap\n",
    "        under = ~over\n",
    "        under_sum = w[under].sum()\n",
    "        if under_sum <= 0:\n",
    "            break\n",
    "        w[under] += excess * (w[under] / under_sum)\n",
    "\n",
    "    return w\n",
    "\n",
    "# ============================================================\n",
    "# TRADING ENGINE (UPDATED FOR \"PLANNED ALIGNMENT\")\n",
    "#\n",
    "# RULES:\n",
    "# - PLAN on Wednesday using ONLY Wednesday close (no Thursday info for sizing/affordability)\n",
    "# - EXECUTE on Thursday morning at Thursday open (fills), but shares are fixed from Wednesday\n",
    "# - NO buy clipping using Thursday open (skip in planning if insufficient cash proxy)\n",
    "# ============================================================\n",
    "\n",
    "cash = INITIAL_CAPITAL\n",
    "positions = {}       # ticker -> {\"shares\": int, \"entry\": float}\n",
    "history = []         # trade log\n",
    "equity_curve = []\n",
    "last_equity_close = INITIAL_CAPITAL\n",
    "\n",
    "# NEW: Storage for weekly rankings before filters\n",
    "weekly_rankings = []\n",
    "\n",
    "# Pending planned orders keyed by exec_date (Thursday)\n",
    "# payload contains: signal_date, spy flag, open_px_map for exec_date, planned trades list\n",
    "pending_orders = {}\n",
    "\n",
    "print(\"\\nRunning trading engine...\")\n",
    "\n",
    "for date in dates:\n",
    "\n",
    "    if date < START_TRADING:\n",
    "        continue\n",
    "\n",
    "    day = df_by_date.get(date)\n",
    "    if day is None or day.empty:\n",
    "        continue\n",
    "\n",
    "    # =======================================================\n",
    "    # 0) EXECUTE any pending orders scheduled for TODAY (Thursday morning)\n",
    "    # =======================================================\n",
    "    if date in pending_orders:\n",
    "        payload = pending_orders.pop(date)\n",
    "        signal_date = payload[\"signal_date\"]\n",
    "        spy_above_200 = payload[\"spy_above_200\"]\n",
    "        open_px_map = payload[\"open_px_map\"]\n",
    "        planned_trades = payload[\"planned_trades\"]\n",
    "        \n",
    "        if date == pd.Timestamp(\"2010-11-26\"):\n",
    "            print(\"\\n=== DEBUG 2010-11-26 EXEC ===\")\n",
    "            print(\"planned_trades:\", len(planned_trades))\n",
    "            if planned_trades:\n",
    "                miss_open = sum(pd.isna(open_px_map.get(tr[\"ticker\"], np.nan)) for tr in planned_trades)\n",
    "                print(\"missing_open_count:\", miss_open)\n",
    "\n",
    "\n",
    "        # Execute SELLS first, then BUYS; within each, rank ascending\n",
    "        planned_trades = sorted(planned_trades, key=lambda x: (0 if x[\"side\"] == \"SELL\" else 1, x[\"rank\"]))\n",
    "\n",
    "        for tr in planned_trades:\n",
    "            t = tr[\"ticker\"]\n",
    "            side = tr[\"side\"]\n",
    "            sh_plan = int(tr[\"shares\"])\n",
    "\n",
    "            if not t or sh_plan <= 0:\n",
    "                continue\n",
    "\n",
    "            # execution price is Thursday open; fallback to last close if missing\n",
    "            px = open_px_map.get(t, np.nan)\n",
    "            if pd.isna(px) or px <= 0:\n",
    "                if t in px_by_ticker:\n",
    "                    px = fast_price_lookup(px_by_ticker[t], date)\n",
    "            if pd.isna(px) or px <= 0:\n",
    "                exec_diag[\"dropped_missing_open\"] += 1\n",
    "                continue\n",
    "\n",
    "            px = float(px)\n",
    "            cash_before = float(cash)\n",
    "\n",
    "            if side == \"SELL\":\n",
    "                cur = int(positions.get(t, {}).get(\"shares\", 0))\n",
    "                sh_exec = min(sh_plan, cur)\n",
    "                if sh_exec <= 0:\n",
    "                    continue\n",
    "\n",
    "                trade_value = sh_exec * px\n",
    "                cash += trade_value\n",
    "\n",
    "                new_sh = cur - sh_exec\n",
    "                if new_sh <= 0:\n",
    "                    positions.pop(t, None)\n",
    "                else:\n",
    "                    positions[t][\"shares\"] = new_sh\n",
    "\n",
    "                typ = \"SELL\"\n",
    "                sh_record = sh_exec\n",
    "\n",
    "            else:  # BUY\n",
    "                # enforce cash reserve at execution\n",
    "                available = cash - MIN_CASH_RESERVE\n",
    "                if available <= 0:\n",
    "                    exec_diag[\"dropped_cash_floor_buy_exec\"] += 1\n",
    "                    continue\n",
    "\n",
    "                max_affordable_shares = int(np.floor(available / px))\n",
    "                sh_exec = min(sh_plan, max_affordable_shares)\n",
    "\n",
    "                if sh_exec <= 0:\n",
    "                    exec_diag[\"dropped_cash_floor_buy_exec\"] += 1\n",
    "                    continue\n",
    "\n",
    "                if sh_exec < sh_plan:\n",
    "                    exec_diag[\"clipped_cash_floor_buy_exec\"] += 1\n",
    "\n",
    "                trade_value = sh_exec * px\n",
    "                cash_before = float(cash)\n",
    "                cash -= trade_value\n",
    "\n",
    "                if t in positions:\n",
    "                    positions[t][\"shares\"] = int(positions[t][\"shares\"]) + sh_exec\n",
    "                else:\n",
    "                    positions[t] = {\"shares\": sh_exec, \"entry\": px}\n",
    "\n",
    "                typ = \"BUY\"\n",
    "                sh_record = sh_exec\n",
    "\n",
    "            equity_after, portfolio_after, npos_after = snapshot_portfolio_open(\n",
    "                date, cash, positions, open_px_map, px_by_ticker\n",
    "            )\n",
    "\n",
    "            # signal close comes from the original Wednesday signal date\n",
    "            signal_day_df = df_by_date.get(signal_date)\n",
    "            signal_px = get_signal_close(signal_day_df, t) if signal_day_df is not None else np.nan\n",
    "\n",
    "            history.append({\n",
    "                \"signal_date\": signal_date,\n",
    "                \"exec_date\": date,\n",
    "                \"signal_close_adj\": signal_px,\n",
    "                \"exec_open_adj\": px,\n",
    "\n",
    "                \"ticker\": t,\n",
    "                \"type\": typ,\n",
    "                \"shares\": int(sh_record),\n",
    "                \"price\": px,\n",
    "                \"value\": float(sh_record * px),\n",
    "                \"reason\": tr[\"reason\"],\n",
    "\n",
    "                \"slope_rank_within_top\": tr[\"rank\"],\n",
    "                \"spy_above_200dma\": spy_above_200,\n",
    "\n",
    "                \"cash_before\": cash_before,\n",
    "                \"cash_after\": float(cash),\n",
    "                \"equity_after\": float(equity_after),\n",
    "                \"portfolio_after\": float(portfolio_after),\n",
    "                \"num_positions_after\": int(npos_after),\n",
    "            })\n",
    "\n",
    "        exec_diag[\"orders_executed\"] += len(planned_trades)\n",
    "\n",
    "    # =======================================================\n",
    "    # 1) PLAN trades on Wednesday close for next trading day open\n",
    "    # =======================================================\n",
    "    if is_rebalance_day(date):\n",
    "        trade_date = next_date_map.get(date)\n",
    "\n",
    "        if trade_date is not None and trade_date in df_by_date:\n",
    "            # SPY regime as-of Wednesday close (with confirmation filter applied)\n",
    "            spy_above_200 = bool(spy_regime_map.get(date, True))\n",
    "            can_buy_next_open = spy_above_200\n",
    "\n",
    "            # Rank / top group (signal day)\n",
    "            rankable = day[\n",
    "                (day[\"slope_adj\"].notna()) &\n",
    "                (day.get(\"in_sp500\", True) == True)\n",
    "            ].copy()\n",
    "\n",
    "            rank_map = {}\n",
    "            top_tickers = set()\n",
    "            top_group = pd.DataFrame()\n",
    "\n",
    "            if not rankable.empty:\n",
    "                rankable = rankable.sort_values(\"slope_adj\", ascending=False)\n",
    "                cutoff = rankable[\"slope_adj\"].quantile(TOP_PERCENTILE)\n",
    "                top_group = rankable[rankable[\"slope_adj\"] >= cutoff].copy()\n",
    "\n",
    "                if not top_group.empty:\n",
    "                    top_group = top_group.sort_values(\"slope_adj\", ascending=False)\n",
    "                    top_group[\"slope_rank_within_top\"] = np.arange(1, len(top_group) + 1)\n",
    "                    rank_map = dict(zip(top_group[\"ticker\"], top_group[\"slope_rank_within_top\"]))\n",
    "                    top_tickers = set(top_group[\"ticker\"].values)\n",
    "\n",
    "            if not top_group.empty:\n",
    "                # Execution proxy prices known at signal time (Wednesday close)\n",
    "                exec_px_map = day.set_index(\"ticker\")[\"close_adj\"].to_dict()\n",
    "\n",
    "                # Thursday open map stored for execution (fills)\n",
    "                trade_day = df_by_date[trade_date]\n",
    "                open_px_map = trade_day.set_index(\"ticker\")[\"open_adj\"].to_dict()\n",
    "\n",
    "                # ---------- PLAN STATE (DO NOT TOUCH REAL cash/positions) ----------\n",
    "                cash_plan = float(cash)\n",
    "                pos_plan = {t: int(p[\"shares\"]) for t, p in positions.items()}\n",
    "\n",
    "                planned = []  # list of dicts {ticker, side, shares, reason, rank}\n",
    "\n",
    "                def px_est(ticker: str) -> float:\n",
    "                    \"\"\"Wednesday close estimate (proxy).\"\"\"\n",
    "                    p = exec_px_map.get(ticker, np.nan)\n",
    "                    if pd.isna(p) or p <= 0:\n",
    "                        if ticker in px_by_ticker:\n",
    "                            p = fast_price_lookup(px_by_ticker[ticker], date)\n",
    "                    return float(p) if (pd.notna(p) and p > 0) else np.nan\n",
    "\n",
    "                # -------------------------\n",
    "                # (A) EXIT SELLS FIRST\n",
    "                # -------------------------\n",
    "                exit_tickers = [t for t in list(pos_plan.keys()) if t not in top_tickers]\n",
    "                for t in exit_tickers:\n",
    "                    sh0 = int(pos_plan.get(t, 0))\n",
    "                    if sh0 <= 0:\n",
    "                        continue\n",
    "\n",
    "                    p = px_est(t)\n",
    "                    if pd.isna(p):\n",
    "                        continue\n",
    "\n",
    "                    cash_plan += sh0 * p\n",
    "                    pos_plan.pop(t, None)\n",
    "\n",
    "                    planned.append({\n",
    "                        \"ticker\": t,\n",
    "                        \"side\": \"SELL\",\n",
    "                        \"shares\": sh0,\n",
    "                        \"reason\": \"not_in_top_quintile\",\n",
    "                        \"rank\": int(rank_map.get(t, 9999)),\n",
    "                    })\n",
    "\n",
    "                # -------------------------\n",
    "                # (B) REVALUE PORTFOLIO AT \"EXEC PROXY\" AFTER EXITS (Wednesday close)\n",
    "                # -------------------------\n",
    "                pos_plan_struct = {t: {\"shares\": sh} for t, sh in pos_plan.items()}\n",
    "                equity_exec, portfolio_exec, _ = snapshot_portfolio_exec_proxy(\n",
    "                    date, cash_plan, pos_plan_struct, exec_px_map, px_by_ticker\n",
    "                )\n",
    "                effective_equity = max(portfolio_exec - MIN_CASH_RESERVE, 0.0)\n",
    "\n",
    "                # -------------------------\n",
    "                # (C) BUILD TARGETS USING WED CLOSE (NO LOOKAHEAD)\n",
    "                # -------------------------\n",
    "                tg = top_group.copy()\n",
    "                tg = tg[\n",
    "                    tg[\"atr20\"].notna() &\n",
    "                    (tg[\"atr20\"] > 0) &\n",
    "                    tg[\"close_adj\"].notna() &\n",
    "                    (tg[\"close_adj\"] > 0)\n",
    "                ].copy()\n",
    "\n",
    "                if not tg.empty:\n",
    "                    inv_vol = 1.0 / tg[\"atr20\"].astype(float)\n",
    "                    total_inv_vol = inv_vol.sum()\n",
    "\n",
    "                    if total_inv_vol > 0:\n",
    "                        tg[\"inv_vol\"] = inv_vol\n",
    "\n",
    "                        # Raw (uncapped) inverse-vol weights\n",
    "                        tg[\"raw_weight\"] = tg[\"inv_vol\"] / total_inv_vol\n",
    "\n",
    "                        # Apply 15% cap and redistribute (if feasible)\n",
    "                        w_cap = cap_and_redistribute_weights(tg[\"raw_weight\"].to_numpy(), MAX_POSITION_WEIGHT)\n",
    "                        tg[\"weight\"] = w_cap\n",
    "\n",
    "                        tg[\"target_value\"] = effective_equity * tg[\"weight\"]\n",
    "                        tg[\"exec_px_est\"] = tg[\"ticker\"].map(exec_px_map)\n",
    "                        tg = tg[tg[\"exec_px_est\"].notna() & (tg[\"exec_px_est\"] > 0)].copy()\n",
    "\n",
    "                        # Hard safety: ensure no target exceeds 15% of proxy portfolio value\n",
    "                        tg[\"target_value\"] = np.minimum(tg[\"target_value\"], MAX_POSITION_WEIGHT * portfolio_exec)\n",
    "\n",
    "                        # target shares based on Wednesday close estimate\n",
    "                        tg[\"target_shares\"] = np.floor(tg[\"target_value\"] / tg[\"exec_px_est\"]).astype(int)\n",
    "                        tg = tg[tg[\"target_shares\"] > 0].copy()\n",
    "\n",
    "                        # deterministic ordering (match generator)\n",
    "                        tg = tg.sort_values(\"slope_adj\", ascending=False)\n",
    "\n",
    "                        total_portfolio_value_exec = portfolio_exec  # proxy portfolio value\n",
    "\n",
    "                        # -------------------------\n",
    "                        # NEW: SAVE PRE-FILTER RANKINGS\n",
    "                        # -------------------------\n",
    "                        for _, r in tg.iterrows():\n",
    "                            t = str(r[\"ticker\"])\n",
    "                            rank = int(rank_map.get(t, 9999))\n",
    "                            p = float(r[\"exec_px_est\"])\n",
    "                            target_sh = int(r[\"target_shares\"])\n",
    "                            cur_sh = int(pos_plan.get(t, 0))\n",
    "                            \n",
    "                            target_value = target_sh * p\n",
    "                            target_weight = (target_value / total_portfolio_value_exec) if total_portfolio_value_exec > 0 else 0.0\n",
    "                            \n",
    "                            cur_value = cur_sh * p\n",
    "                            cur_weight = (cur_value / total_portfolio_value_exec) if total_portfolio_value_exec > 0 else 0.0\n",
    "                            \n",
    "                            weekly_rankings.append({\n",
    "                                \"signal_date\": date,\n",
    "                                \"exec_date\": trade_date,\n",
    "                                \"ticker\": t,\n",
    "                                \"slope_rank\": rank,\n",
    "                                \"slope_adj\": float(r[\"slope_adj\"]),\n",
    "                                \"atr20\": float(r[\"atr20\"]),\n",
    "                                \"close_adj\": float(r[\"close_adj\"]),\n",
    "                                \"raw_weight\": float(r[\"raw_weight\"]),\n",
    "                                \"capped_weight\": float(r[\"weight\"]),\n",
    "                                \"target_value\": target_value,\n",
    "                                \"target_weight\": target_weight,\n",
    "                                \"target_shares\": target_sh,\n",
    "                                \"current_shares\": cur_sh,\n",
    "                                \"current_value\": cur_value,\n",
    "                                \"current_weight\": cur_weight,\n",
    "                                \"spy_above_200dma\": spy_above_200,\n",
    "                                \"portfolio_value\": total_portfolio_value_exec,\n",
    "                            })\n",
    "\n",
    "                        # -------------------------\n",
    "                        # (D) REBALANCE LOOP (SEQUENTIAL cash_plan updates like generator)\n",
    "                        # -------------------------\n",
    "                        for _, r in tg.iterrows():\n",
    "                            t = str(r[\"ticker\"])\n",
    "                            rank = int(rank_map.get(t, 9999))\n",
    "\n",
    "                            p = float(r[\"exec_px_est\"])\n",
    "                            if not (p > 0):\n",
    "                                continue\n",
    "\n",
    "                            target_sh = int(r[\"target_shares\"])\n",
    "                            cur_sh = int(pos_plan.get(t, 0))\n",
    "\n",
    "                            # Enforce 15% max position at share level (proxy portfolio value)\n",
    "                            max_shares_allowed = (\n",
    "                                int(np.floor((MAX_POSITION_WEIGHT * total_portfolio_value_exec) / p))\n",
    "                                if total_portfolio_value_exec > 0 else 0\n",
    "                            )\n",
    "                            target_sh = min(target_sh, max_shares_allowed)\n",
    "\n",
    "                            # weights computed on proxy prices (Wednesday close)\n",
    "                            target_value = target_sh * p\n",
    "                            target_weight = (target_value / total_portfolio_value_exec) if total_portfolio_value_exec > 0 else 0.0\n",
    "\n",
    "                            cur_value = cur_sh * p\n",
    "                            cur_weight = (cur_value / total_portfolio_value_exec) if total_portfolio_value_exec > 0 else 0.0\n",
    "\n",
    "                            weight_diff = abs(target_weight - cur_weight)\n",
    "                            is_new_position = (cur_sh == 0)\n",
    "\n",
    "                            # If currently breaching the cap, force a trim even if within drift\n",
    "                            cap_breach = (cur_weight > MAX_POSITION_WEIGHT + 1e-9)\n",
    "\n",
    "                            if (weight_diff < DRIFT_THRESHOLD) and (not cap_breach):\n",
    "                                continue\n",
    "\n",
    "                            # -------- SELL (rebalance down) --------\n",
    "                            if target_sh < cur_sh:\n",
    "                                trade_sh = cur_sh - target_sh\n",
    "                                est_value = trade_sh * p\n",
    "\n",
    "                                if est_value < MIN_TRADE_VALUE:\n",
    "                                    continue\n",
    "\n",
    "                                cash_plan += est_value\n",
    "\n",
    "                                new_sh = cur_sh - trade_sh\n",
    "                                if new_sh <= 0:\n",
    "                                    pos_plan.pop(t, None)\n",
    "                                else:\n",
    "                                    pos_plan[t] = new_sh\n",
    "\n",
    "                                planned.append({\n",
    "                                    \"ticker\": t,\n",
    "                                    \"side\": \"SELL\",\n",
    "                                    \"shares\": int(trade_sh),\n",
    "                                    \"reason\": \"rebalance_down\",\n",
    "                                    \"rank\": rank,\n",
    "                                })\n",
    "\n",
    "                            # -------- BUY (rebalance up / new entry) --------\n",
    "                            elif target_sh > cur_sh:\n",
    "                                if not can_buy_next_open:\n",
    "                                    continue\n",
    "\n",
    "                                trade_sh = target_sh - cur_sh\n",
    "                                est_value = trade_sh * p\n",
    "\n",
    "                                if is_new_position and target_weight < MIN_NEW_POSITION_WEIGHT:\n",
    "                                    continue\n",
    "\n",
    "                                if est_value < MIN_TRADE_VALUE:\n",
    "                                    continue\n",
    "\n",
    "                                # IMPORTANT: skip (NO CLIP) to match generator\n",
    "                                if est_value > (cash_plan - MIN_CASH_RESERVE):\n",
    "                                    exec_diag[\"dropped_cash_floor_buy\"] += 1\n",
    "                                    continue\n",
    "\n",
    "                                cash_plan -= est_value\n",
    "                                pos_plan[t] = cur_sh + trade_sh\n",
    "\n",
    "                                planned.append({\n",
    "                                    \"ticker\": t,\n",
    "                                    \"side\": \"BUY\",\n",
    "                                    \"shares\": int(trade_sh),\n",
    "                                    \"reason\": (\"rebalance_up\" if cur_sh > 0 else \"new_entry\"),\n",
    "                                    \"rank\": rank,\n",
    "                                })\n",
    "                if date == pd.Timestamp(\"2010-11-24\"):\n",
    "                    print(\"\\n=== DEBUG 2010-11-24 PLAN ===\")\n",
    "                    print(\"trade_date:\", trade_date)\n",
    "                    print(\"spy_above_200:\", spy_above_200)\n",
    "                    print(\"positions_before:\", len(positions))\n",
    "                    print(\"top_group_size:\", len(top_group))\n",
    "                    print(\"exit_tickers:\", len([t for t in positions.keys() if t not in top_tickers]))\n",
    "                    print(\"planned_trades:\", len(planned))\n",
    "                    if planned:\n",
    "                        print(\"planned sample:\", planned[:10])\n",
    "\n",
    "                # Store for execution on trade_date open\n",
    "                pending_orders[trade_date] = {\n",
    "                    \"signal_date\": date,\n",
    "                    \"spy_above_200\": spy_above_200,\n",
    "                    \"open_px_map\": open_px_map,\n",
    "                    \"planned_trades\": planned,\n",
    "                }\n",
    "                exec_diag[\"orders_seen\"] += len(planned)\n",
    "\n",
    "    # =======================================================\n",
    "    # 2) DAILY MARK-TO-MARKET (end of day close)\n",
    "    # =======================================================\n",
    "    equity_close, portfolio_value_close, num_positions = snapshot_portfolio_close(\n",
    "        date, cash, positions, px_by_ticker\n",
    "    )\n",
    "    last_equity_close = portfolio_value_close\n",
    "\n",
    "    equity_curve.append({\n",
    "        \"date\": date,\n",
    "        \"portfolio_value\": portfolio_value_close,\n",
    "        \"cash\": cash,\n",
    "        \"num_positions\": num_positions,\n",
    "    })\n",
    "\n",
    "# ============================================================\n",
    "# SAVE TRADES, EQUITY, AND WEEKLY RANKINGS\n",
    "# ============================================================\n",
    "\n",
    "trades = pd.DataFrame(history)\n",
    "equity_df = pd.DataFrame(equity_curve)\n",
    "rankings_df = pd.DataFrame(weekly_rankings)\n",
    "\n",
    "trades_file = os.path.join(OUTPUT_DIR_TRADES, \"13-trades_regression_insp500_spyfilter_cap15.parquet\")\n",
    "equity_file = os.path.join(OUTPUT_DIR_TRADES, \"13-equity_curve_regression_insp500_spyfilter_cap15.parquet\")\n",
    "rankings_file = os.path.join(OUTPUT_DIR_TRADES, \"13-weekly_rankings_pre_filter_cap15.parquet\")\n",
    "\n",
    "trades.to_parquet(trades_file, index=False)\n",
    "equity_df.to_parquet(equity_file, index=False)\n",
    "rankings_df.to_parquet(rankings_file, index=False)\n",
    "\n",
    "print(\"=== TRADING COMPLETE ===\")\n",
    "print(\"Final portfolio value:\", portfolio_value_close)\n",
    "print(\"Final cash balance:\", cash)\n",
    "print(\"Total trades:\", len(trades))\n",
    "print(\"Total weekly rankings:\", len(rankings_df))\n",
    "print(f\"Trades saved to:    {trades_file}\")\n",
    "print(f\"Equity saved to:    {equity_file}\")\n",
    "print(f\"Rankings saved to:  {rankings_file}\\n\")\n",
    "\n",
    "print(\"Diagnostics:\")\n",
    "print(f\"  orders_seen (planned):        {exec_diag['orders_seen']}\")\n",
    "print(f\"  orders_executed (fills):      {exec_diag['orders_executed']}\")\n",
    "print(f\"  dropped_missing_open:         {exec_diag['dropped_missing_open']}\")\n",
    "print(f\"  dropped_cash_floor_buy(plan): {exec_diag['dropped_cash_floor_buy']}\")\n",
    "print(f\"  warn_exec_cash_breach:        {exec_diag['warn_exec_cash_breach']}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# PERFORMANCE ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== PERFORMANCE ANALYSIS (Regression-Only System) ===\")\n",
    "\n",
    "if \"spy_close\" not in spy.columns:\n",
    "    if \"Close\" in spy.columns:\n",
    "        spy[\"spy_close\"] = spy[\"Close\"]\n",
    "    else:\n",
    "        raise ValueError(\"Cannot find a SPY close column for performance merge.\")\n",
    "\n",
    "eq = equity_df.copy()\n",
    "eq[\"date\"] = pd.to_datetime(eq[\"date\"])\n",
    "\n",
    "df_perf = eq.merge(spy[[\"date\", \"spy_close\"]], on=\"date\", how=\"inner\")\n",
    "df_perf = df_perf.sort_values(\"date\")\n",
    "\n",
    "print(f\"Loaded equity curve: {len(eq):,} rows\")\n",
    "print(f\"Loaded SPY file:     {len(spy):,} rows\")\n",
    "print(f\"Merged dataset:      {len(df_perf):,} rows\\n\")\n",
    "\n",
    "df_perf[\"strat_ret\"] = df_perf[\"portfolio_value\"].pct_change().fillna(0)\n",
    "df_perf[\"spy_ret\"]   = df_perf[\"spy_close\"].pct_change().fillna(0)\n",
    "df_perf[\"year\"]      = df_perf[\"date\"].dt.year\n",
    "\n",
    "def cagr(total_return, n_years):\n",
    "    return (1 + total_return)**(1 / n_years) - 1 if n_years > 0 else np.nan\n",
    "\n",
    "def max_drawdown(series):\n",
    "    roll_max = series.cummax()\n",
    "    dd = series / roll_max - 1\n",
    "    return dd.min()\n",
    "\n",
    "def sharpe(returns, rf=0.0):\n",
    "    if returns.std() == 0:\n",
    "        return 0\n",
    "    return (returns.mean() - rf) / returns.std() * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "\n",
    "def sortino(returns, rf=0.0):\n",
    "    downside = returns[returns < 0]\n",
    "    if downside.std() == 0:\n",
    "        return 0\n",
    "    return (returns.mean() - rf) / downside.std() * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "\n",
    "start_val = df_perf[\"portfolio_value\"].iloc[0]\n",
    "end_val   = df_perf[\"portfolio_value\"].iloc[-1]\n",
    "total_ret = end_val / start_val - 1\n",
    "\n",
    "n_years = (df_perf[\"date\"].iloc[-1] - df_perf[\"date\"].iloc[0]).days / 365.25\n",
    "\n",
    "strat_cagr   = cagr(total_ret, n_years)\n",
    "strat_vol    = df_perf[\"strat_ret\"].std() * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "strat_sharpe = sharpe(df_perf[\"strat_ret\"])\n",
    "strat_sortino = sortino(df_perf[\"strat_ret\"])\n",
    "strat_maxdd  = max_drawdown(df_perf[\"portfolio_value\"])\n",
    "strat_calmar = strat_cagr / abs(strat_maxdd) if strat_maxdd != 0 else np.nan\n",
    "\n",
    "spy_total_ret = df_perf[\"spy_close\"].iloc[-1] / df_perf[\"spy_close\"].iloc[0] - 1\n",
    "spy_cagr   = cagr(spy_total_ret, n_years)\n",
    "spy_vol    = df_perf[\"spy_ret\"].std() * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "spy_sharpe = sharpe(df_perf[\"spy_ret\"])\n",
    "spy_sortino = sortino(df_perf[\"spy_ret\"])\n",
    "spy_maxdd  = max_drawdown(df_perf[\"spy_close\"])\n",
    "spy_calmar = spy_cagr / abs(spy_maxdd) if spy_maxdd != 0 else np.nan\n",
    "\n",
    "def year_stats(g):\n",
    "    start = g[\"portfolio_value\"].iloc[0]\n",
    "    end   = g[\"portfolio_value\"].iloc[-1]\n",
    "\n",
    "    pv = g[\"portfolio_value\"]\n",
    "    rollmax = pv.cummax()\n",
    "    dd = (pv / rollmax - 1).min()\n",
    "\n",
    "    spy_start = g[\"spy_close\"].iloc[0]\n",
    "    spy_end   = g[\"spy_close\"].iloc[-1]\n",
    "    spy_dd    = max_drawdown(g[\"spy_close\"])\n",
    "\n",
    "    return pd.Series({\n",
    "        \"start_value\": start,\n",
    "        \"end_value\": end,\n",
    "        \"strat_return\": end/start - 1,\n",
    "        \"strat_maxdd\": dd,\n",
    "        \"strat_sharpe\": sharpe(g[\"strat_ret\"]),\n",
    "        \"strat_sortino\": sortino(g[\"strat_ret\"]),\n",
    "        \"strat_calmar\": (end/start - 1)/abs(dd) if dd != 0 else np.nan,\n",
    "        \"spy_return\": spy_end/spy_start - 1,\n",
    "        \"spy_maxdd\": spy_dd,\n",
    "        \"spy_sharpe\": sharpe(g[\"spy_ret\"]),\n",
    "        \"spy_sortino\": sortino(g[\"spy_ret\"]),\n",
    "        \"spy_calmar\": (spy_end/spy_start - 1)/abs(spy_dd) if spy_dd != 0 else np.nan\n",
    "    })\n",
    "\n",
    "yearly = df_perf.groupby(\"year\", group_keys=False).apply(year_stats)\n",
    "\n",
    "print(\"=== Strategy Performance ===\")\n",
    "print(f\"CAGR:          {strat_cagr:8.4f}\")\n",
    "print(f\"Volatility:    {strat_vol:8.4f}\")\n",
    "print(f\"Sharpe:        {strat_sharpe:8.4f}\")\n",
    "print(f\"Sortino:       {strat_sortino:8.4f}\")\n",
    "print(f\"MaxDD:         {strat_maxdd:8.4f}\")\n",
    "print(f\"Calmar:        {strat_calmar:8.4f}\\n\")\n",
    "\n",
    "print(\"=== SPY Benchmark ===\")\n",
    "print(f\"CAGR:          {spy_cagr:8.4f}\")\n",
    "print(f\"Volatility:    {spy_vol:8.4f}\")\n",
    "print(f\"Sharpe:        {spy_sharpe:8.4f}\")\n",
    "print(f\"Sortino:       {spy_sortino:8.4f}\")\n",
    "print(f\"MaxDD:         {spy_maxdd:8.4f}\")\n",
    "print(f\"Calmar:        {spy_calmar:8.4f}\\n\")\n",
    "\n",
    "print(\"=== Year-by-Year Comparison ===\")\n",
    "print(yearly)\n",
    "\n",
    "yearly_path  = os.path.join(OUTPUT_DIR_PERF, \"14-regression_insp500_spyfilter-yearly_comparison_cap15.csv\")\n",
    "summary_path = os.path.join(OUTPUT_DIR_PERF, \"14-regression_insp500_spyfilter-performance_summary_cap15.csv\")\n",
    "\n",
    "df_summary = pd.DataFrame([{\n",
    "    \"spy_regime_confirm_days\": SPY_REGIME_CONFIRM_DAYS,\n",
    "    \"strat_cagr\": strat_cagr,\n",
    "    \"strat_vol\": strat_vol,\n",
    "    \"strat_sharpe\": strat_sharpe,\n",
    "    \"strat_sortino\": strat_sortino,\n",
    "    \"strat_maxdd\": strat_maxdd,\n",
    "    \"strat_calmar\": strat_calmar,\n",
    "    \"spy_cagr\": spy_cagr,\n",
    "    \"spy_vol\": spy_vol,\n",
    "    \"spy_sharpe\": spy_sharpe,\n",
    "    \"spy_sortino\": spy_sortino,\n",
    "    \"spy_maxdd\": spy_maxdd,\n",
    "    \"spy_calmar\": spy_calmar,\n",
    "}])\n",
    "\n",
    "yearly.to_csv(yearly_path)\n",
    "df_summary.to_csv(summary_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(f\"  → {summary_path}\")\n",
    "print(f\"  → {yearly_path}\")\n",
    "print(\"\\n=== COMPLETE ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_quant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
