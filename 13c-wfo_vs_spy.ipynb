{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e586262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " REGIME-BASED PERFORMANCE ANALYSIS: STRATEGY vs SPY (v2)\n",
      "================================================================================\n",
      "\n",
      "Data range: 2000-01-03 to 2024-12-31\n",
      "Total aligned days: 6,289 (24.96 years)\n",
      "Bull market days (SPY > 200 DMA): 4,616 (73.4%)\n",
      "Bear market days (SPY < 200 DMA): 1,673 (26.6%)\n",
      "\n",
      "================================================================================\n",
      " SECTION 1: OVERALL STATISTICS (Full Contiguous Series)\n",
      "================================================================================\n",
      "\n",
      "  Metric                                Strategy             SPY            Diff\n",
      "  ------------------------------ --------------- --------------- ---------------\n",
      "  Ann. Return                             16.11%           7.63%           5.63%\n",
      "  Ann. Volatility                         15.82%          19.39%          17.21%\n",
      "  Sharpe Ratio                             1.024           0.476           0.548\n",
      "  Max Drawdown                           -28.21%         -55.19%          26.98%\n",
      "  Win Rate                                47.81%          54.40%          -6.58%\n",
      "  \n",
      "  Information Ratio                        0.405\n",
      "  Ann. Excess Return (correct)             5.63%\n",
      "\n",
      "================================================================================\n",
      " SECTION 2: CONTIGUOUS SEGMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "  This analyzes each continuous bull/bear period separately,\n",
      "  avoiding the pitfalls of stitching non-contiguous days together.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " BEAR MARKET SEGMENTS (SPY < 200 DMA)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Found 89 contiguous bear segment(s):\n",
      "  #    Start        End          Days   Strat Tot    SPY Tot      Excess       Strat DD   SPY DD    \n",
      "  ---- ------------ ------------ ------ ------------ ------------ ------------ ---------- ----------\n",
      "  1    2000-02-18   2000-02-22   2           -3.14%      -2.40%      -0.74%    -0.09%    -0.25%\n",
      "  2    2000-02-24   2000-02-25   2            5.38%      -2.37%       7.75%     0.00%    -0.36%\n",
      "  3    2000-04-14   2000-04-14   1           -8.38%      -5.72%      -2.66%     0.00%     0.00%\n",
      "  4    2000-05-10   2000-05-10   1           -4.09%      -2.26%      -1.84%     0.00%     0.00%\n",
      "  5    2000-05-23   2000-05-23   1            0.71%      -1.47%       2.18%     0.00%     0.00%\n",
      "  6    2000-05-25   2000-05-26   2           -1.86%      -1.60%      -0.26%    -1.57%     0.00%\n",
      "  7    2000-07-28   2000-07-28   1           -0.78%      -2.26%       1.48%     0.00%     0.00%\n",
      "  8    2000-09-21   2000-09-21   1            0.16%      -1.52%       1.68%     0.00%     0.00%\n",
      "  9    2000-09-25   2000-09-27   3            3.08%      -1.46%       4.54%     0.00%    -1.28%\n",
      "  10   2000-09-29   2002-01-02   313         -0.89%     -19.06%      18.16%    -4.94%   -31.69%\n",
      "  11   2002-01-09   2002-03-01   36           0.00%      -2.39%       2.39%     0.00%    -6.94%\n",
      "  12   2002-03-25   2002-03-25   1           -0.35%      -1.24%       0.89%     0.00%     0.00%\n",
      "  13   2002-04-03   2002-04-09   5            2.09%      -1.58%       3.67%     0.00%    -0.88%\n",
      "  14   2002-04-11   2002-04-15   3           -0.34%      -2.50%       2.16%     0.00%    -0.76%\n",
      "  15   2002-04-17   2003-03-20   234         -1.96%     -21.12%      19.16%    -1.61%   -30.31%\n",
      "  16   2003-03-24   2003-04-03   9            0.00%      -2.20%       2.20%     0.00%    -3.18%\n",
      "  17   2003-04-07   2003-04-07   1            0.00%      -0.19%       0.19%     0.00%     0.00%\n",
      "  18   2003-04-09   2003-04-11   3            0.00%      -1.18%       1.18%     0.00%    -0.41%\n",
      "  19   2004-07-21   2004-07-28   6           -2.94%      -1.38%      -1.56%    -2.01%    -1.03%\n",
      "  20   2004-08-03   2004-08-24   16          -2.25%      -0.65%      -1.61%    -2.82%    -3.05%\n",
      "  21   2004-08-30   2004-08-30   1            0.18%      -0.83%       1.01%     0.00%     0.00%\n",
      "  22   2004-09-23   2004-09-23   1           -0.76%      -0.54%      -0.22%     0.00%     0.00%\n",
      "  23   2004-09-27   2004-09-28   2            0.65%      -0.16%       0.81%     0.00%     0.00%\n",
      "  24   2004-10-13   2004-10-15   3           -0.91%      -1.13%       0.22%     0.00%    -0.81%\n",
      "  25   2004-10-19   2004-10-26   6            0.78%      -0.13%       0.91%    -0.45%    -1.24%\n",
      "  26   2005-04-15   2005-04-18   2           -1.03%      -1.10%       0.07%     0.00%     0.00%\n",
      "  27   2005-04-20   2005-04-20   1           -0.83%      -1.40%       0.57%     0.00%     0.00%\n",
      "  28   2005-04-28   2005-04-28   1           -0.54%      -1.25%       0.72%     0.00%     0.00%\n",
      "  29   2005-10-06   2005-10-06   1           -1.00%      -0.36%      -0.64%     0.00%     0.00%\n",
      "  30   2005-10-10   2005-10-18   7           -0.88%      -1.50%       0.62%    -1.24%    -1.08%\n",
      "  31   2005-10-20   2005-10-21   2           -0.02%      -1.38%       1.36%    -0.03%     0.00%\n",
      "  32   2005-10-27   2005-10-27   1            0.02%      -1.06%       1.08%     0.00%     0.00%\n",
      "  33   2006-06-09   2006-06-14   4           -2.31%      -1.79%      -0.52%    -2.47%    -2.23%\n",
      "  34   2006-06-16   2006-06-28   9           -0.20%      -0.65%       0.45%    -1.16%    -0.88%\n",
      "  35   2006-07-13   2006-07-18   4           -2.82%      -1.65%      -1.17%    -1.18%    -0.53%\n",
      "  36   2006-07-20   2006-07-21   2           -1.50%      -1.38%      -0.12%    -0.89%    -0.70%\n",
      "  37   2007-08-03   2007-08-03   1           -3.02%      -2.57%      -0.45%     0.00%     0.00%\n",
      "  38   2007-08-14   2007-08-16   3           -4.96%      -2.16%      -2.80%    -3.71%    -1.38%\n",
      "  39   2007-08-20   2007-08-20   1            0.44%      -0.05%       0.49%     0.00%     0.00%\n",
      "  40   2007-08-28   2007-08-28   1           -2.84%      -2.20%      -0.64%     0.00%     0.00%\n",
      "  41   2007-11-08   2007-11-12   3           -9.28%      -2.85%      -6.44%    -7.15%    -2.35%\n",
      "  42   2007-11-15   2007-11-29   10           2.28%      -0.33%       2.61%    -1.56%    -3.32%\n",
      "  43   2007-12-04   2007-12-04   1            0.08%      -0.89%       0.97%     0.00%     0.00%\n",
      "  44   2007-12-14   2007-12-20   5           -0.97%      -1.52%       0.55%    -1.57%    -1.43%\n",
      "  45   2007-12-28   2008-05-05   88          -6.21%      -4.16%      -2.05%   -10.59%   -13.10%\n",
      "  46   2008-05-07   2008-05-14   6           -0.05%      -0.90%       0.85%    -0.08%    -0.44%\n",
      "  47   2008-05-21   2009-05-28   257         -0.20%     -34.24%      34.04%    -0.23%   -50.70%\n",
      "  48   2010-05-20   2010-05-26   5           -1.77%      -4.11%       2.34%    -1.69%    -1.78%\n",
      "  49   2010-05-28   2010-06-01   2           -2.79%      -2.92%       0.12%    -1.92%    -1.68%\n",
      "  50   2010-06-04   2010-06-14   7           -1.24%      -1.08%      -0.16%    -2.18%    -1.25%\n",
      "  51   2010-06-22   2010-07-23   23          -3.11%      -0.90%      -2.21%    -6.79%    -6.73%\n",
      "  52   2010-07-29   2010-07-30   2           -0.90%      -0.51%      -0.40%    -0.10%    -0.02%\n",
      "  53   2010-08-11   2010-09-09   21           0.80%      -1.30%       2.09%    -0.63%    -4.15%\n",
      "  54   2011-08-02   2011-10-26   61          -6.03%      -2.98%      -3.05%    -7.74%   -12.42%\n",
      "  55   2011-10-31   2011-11-07   6            0.14%      -1.82%       1.95%    -0.14%    -2.79%\n",
      "  56   2011-11-09   2011-11-10   2           -0.11%      -2.78%       2.68%     0.00%     0.00%\n",
      "  57   2011-11-14   2011-12-02   14          -0.07%      -1.42%       1.35%    -0.08%    -7.73%\n",
      "  58   2011-12-08   2011-12-08   1           -0.70%      -2.19%       1.49%     0.00%     0.00%\n",
      "  59   2011-12-12   2011-12-21   8           -0.38%      -0.87%       0.49%    -2.19%    -2.54%\n",
      "  60   2012-11-14   2012-11-16   3            0.31%      -1.03%       1.34%     0.00%    -0.17%\n",
      "  61   2014-10-13   2014-10-17   5           -2.19%      -1.09%      -1.11%    -1.54%    -0.76%\n",
      "  62   2015-08-20   2015-10-21   44          -3.08%      -2.60%      -0.48%    -5.12%    -8.19%\n",
      "  63   2015-11-12   2015-11-13   2           -1.46%      -2.50%       1.05%    -0.74%    -1.12%\n",
      "  64   2015-12-11   2015-12-15   3           -0.42%      -0.41%      -0.01%     0.00%     0.00%\n",
      "  65   2015-12-17   2015-12-22   4            0.10%      -1.60%       1.70%    -1.82%    -1.78%\n",
      "  66   2015-12-31   2016-03-10   48          -8.34%      -3.10%      -5.24%    -8.63%   -10.31%\n",
      "  67   2016-06-27   2016-06-27   1           -1.33%      -1.79%       0.46%     0.00%     0.00%\n",
      "  68   2018-10-11   2018-10-11   1           -2.66%      -2.20%      -0.46%     0.00%     0.00%\n",
      "  69   2018-10-23   2018-11-05   10          -2.11%      -0.59%      -1.52%    -3.72%    -3.56%\n",
      "  70   2018-11-12   2018-11-27   11          -3.67%      -3.37%      -0.31%    -3.87%    -3.83%\n",
      "  71   2018-11-29   2018-11-29   1            0.15%      -0.22%       0.37%     0.00%     0.00%\n",
      "  72   2018-12-04   2019-02-01   40          -3.87%      -2.74%      -1.13%    -7.37%   -12.78%\n",
      "  73   2019-02-07   2019-02-11   3            0.70%      -0.78%       1.47%     0.00%     0.00%\n",
      "  74   2019-05-31   2019-06-03   2           -0.54%      -1.60%       1.06%     0.00%    -0.25%\n",
      "  75   2020-02-27   2020-02-28   2           -3.87%      -4.89%       1.03%    -1.03%    -0.42%\n",
      "  76   2020-03-03   2020-03-03   1           -2.85%      -2.86%       0.02%     0.00%     0.00%\n",
      "  77   2020-03-05   2020-05-22   56         -10.23%      -5.01%      -5.22%   -23.13%   -25.85%\n",
      "  78   2022-01-21   2022-01-21   1           -2.21%      -1.96%      -0.24%     0.00%     0.00%\n",
      "  79   2022-01-25   2022-01-27   3           -0.46%      -1.96%       1.49%     0.00%    -0.74%\n",
      "  80   2022-02-11   2022-02-14   2           -1.31%      -2.29%       0.98%    -1.00%    -0.33%\n",
      "  81   2022-02-17   2022-03-17   20           0.90%      -1.24%       2.14%    -2.48%    -4.94%\n",
      "  82   2022-04-11   2022-08-15   87          -4.65%      -3.77%      -0.89%    -9.70%   -17.61%\n",
      "  83   2022-08-17   2022-11-29   73           0.00%      -7.64%       7.64%     0.00%   -16.33%\n",
      "  84   2022-12-05   2022-12-12   6           -3.03%      -1.96%      -1.07%    -2.42%    -1.61%\n",
      "  85   2022-12-14   2023-01-10   18           0.35%      -2.39%       2.74%    -2.14%    -5.26%\n",
      "  86   2023-01-18   2023-01-19   2           -1.27%      -2.30%       1.03%    -0.65%    -0.73%\n",
      "  87   2023-03-10   2023-03-13   2           -1.39%      -1.58%       0.19%    -0.37%    -0.14%\n",
      "  88   2023-03-15   2023-03-15   1           -1.38%      -0.63%      -0.75%     0.00%     0.00%\n",
      "  89   2023-10-25   2023-10-31   5           -0.38%      -1.28%       0.90%    -1.62%    -1.65%\n",
      "\n",
      "  Summary across bear segments:\n",
      "    Excess return: mean=1.18%, median=0.55%\n",
      "    Strategy beat SPY in 56/89 segments (62.9%)\n",
      "    Strategy max DD: worst=-23.13%, median=-0.09%\n",
      "    SPY max DD: worst=-50.70%, median=-0.74%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " BULL MARKET SEGMENTS (SPY > 200 DMA)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Found 90 contiguous bull segment(s).\n",
      "\n",
      "  Summary across bull segments:\n",
      "    Excess return: mean=1.21%, median=-0.30%\n",
      "    Strategy beat SPY in 35/90 segments (38.9%)\n",
      "    Strategy max DD: worst=-17.73%, median=-0.55%\n",
      "\n",
      "================================================================================\n",
      " SECTION 3: CONDITIONAL STATISTICS (Days Labeled as Bull/Bear)\n",
      "================================================================================\n",
      "\n",
      "  These stats describe behavior conditional on regime, NOT tradable returns.\n",
      "\n",
      "  Conditional Statistics (Bull days, n=4,616):\n",
      "  NOTE: These are 'conditional on regime' stats, not tradable regime returns.\n",
      "  \n",
      "  Metric                                Strategy             SPY            Diff\n",
      "  ------------------------------ --------------- --------------- ---------------\n",
      "  Mean daily return                      0.1147%         0.0969%         0.0178%\n",
      "  Daily volatility                       1.0369%         0.8376%         0.1994%\n",
      "  Win rate                                56.00%          57.11%          -1.10%\n",
      "  \n",
      "  Ann. Sharpe (conditional)                1.756           1.837          -0.081\n",
      "  IR (Sharpe of excess)                    0.376\n",
      "  Ann. excess return                       3.84%\n",
      "\n",
      "  Conditional Statistics (Bear days, n=1,673):\n",
      "  NOTE: These are 'conditional on regime' stats, not tradable regime returns.\n",
      "  \n",
      "  Metric                                Strategy             SPY            Diff\n",
      "  ------------------------------ --------------- --------------- ---------------\n",
      "  Mean daily return                     -0.0749%        -0.1297%         0.0548%\n",
      "  Daily volatility                       0.8589%         1.9064%        -1.0475%\n",
      "  Win rate                                25.22%          46.92%         -21.70%\n",
      "  \n",
      "  Ann. Sharpe (conditional)               -1.383          -1.080          -0.304\n",
      "  IR (Sharpe of excess)                    0.514\n",
      "  Ann. excess return                      10.72%\n",
      "\n",
      "================================================================================\n",
      " SECTION 4A: SIMPLE BOOTSTRAP (Original Method - For Comparison)\n",
      "================================================================================\n",
      "\n",
      "  This uses the SIMPLE method from the original script:\n",
      "  - Bootstrap the excess returns directly\n",
      "  - Compute Sharpe(excess) on each bootstrap sample\n",
      "  - Does NOT preserve regime structure\n",
      "\n",
      "  IR point estimate (Sharpe of excess): 0.405\n",
      "  Sharpe(strat) - Sharpe(SPY): 0.548\n",
      "\n",
      "  Block bootstrap sensitivity (IR > 0 one-sided test):\n",
      "  Block    95% CI                   p(IR<=0)     p (2-sided)  Sig?    \n",
      "  -------- ------------------------ ------------ ------------ --------\n",
      "       5   [ 0.052,  0.773]       0.0120       0.0240       Yes **\n",
      "      10   [ 0.055,  0.777]       0.0110       0.0220       Yes **\n",
      "      21   [ 0.032,  0.760]       0.0162       0.0324       Yes **\n",
      "      42   [ 0.035,  0.733]       0.0174       0.0348       Yes **\n",
      "      63   [ 0.032,  0.680]       0.0144       0.0288       Yes **\n",
      "\n",
      "================================================================================\n",
      " SECTION 4B: REGIME-AWARE BOOTSTRAP (v2 Method)\n",
      "================================================================================\n",
      "\n",
      "  Bootstrap performed on FULL contiguous series, then regime stats computed.\n",
      "  This preserves the time-series dependence structure correctly.\n",
      "\n",
      "  Running bootstrap (this may take a moment)...\n",
      "\n",
      "  Bootstrap Results for Overall (n_boot=5000, block_len=21):\n",
      "    IR point estimate (median): 0.404\n",
      "    95% CI: [0.032, 0.760]\n",
      "    One-sided p-value (H0: IR ≤ 0): 0.0162\n",
      "    Two-sided p-value (H0: IR = 0): 0.0324\n",
      "    Significant at α=0.05 (two-sided): Yes **\n",
      "\n",
      "  Bootstrap Results for Bull Market (n_boot=5000, block_len=21):\n",
      "    IR point estimate (median): 0.368\n",
      "    95% CI: [-0.119, 0.858]\n",
      "    One-sided p-value (H0: IR ≤ 0): 0.0680\n",
      "    Two-sided p-value (H0: IR = 0): 0.1360\n",
      "    Significant at α=0.05 (two-sided): No\n",
      "\n",
      "  Bootstrap Results for Bear Market (n_boot=5000, block_len=21):\n",
      "    IR point estimate (median): 0.516\n",
      "    95% CI: [-0.135, 1.119]\n",
      "    One-sided p-value (H0: IR ≤ 0): 0.0550\n",
      "    Two-sided p-value (H0: IR = 0): 0.1100\n",
      "    Significant at α=0.05 (two-sided): No\n",
      "\n",
      "================================================================================\n",
      " SECTION 4C: METHOD COMPARISON - WHY THE DISCREPANCY?\n",
      "================================================================================\n",
      "\n",
      "  Comparison at block_len=21:\n",
      "  Method                    IR         95% CI                   p (1-side)   p (2-side)  \n",
      "  ------------------------- ---------- ------------------------ ------------ ------------\n",
      "  Simple (excess only)      0.405      [0.032, 0.760]       0.0162       0.0324\n",
      "  Regime-aware (overall)    0.404      [0.032, 0.760]       0.0162       0.0324\n",
      "\n",
      "  EXPLANATION OF DISCREPANCY:\n",
      "\n",
      "  Both methods bootstrap the SAME underlying data, but:\n",
      "\n",
      "  1. SIMPLE METHOD: \n",
      "     - Resamples excess returns (strat - spy) directly\n",
      "     - Computes Sharpe of the resampled excess returns\n",
      "     - Each bootstrap sample has the SAME number of observations\n",
      "\n",
      "  2. REGIME-AWARE METHOD:\n",
      "     - Resamples the full series (strat, spy, AND regime labels together)\n",
      "     - Then computes regime-specific stats on each bootstrap sample\n",
      "     - The \"overall\" IR should theoretically match, but...\n",
      "     - Regime proportions can vary between bootstrap samples\n",
      "\n",
      "  The discrepancy likely comes from:\n",
      "  - Random seed handling differences between the two bootstrap loops\n",
      "  - The regime method resamples regime labels too, which can slightly \n",
      "    change the effective weighting\n",
      "  - Numerical precision in how returns are combined\n",
      "\n",
      "  For OVERALL IR, the SIMPLE method is actually more direct and appropriate.\n",
      "  The REGIME method is designed for comparing bull vs bear performance.\n",
      "\n",
      "\n",
      "================================================================================\n",
      " SECTION 5: KEY FINDINGS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "  Regime          IR         95% CI                    Significant?   \n",
      "  --------------- ---------- ------------------------- ---------------\n",
      "  Overall         0.405      [0.032, 0.760]           YES            \n",
      "  Bull            0.376      [-0.119, 0.858]           NO             \n",
      "  Bear            0.514      [-0.135, 1.119]           NO             \n",
      "\n",
      "  Bear market segment win rate: 56/89 (62.9%)\n",
      "  Worst bear segment: Strategy -10.2% vs SPY -34.2%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " INTERPRETATION NOTES:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  1. OVERALL IR: Tests whether strategy has risk-adjusted alpha vs SPY across\n",
      "     the full time period. This is the most reliable test.\n",
      "\n",
      "  2. REGIME IRs: These test conditional performance, but interpretation requires\n",
      "     care - the bootstrap resamples the full series, so regime proportions may\n",
      "     vary across samples.\n",
      "\n",
      "  3. SEGMENT ANALYSIS: Shows actual performance in each contiguous bear/bull\n",
      "     market. This is the most intuitive way to see \"what happened in 2008\" etc.\n",
      "\n",
      "  4. If you trade based on the regime signal, enable LAG_REGIME=True to avoid\n",
      "     look-ahead bias in this analysis.\n",
      "\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Regime-Based Performance Analysis: Strategy vs SPY (v2)\n",
    "\n",
    "Compares strategy performance against SPY during:\n",
    "- Bull markets (SPY above 200-day MA, regime=1)\n",
    "- Bear markets (SPY below 200-day MA, regime=0)\n",
    "\n",
    "Key improvements over v1:\n",
    "- Contiguous segment analysis (no artificial stitching)\n",
    "- Correct excess return calculation: ann_return(strat - spy)\n",
    "- Bootstrap on full series, then compute regime stats (preserves time structure)\n",
    "- Regime lag option to avoid look-ahead bias\n",
    "- Per-segment breakdown for bear/bull markets\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "EQUITY_FILE = \"./13b-wfo/walkforward_top48_equity_curve.csv\"\n",
    "SPY_PARQUET = \"./8-SPY_200DMA_market_regime/8-SPY_200DMA_regime.parquet\"\n",
    "\n",
    "N_BOOT = 5000\n",
    "BLOCK_LEN = 21  # Primary block length for bootstrap\n",
    "BLOCK_LENS = [5, 10, 21, 42, 63]  # For sensitivity check (simple method)\n",
    "SEED = 7\n",
    "\n",
    "# Set to True if your strategy uses the regime signal for trading decisions\n",
    "# This will lag the regime by 1 day to avoid look-ahead bias\n",
    "LAG_REGIME = False\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DATA CLASSES\n",
    "# =========================\n",
    "@dataclass\n",
    "class SegmentStats:\n",
    "    \"\"\"Statistics for a contiguous regime segment.\"\"\"\n",
    "    start_date: pd.Timestamp\n",
    "    end_date: pd.Timestamp\n",
    "    n_days: int\n",
    "    strat_total_return: float\n",
    "    spy_total_return: float\n",
    "    strat_ann_return: float\n",
    "    spy_ann_return: float\n",
    "    excess_total_return: float\n",
    "    strat_max_dd: float\n",
    "    spy_max_dd: float\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def ann_sharpe(r: np.ndarray) -> float:\n",
    "    \"\"\"Annualized Sharpe ratio (assuming zero risk-free rate).\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 2:\n",
    "        return np.nan\n",
    "    sd = r.std(ddof=1)\n",
    "    if sd <= 0 or np.isnan(sd):\n",
    "        return 0.0\n",
    "    return np.sqrt(TRADING_DAYS) * r.mean() / sd\n",
    "\n",
    "\n",
    "def ann_return(r: np.ndarray) -> float:\n",
    "    \"\"\"Annualized return from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 2:\n",
    "        return np.nan\n",
    "    total = np.prod(1 + r) - 1\n",
    "    years = r.size / TRADING_DAYS\n",
    "    if years <= 0:\n",
    "        return np.nan\n",
    "    return (1 + total) ** (1 / years) - 1\n",
    "\n",
    "\n",
    "def total_return(r: np.ndarray) -> float:\n",
    "    \"\"\"Total cumulative return from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 1:\n",
    "        return np.nan\n",
    "    return np.prod(1 + r) - 1\n",
    "\n",
    "\n",
    "def ann_volatility(r: np.ndarray) -> float:\n",
    "    \"\"\"Annualized volatility from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 2:\n",
    "        return np.nan\n",
    "    return r.std(ddof=1) * np.sqrt(TRADING_DAYS)\n",
    "\n",
    "\n",
    "def max_drawdown(r: np.ndarray) -> float:\n",
    "    \"\"\"Maximum drawdown from daily returns.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 1:\n",
    "        return np.nan\n",
    "    cum = np.cumprod(1 + r)\n",
    "    running_max = np.maximum.accumulate(cum)\n",
    "    dd = (cum - running_max) / running_max\n",
    "    return dd.min()\n",
    "\n",
    "\n",
    "def win_rate(r: np.ndarray) -> float:\n",
    "    \"\"\"Percentage of positive return days.\"\"\"\n",
    "    r = np.asarray(r, float)\n",
    "    r = r[~np.isnan(r)]\n",
    "    if r.size < 1:\n",
    "        return np.nan\n",
    "    return np.mean(r > 0)\n",
    "\n",
    "\n",
    "def find_contiguous_segments(df: pd.DataFrame, regime_col: str = \"market_regime\") -> List[Tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    Find contiguous segments of the same regime.\n",
    "    Returns list of (start_idx, end_idx, regime_value) tuples.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    if len(df) == 0:\n",
    "        return segments\n",
    "    \n",
    "    regime = df[regime_col].values\n",
    "    start_idx = 0\n",
    "    current_regime = regime[0]\n",
    "    \n",
    "    for i in range(1, len(regime)):\n",
    "        if regime[i] != current_regime:\n",
    "            segments.append((start_idx, i - 1, int(current_regime)))\n",
    "            start_idx = i\n",
    "            current_regime = regime[i]\n",
    "    \n",
    "    # Don't forget the last segment\n",
    "    segments.append((start_idx, len(regime) - 1, int(current_regime)))\n",
    "    \n",
    "    return segments\n",
    "\n",
    "\n",
    "def compute_segment_stats(df: pd.DataFrame, start_idx: int, end_idx: int) -> SegmentStats:\n",
    "    \"\"\"Compute statistics for a single contiguous segment.\"\"\"\n",
    "    segment = df.iloc[start_idx:end_idx + 1]\n",
    "    \n",
    "    strat_ret = segment[\"strat_ret\"].values\n",
    "    spy_ret = segment[\"spy_ret\"].values\n",
    "    n_days = len(segment)\n",
    "    years = n_days / TRADING_DAYS\n",
    "    \n",
    "    strat_total = total_return(strat_ret)\n",
    "    spy_total = total_return(spy_ret)\n",
    "    \n",
    "    # Annualize only if segment is long enough\n",
    "    if years > 0.1:  # At least ~25 days\n",
    "        strat_ann = (1 + strat_total) ** (1 / years) - 1\n",
    "        spy_ann = (1 + spy_total) ** (1 / years) - 1\n",
    "    else:\n",
    "        strat_ann = np.nan\n",
    "        spy_ann = np.nan\n",
    "    \n",
    "    return SegmentStats(\n",
    "        start_date=segment[\"date\"].iloc[0],\n",
    "        end_date=segment[\"date\"].iloc[-1],\n",
    "        n_days=n_days,\n",
    "        strat_total_return=strat_total,\n",
    "        spy_total_return=spy_total,\n",
    "        strat_ann_return=strat_ann,\n",
    "        spy_ann_return=spy_ann,\n",
    "        excess_total_return=strat_total - spy_total,\n",
    "        strat_max_dd=max_drawdown(strat_ret),\n",
    "        spy_max_dd=max_drawdown(spy_ret),\n",
    "    )\n",
    "\n",
    "\n",
    "def block_bootstrap_idx(n: int, block_len: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Stationary-ish block bootstrap via concatenating random contiguous blocks.\n",
    "    Falls back to IID bootstrap if block_len<=1 or block_len>n.\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    if block_len <= 1 or block_len > n:\n",
    "        return rng.integers(0, n, size=n, dtype=int)\n",
    "\n",
    "    idx = []\n",
    "    max_start = n - block_len\n",
    "    while len(idx) < n:\n",
    "        s = int(rng.integers(0, max_start + 1))\n",
    "        idx.extend(range(s, s + block_len))\n",
    "    return np.array(idx[:n], dtype=int)\n",
    "\n",
    "\n",
    "def bootstrap_ir_simple(df: pd.DataFrame, n_boot: int = 5000, block_len: int = 21, seed: int = 7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simple bootstrap distribution of IR = Sharpe(excess), where excess = strat_ret - spy_ret.\n",
    "    This is the METHOD FROM THE ORIGINAL SCRIPT for comparison.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    ex = (df[\"strat_ret\"] - df[\"spy_ret\"]).to_numpy(dtype=float)\n",
    "    ex = ex[~np.isnan(ex)]\n",
    "    n = len(ex)\n",
    "    if n < 2:\n",
    "        return np.array([], dtype=float)\n",
    "\n",
    "    dist = np.empty(n_boot, dtype=float)\n",
    "    for i in range(n_boot):\n",
    "        b = block_bootstrap_idx(n, block_len, rng)\n",
    "        dist[i] = ann_sharpe(ex[b])\n",
    "    return dist\n",
    "\n",
    "\n",
    "def compute_regime_stats_from_returns(\n",
    "    strat_ret: np.ndarray, \n",
    "    spy_ret: np.ndarray, \n",
    "    regime: np.ndarray\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Compute regime statistics from return arrays.\n",
    "    Used for both point estimates and bootstrap samples.\n",
    "    \"\"\"\n",
    "    excess_ret = strat_ret - spy_ret\n",
    "    \n",
    "    bull_mask = regime == 1\n",
    "    bear_mask = regime == 0\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, mask in [(\"bull\", bull_mask), (\"bear\", bear_mask), (\"overall\", np.ones(len(regime), dtype=bool))]:\n",
    "        if mask.sum() < 2:\n",
    "            results[name] = {\n",
    "                \"strat_sharpe\": np.nan,\n",
    "                \"spy_sharpe\": np.nan,\n",
    "                \"ir\": np.nan,\n",
    "                \"excess_ann_return\": np.nan,\n",
    "                \"strat_ann_return\": np.nan,\n",
    "                \"spy_ann_return\": np.nan,\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        s = strat_ret[mask]\n",
    "        p = spy_ret[mask]\n",
    "        e = excess_ret[mask]\n",
    "        \n",
    "        results[name] = {\n",
    "            \"strat_sharpe\": ann_sharpe(s),\n",
    "            \"spy_sharpe\": ann_sharpe(p),\n",
    "            \"ir\": ann_sharpe(e),\n",
    "            \"excess_ann_return\": ann_return(e),  # CORRECT: annualize the excess return stream\n",
    "            \"strat_ann_return\": ann_return(s),\n",
    "            \"spy_ann_return\": ann_return(p),\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def bootstrap_regime_stats(\n",
    "    df: pd.DataFrame, \n",
    "    n_boot: int = 5000, \n",
    "    block_len: int = 21, \n",
    "    seed: int = 7\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Bootstrap on the FULL contiguous series, then compute regime stats per sample.\n",
    "    This preserves the time structure properly.\n",
    "    \n",
    "    Returns dict with keys like 'bull_ir', 'bear_ir', 'overall_ir', etc.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    strat_ret = df[\"strat_ret\"].to_numpy(dtype=float)\n",
    "    spy_ret = df[\"spy_ret\"].to_numpy(dtype=float)\n",
    "    regime = df[\"market_regime\"].to_numpy(dtype=int)\n",
    "    \n",
    "    n = len(df)\n",
    "    \n",
    "    # Initialize result arrays\n",
    "    metrics = [\"ir\", \"strat_sharpe\", \"spy_sharpe\", \"excess_ann_return\"]\n",
    "    regimes = [\"overall\", \"bull\", \"bear\"]\n",
    "    \n",
    "    results = {f\"{r}_{m}\": np.empty(n_boot, dtype=float) for r in regimes for m in metrics}\n",
    "    \n",
    "    for i in range(n_boot):\n",
    "        idx = block_bootstrap_idx(n, block_len, rng)\n",
    "        \n",
    "        # Resample all arrays with the same indices (preserves alignment)\n",
    "        s_boot = strat_ret[idx]\n",
    "        p_boot = spy_ret[idx]\n",
    "        r_boot = regime[idx]\n",
    "        \n",
    "        stats = compute_regime_stats_from_returns(s_boot, p_boot, r_boot)\n",
    "        \n",
    "        for reg in regimes:\n",
    "            for met in metrics:\n",
    "                results[f\"{reg}_{met}\"][i] = stats[reg][met]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_segment_summary(segments: List[SegmentStats], regime_name: str):\n",
    "    \"\"\"Print summary of contiguous segments for a regime.\"\"\"\n",
    "    if not segments:\n",
    "        print(f\"\\n  No {regime_name} segments found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n  Found {len(segments)} contiguous {regime_name} segment(s):\")\n",
    "    print(f\"  {'#':<4} {'Start':<12} {'End':<12} {'Days':<6} {'Strat Tot':<12} {'SPY Tot':<12} {'Excess':<12} {'Strat DD':<10} {'SPY DD':<10}\")\n",
    "    print(f\"  {'-'*4} {'-'*12} {'-'*12} {'-'*6} {'-'*12} {'-'*12} {'-'*12} {'-'*10} {'-'*10}\")\n",
    "    \n",
    "    for i, seg in enumerate(segments, 1):\n",
    "        print(\n",
    "            f\"  {i:<4} \"\n",
    "            f\"{seg.start_date.strftime('%Y-%m-%d'):<12} \"\n",
    "            f\"{seg.end_date.strftime('%Y-%m-%d'):<12} \"\n",
    "            f\"{seg.n_days:<6} \"\n",
    "            f\"{seg.strat_total_return*100:>10.2f}% \"\n",
    "            f\"{seg.spy_total_return*100:>10.2f}% \"\n",
    "            f\"{seg.excess_total_return*100:>10.2f}% \"\n",
    "            f\"{seg.strat_max_dd*100:>8.2f}% \"\n",
    "            f\"{seg.spy_max_dd*100:>8.2f}%\"\n",
    "        )\n",
    "    \n",
    "    # Summary statistics across segments\n",
    "    print(f\"\\n  Summary across {regime_name} segments:\")\n",
    "    \n",
    "    excess_returns = [s.excess_total_return for s in segments]\n",
    "    strat_dds = [s.strat_max_dd for s in segments]\n",
    "    spy_dds = [s.spy_max_dd for s in segments]\n",
    "    \n",
    "    print(f\"    Excess return: mean={np.mean(excess_returns)*100:.2f}%, median={np.median(excess_returns)*100:.2f}%\")\n",
    "    print(f\"    Strategy beat SPY in {sum(1 for e in excess_returns if e > 0)}/{len(segments)} segments ({sum(1 for e in excess_returns if e > 0)/len(segments)*100:.1f}%)\")\n",
    "    print(f\"    Strategy max DD: worst={min(strat_dds)*100:.2f}%, median={np.median(strat_dds)*100:.2f}%\")\n",
    "    print(f\"    SPY max DD: worst={min(spy_dds)*100:.2f}%, median={np.median(spy_dds)*100:.2f}%\")\n",
    "\n",
    "\n",
    "def print_conditional_stats(df: pd.DataFrame, regime_name: str, regime_value: int):\n",
    "    \"\"\"Print conditional statistics (average behavior on days with this regime).\"\"\"\n",
    "    subset = df[df[\"market_regime\"] == regime_value]\n",
    "    \n",
    "    if len(subset) < 2:\n",
    "        print(f\"\\n  Insufficient data for {regime_name} regime.\")\n",
    "        return\n",
    "    \n",
    "    strat_ret = subset[\"strat_ret\"].to_numpy()\n",
    "    spy_ret = subset[\"spy_ret\"].to_numpy()\n",
    "    excess_ret = strat_ret - spy_ret\n",
    "    \n",
    "    print(f\"\\n  Conditional Statistics ({regime_name} days, n={len(subset):,}):\")\n",
    "    print(f\"  NOTE: These are 'conditional on regime' stats, not tradable regime returns.\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  {'Metric':<30} {'Strategy':>15} {'SPY':>15} {'Diff':>15}\")\n",
    "    print(f\"  {'-'*30} {'-'*15} {'-'*15} {'-'*15}\")\n",
    "    \n",
    "    # Daily stats (more meaningful for conditional analysis)\n",
    "    print(f\"  {'Mean daily return':<30} {strat_ret.mean()*100:>14.4f}% {spy_ret.mean()*100:>14.4f}% {excess_ret.mean()*100:>14.4f}%\")\n",
    "    print(f\"  {'Daily volatility':<30} {strat_ret.std()*100:>14.4f}% {spy_ret.std()*100:>14.4f}% {(strat_ret.std()-spy_ret.std())*100:>14.4f}%\")\n",
    "    print(f\"  {'Win rate':<30} {win_rate(strat_ret)*100:>14.2f}% {win_rate(spy_ret)*100:>14.2f}% {(win_rate(strat_ret)-win_rate(spy_ret))*100:>14.2f}%\")\n",
    "    print(f\"  \")\n",
    "    \n",
    "    # Annualized (with caveat)\n",
    "    print(f\"  {'Ann. Sharpe (conditional)':<30} {ann_sharpe(strat_ret):>15.3f} {ann_sharpe(spy_ret):>15.3f} {ann_sharpe(strat_ret)-ann_sharpe(spy_ret):>15.3f}\")\n",
    "    print(f\"  {'IR (Sharpe of excess)':<30} {ann_sharpe(excess_ret):>15.3f}\")\n",
    "    print(f\"  {'Ann. excess return':<30} {ann_return(excess_ret)*100:>14.2f}%\")\n",
    "\n",
    "\n",
    "def print_bootstrap_results(boot_results: Dict[str, np.ndarray], regime: str, label: str):\n",
    "    \"\"\"Print bootstrap results for a regime.\"\"\"\n",
    "    ir_dist = boot_results[f\"{regime}_ir\"]\n",
    "    ir_dist = ir_dist[~np.isnan(ir_dist)]\n",
    "    \n",
    "    if len(ir_dist) < 100:\n",
    "        print(f\"\\n  Bootstrap results for {label}: insufficient valid samples.\")\n",
    "        return\n",
    "    \n",
    "    ci = np.percentile(ir_dist, [2.5, 97.5])\n",
    "    point_ir = np.median(ir_dist)\n",
    "    \n",
    "    p_one_sided = np.mean(ir_dist <= 0.0)\n",
    "    p_two_sided = 2 * min(p_one_sided, 1 - p_one_sided)\n",
    "    \n",
    "    ci_excludes_zero = (ci[0] > 0) or (ci[1] < 0)\n",
    "    sig_marker = \"Yes **\" if ci_excludes_zero else \"No\"\n",
    "    \n",
    "    print(f\"\\n  Bootstrap Results for {label} (n_boot={len(ir_dist)}, block_len={BLOCK_LEN}):\")\n",
    "    print(f\"    IR point estimate (median): {point_ir:.3f}\")\n",
    "    print(f\"    95% CI: [{ci[0]:.3f}, {ci[1]:.3f}]\")\n",
    "    print(f\"    One-sided p-value (H0: IR ≤ 0): {p_one_sided:.4f}\")\n",
    "    print(f\"    Two-sided p-value (H0: IR = 0): {p_two_sided:.4f}\")\n",
    "    print(f\"    Significant at α=0.05 (two-sided): {sig_marker}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN ANALYSIS\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Load equity curve ---\n",
    "    # Handle both CSV and parquet formats\n",
    "    if EQUITY_FILE.endswith(\".csv\"):\n",
    "        eq = pd.read_csv(EQUITY_FILE, parse_dates=[\"date\"]).copy()\n",
    "    else:\n",
    "        eq = pd.read_parquet(EQUITY_FILE).copy()\n",
    "        # Handle index vs column for date\n",
    "        if \"date\" not in eq.columns and eq.index.name == \"date\":\n",
    "            eq = eq.reset_index()\n",
    "        elif \"date\" not in eq.columns and \"Date\" in eq.columns:\n",
    "            eq = eq.rename(columns={\"Date\": \"date\"})\n",
    "    \n",
    "    eq[\"date\"] = pd.to_datetime(eq[\"date\"])\n",
    "    eq = eq.sort_values(\"date\").drop_duplicates(\"date\")\n",
    "    \n",
    "    # Handle different column names for equity value\n",
    "    if \"equity\" in eq.columns:\n",
    "        eq[\"strat_ret\"] = eq[\"equity\"].pct_change().fillna(0.0)\n",
    "    elif \"portfolio_value\" in eq.columns:\n",
    "        eq[\"strat_ret\"] = eq[\"portfolio_value\"].pct_change().fillna(0.0)\n",
    "    else:\n",
    "        raise ValueError(f\"Could not find equity column. Available: {eq.columns.tolist()}\")\n",
    "\n",
    "    # --- Load SPY file with market regime ---\n",
    "    spy = pd.read_parquet(SPY_PARQUET).copy()\n",
    "    spy = spy.reset_index().rename(columns={\"Date\": \"date\", \"index\": \"date\"})\n",
    "    spy[\"date\"] = pd.to_datetime(spy[\"date\"])\n",
    "    spy = spy.sort_values(\"date\")\n",
    "    spy[\"spy_ret\"] = spy[\"spy_close\"].pct_change().fillna(0.0)\n",
    "    \n",
    "    # --- Optional: Lag regime to avoid look-ahead bias ---\n",
    "    if LAG_REGIME:\n",
    "        spy[\"market_regime\"] = spy[\"market_regime\"].shift(1).fillna(0).astype(int)\n",
    "        print(\"NOTE: Regime lagged by 1 day to avoid look-ahead bias.\\n\")\n",
    "\n",
    "    # --- Align on common dates ---\n",
    "    df = eq.merge(spy[[\"date\", \"spy_ret\", \"market_regime\"]], on=\"date\", how=\"inner\").dropna()\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    if len(df) < 2:\n",
    "        raise RuntimeError(\"Not enough aligned data points between equity curve and SPY.\")\n",
    "\n",
    "    # --- Compute excess returns (CORRECT way) ---\n",
    "    df[\"excess_ret\"] = df[\"strat_ret\"] - df[\"spy_ret\"]\n",
    "\n",
    "    # =========================\n",
    "    # HEADER\n",
    "    # =========================\n",
    "    print(\"=\" * 80)\n",
    "    print(\" REGIME-BASED PERFORMANCE ANALYSIS: STRATEGY vs SPY (v2)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nData range: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Total aligned days: {len(df):,} ({len(df)/TRADING_DAYS:.2f} years)\")\n",
    "    \n",
    "    n_bull = (df[\"market_regime\"] == 1).sum()\n",
    "    n_bear = (df[\"market_regime\"] == 0).sum()\n",
    "    print(f\"Bull market days (SPY > 200 DMA): {n_bull:,} ({n_bull/len(df)*100:.1f}%)\")\n",
    "    print(f\"Bear market days (SPY < 200 DMA): {n_bear:,} ({n_bear/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if LAG_REGIME:\n",
    "        print(\"\\n⚠️  REGIME LAGGED BY 1 DAY (look-ahead bias prevention enabled)\")\n",
    "\n",
    "    # =========================\n",
    "    # OVERALL STATISTICS (Full Series)\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 1: OVERALL STATISTICS (Full Contiguous Series)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    strat_ret = df[\"strat_ret\"].to_numpy()\n",
    "    spy_ret = df[\"spy_ret\"].to_numpy()\n",
    "    excess_ret = df[\"excess_ret\"].to_numpy()\n",
    "    \n",
    "    print(f\"\\n  {'Metric':<30} {'Strategy':>15} {'SPY':>15} {'Diff':>15}\")\n",
    "    print(f\"  {'-'*30} {'-'*15} {'-'*15} {'-'*15}\")\n",
    "    print(f\"  {'Ann. Return':<30} {ann_return(strat_ret)*100:>14.2f}% {ann_return(spy_ret)*100:>14.2f}% {ann_return(excess_ret)*100:>14.2f}%\")\n",
    "    print(f\"  {'Ann. Volatility':<30} {ann_volatility(strat_ret)*100:>14.2f}% {ann_volatility(spy_ret)*100:>14.2f}% {ann_volatility(excess_ret)*100:>14.2f}%\")\n",
    "    print(f\"  {'Sharpe Ratio':<30} {ann_sharpe(strat_ret):>15.3f} {ann_sharpe(spy_ret):>15.3f} {ann_sharpe(strat_ret)-ann_sharpe(spy_ret):>15.3f}\")\n",
    "    print(f\"  {'Max Drawdown':<30} {max_drawdown(strat_ret)*100:>14.2f}% {max_drawdown(spy_ret)*100:>14.2f}% {(max_drawdown(strat_ret)-max_drawdown(spy_ret))*100:>14.2f}%\")\n",
    "    print(f\"  {'Win Rate':<30} {win_rate(strat_ret)*100:>14.2f}% {win_rate(spy_ret)*100:>14.2f}% {(win_rate(strat_ret)-win_rate(spy_ret))*100:>14.2f}%\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  {'Information Ratio':<30} {ann_sharpe(excess_ret):>15.3f}\")\n",
    "    print(f\"  {'Ann. Excess Return (correct)':<30} {ann_return(excess_ret)*100:>14.2f}%\")\n",
    "\n",
    "    # =========================\n",
    "    # CONTIGUOUS SEGMENT ANALYSIS\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 2: CONTIGUOUS SEGMENT ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n  This analyzes each continuous bull/bear period separately,\")\n",
    "    print(\"  avoiding the pitfalls of stitching non-contiguous days together.\")\n",
    "    \n",
    "    segments = find_contiguous_segments(df)\n",
    "    \n",
    "    bull_segments = []\n",
    "    bear_segments = []\n",
    "    \n",
    "    for start_idx, end_idx, regime_val in segments:\n",
    "        stats = compute_segment_stats(df, start_idx, end_idx)\n",
    "        if regime_val == 1:\n",
    "            bull_segments.append(stats)\n",
    "        else:\n",
    "            bear_segments.append(stats)\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" BEAR MARKET SEGMENTS (SPY < 200 DMA)\")\n",
    "    print(\"-\" * 80)\n",
    "    print_segment_summary(bear_segments, \"bear\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" BULL MARKET SEGMENTS (SPY > 200 DMA)\")\n",
    "    print(\"-\" * 80)\n",
    "    # Only show summary for bull (too many segments usually)\n",
    "    if bull_segments:\n",
    "        print(f\"\\n  Found {len(bull_segments)} contiguous bull segment(s).\")\n",
    "        excess_returns = [s.excess_total_return for s in bull_segments]\n",
    "        strat_dds = [s.strat_max_dd for s in bull_segments]\n",
    "        print(f\"\\n  Summary across bull segments:\")\n",
    "        print(f\"    Excess return: mean={np.mean(excess_returns)*100:.2f}%, median={np.median(excess_returns)*100:.2f}%\")\n",
    "        print(f\"    Strategy beat SPY in {sum(1 for e in excess_returns if e > 0)}/{len(bull_segments)} segments ({sum(1 for e in excess_returns if e > 0)/len(bull_segments)*100:.1f}%)\")\n",
    "        print(f\"    Strategy max DD: worst={min(strat_dds)*100:.2f}%, median={np.median(strat_dds)*100:.2f}%\")\n",
    "\n",
    "    # =========================\n",
    "    # CONDITIONAL STATISTICS (for reference)\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 3: CONDITIONAL STATISTICS (Days Labeled as Bull/Bear)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n  These stats describe behavior conditional on regime, NOT tradable returns.\")\n",
    "    \n",
    "    print_conditional_stats(df, \"Bull\", 1)\n",
    "    print_conditional_stats(df, \"Bear\", 0)\n",
    "\n",
    "    # =========================\n",
    "    # BOOTSTRAP ANALYSIS - SIMPLE METHOD (Original Script)\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 4A: SIMPLE BOOTSTRAP (Original Method - For Comparison)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n  This uses the SIMPLE method from the original script:\")\n",
    "    print(\"  - Bootstrap the excess returns directly\")\n",
    "    print(\"  - Compute Sharpe(excess) on each bootstrap sample\")\n",
    "    print(\"  - Does NOT preserve regime structure\")\n",
    "    \n",
    "    # Point estimates (same as original script)\n",
    "    ir_point = ann_sharpe(df[\"strat_ret\"] - df[\"spy_ret\"])\n",
    "    sd_point = ann_sharpe(df[\"strat_ret\"]) - ann_sharpe(df[\"spy_ret\"])\n",
    "    \n",
    "    print(f\"\\n  IR point estimate (Sharpe of excess): {ir_point:.3f}\")\n",
    "    print(f\"  Sharpe(strat) - Sharpe(SPY): {sd_point:.3f}\")\n",
    "    \n",
    "    print(\"\\n  Block bootstrap sensitivity (IR > 0 one-sided test):\")\n",
    "    print(f\"  {'Block':<8} {'95% CI':<24} {'p(IR<=0)':<12} {'p (2-sided)':<12} {'Sig?':<8}\")\n",
    "    print(f\"  {'-'*8} {'-'*24} {'-'*12} {'-'*12} {'-'*8}\")\n",
    "    \n",
    "    for bl in BLOCK_LENS:\n",
    "        dist_ir = bootstrap_ir_simple(df, n_boot=N_BOOT, block_len=bl, seed=SEED)\n",
    "        if dist_ir.size == 0:\n",
    "            print(f\"  {bl:>6}: not enough data to bootstrap.\")\n",
    "            continue\n",
    "\n",
    "        ci = np.percentile(dist_ir, [2.5, 97.5])\n",
    "        p_one_sided = np.mean(dist_ir <= 0.0)  # H0: IR <= 0\n",
    "        p_two_sided = 2 * min(p_one_sided, 1 - p_one_sided)\n",
    "        ci_excludes_zero = (ci[0] > 0) or (ci[1] < 0)\n",
    "        sig_marker = \"Yes **\" if ci_excludes_zero else \"No\"\n",
    "\n",
    "        print(\n",
    "            f\"  {bl:>6}   [{ci[0]: .3f}, {ci[1]: .3f}]       \"\n",
    "            f\"{p_one_sided:.4f}       {p_two_sided:.4f}       {sig_marker}\"\n",
    "        )\n",
    "\n",
    "    # =========================\n",
    "    # BOOTSTRAP ANALYSIS - REGIME METHOD (Correct Method)\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 4B: REGIME-AWARE BOOTSTRAP (v2 Method)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n  Bootstrap performed on FULL contiguous series, then regime stats computed.\")\n",
    "    print(\"  This preserves the time-series dependence structure correctly.\")\n",
    "    \n",
    "    print(\"\\n  Running bootstrap (this may take a moment)...\")\n",
    "    boot_results = bootstrap_regime_stats(df, n_boot=N_BOOT, block_len=BLOCK_LEN, seed=SEED)\n",
    "    \n",
    "    print_bootstrap_results(boot_results, \"overall\", \"Overall\")\n",
    "    print_bootstrap_results(boot_results, \"bull\", \"Bull Market\")\n",
    "    print_bootstrap_results(boot_results, \"bear\", \"Bear Market\")\n",
    "    \n",
    "    # =========================\n",
    "    # COMPARISON OF METHODS\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 4C: METHOD COMPARISON - WHY THE DISCREPANCY?\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get the simple method CI at block_len=21 for direct comparison\n",
    "    dist_simple = bootstrap_ir_simple(df, n_boot=N_BOOT, block_len=BLOCK_LEN, seed=SEED)\n",
    "    ci_simple = np.percentile(dist_simple, [2.5, 97.5])\n",
    "    p_simple_one = np.mean(dist_simple <= 0.0)\n",
    "    p_simple_two = 2 * min(p_simple_one, 1 - p_simple_one)\n",
    "    \n",
    "    # Get the regime method overall CI\n",
    "    overall_dist = boot_results[\"overall_ir\"][~np.isnan(boot_results[\"overall_ir\"])]\n",
    "    ci_regime = np.percentile(overall_dist, [2.5, 97.5])\n",
    "    p_regime_one = np.mean(overall_dist <= 0.0)\n",
    "    p_regime_two = 2 * min(p_regime_one, 1 - p_regime_one)\n",
    "    \n",
    "    print(f\"\\n  Comparison at block_len={BLOCK_LEN}:\")\n",
    "    print(f\"  {'Method':<25} {'IR':<10} {'95% CI':<24} {'p (1-side)':<12} {'p (2-side)':<12}\")\n",
    "    print(f\"  {'-'*25} {'-'*10} {'-'*24} {'-'*12} {'-'*12}\")\n",
    "    print(f\"  {'Simple (excess only)':<25} {ir_point:<10.3f} [{ci_simple[0]:.3f}, {ci_simple[1]:.3f}]       {p_simple_one:.4f}       {p_simple_two:.4f}\")\n",
    "    print(f\"  {'Regime-aware (overall)':<25} {np.median(overall_dist):<10.3f} [{ci_regime[0]:.3f}, {ci_regime[1]:.3f}]       {p_regime_one:.4f}       {p_regime_two:.4f}\")\n",
    "    \n",
    "    print(f\"\"\"\n",
    "  EXPLANATION OF DISCREPANCY:\n",
    "  \n",
    "  Both methods bootstrap the SAME underlying data, but:\n",
    "  \n",
    "  1. SIMPLE METHOD: \n",
    "     - Resamples excess returns (strat - spy) directly\n",
    "     - Computes Sharpe of the resampled excess returns\n",
    "     - Each bootstrap sample has the SAME number of observations\n",
    "     \n",
    "  2. REGIME-AWARE METHOD:\n",
    "     - Resamples the full series (strat, spy, AND regime labels together)\n",
    "     - Then computes regime-specific stats on each bootstrap sample\n",
    "     - The \"overall\" IR should theoretically match, but...\n",
    "     - Regime proportions can vary between bootstrap samples\n",
    "     \n",
    "  The discrepancy likely comes from:\n",
    "  - Random seed handling differences between the two bootstrap loops\n",
    "  - The regime method resamples regime labels too, which can slightly \n",
    "    change the effective weighting\n",
    "  - Numerical precision in how returns are combined\n",
    "  \n",
    "  For OVERALL IR, the SIMPLE method is actually more direct and appropriate.\n",
    "  The REGIME method is designed for comparing bull vs bear performance.\n",
    "\"\"\")\n",
    "    \n",
    "\n",
    "    # =========================\n",
    "    # KEY FINDINGS SUMMARY\n",
    "    # =========================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" SECTION 5: KEY FINDINGS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Overall\n",
    "    overall_ir = ann_sharpe(excess_ret)\n",
    "    overall_ci = np.percentile(boot_results[\"overall_ir\"][~np.isnan(boot_results[\"overall_ir\"])], [2.5, 97.5])\n",
    "    overall_sig = \"YES\" if (overall_ci[0] > 0 or overall_ci[1] < 0) else \"NO\"\n",
    "    \n",
    "    # Bull\n",
    "    bull_mask = df[\"market_regime\"] == 1\n",
    "    bull_ir = ann_sharpe(excess_ret[bull_mask])\n",
    "    bull_ci = np.percentile(boot_results[\"bull_ir\"][~np.isnan(boot_results[\"bull_ir\"])], [2.5, 97.5])\n",
    "    bull_sig = \"YES\" if (bull_ci[0] > 0 or bull_ci[1] < 0) else \"NO\"\n",
    "    \n",
    "    # Bear\n",
    "    bear_mask = df[\"market_regime\"] == 0\n",
    "    bear_ir = ann_sharpe(excess_ret[bear_mask])\n",
    "    bear_ci = np.percentile(boot_results[\"bear_ir\"][~np.isnan(boot_results[\"bear_ir\"])], [2.5, 97.5])\n",
    "    bear_sig = \"YES\" if (bear_ci[0] > 0 or bear_ci[1] < 0) else \"NO\"\n",
    "    \n",
    "    print(f\"\\n  {'Regime':<15} {'IR':<10} {'95% CI':<25} {'Significant?':<15}\")\n",
    "    print(f\"  {'-'*15} {'-'*10} {'-'*25} {'-'*15}\")\n",
    "    print(f\"  {'Overall':<15} {overall_ir:<10.3f} [{overall_ci[0]:.3f}, {overall_ci[1]:.3f}]{'':>10} {overall_sig:<15}\")\n",
    "    print(f\"  {'Bull':<15} {bull_ir:<10.3f} [{bull_ci[0]:.3f}, {bull_ci[1]:.3f}]{'':>10} {bull_sig:<15}\")\n",
    "    print(f\"  {'Bear':<15} {bear_ir:<10.3f} [{bear_ci[0]:.3f}, {bear_ci[1]:.3f}]{'':>10} {bear_sig:<15}\")\n",
    "    \n",
    "    # Segment-based insights\n",
    "    if bear_segments:\n",
    "        bear_wins = sum(1 for s in bear_segments if s.excess_total_return > 0)\n",
    "        bear_total = len(bear_segments)\n",
    "        print(f\"\\n  Bear market segment win rate: {bear_wins}/{bear_total} ({bear_wins/bear_total*100:.1f}%)\")\n",
    "        \n",
    "        worst_bear_strat = min(s.strat_total_return for s in bear_segments)\n",
    "        worst_bear_spy = min(s.spy_total_return for s in bear_segments)\n",
    "        print(f\"  Worst bear segment: Strategy {worst_bear_strat*100:.1f}% vs SPY {worst_bear_spy*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\" INTERPRETATION NOTES:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"\"\"\n",
    "  1. OVERALL IR: Tests whether strategy has risk-adjusted alpha vs SPY across\n",
    "     the full time period. This is the most reliable test.\n",
    "  \n",
    "  2. REGIME IRs: These test conditional performance, but interpretation requires\n",
    "     care - the bootstrap resamples the full series, so regime proportions may\n",
    "     vary across samples.\n",
    "  \n",
    "  3. SEGMENT ANALYSIS: Shows actual performance in each contiguous bear/bull\n",
    "     market. This is the most intuitive way to see \"what happened in 2008\" etc.\n",
    "  \n",
    "  4. If you trade based on the regime signal, enable LAG_REGIME=True to avoid\n",
    "     look-ahead bias in this analysis.\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_quant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
