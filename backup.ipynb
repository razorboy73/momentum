{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb63f0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os, time, json, shutil, subprocess\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG — RUN NOTEBOOK FROM MomentumSystem ROOT OR SET PATH\n",
    "# ============================================================\n",
    "\n",
    "# Option A (recommended): run notebook from MomentumSystem root\n",
    "#PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "# Option B: hardcode it (uncomment and set)\n",
    "PROJECT_ROOT = Path(r\"C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\")\n",
    "\n",
    "SOURCE_FOLDERS = [\n",
    "    \"13-match_trade_generator_output_regression_insp500_spyfilter_cap15\",\n",
    "    \"13-trading_output_regression_insp500_spyfilter_cap15\",\n",
    "    \"27a-2G_live_trading\",\n",
    "]\n",
    "\n",
    "# Your new folders (you said you created them)\n",
    "PUBLISH_ROOT    = PROJECT_ROOT / \"_publish\"\n",
    "LOG_DIR         = PROJECT_ROOT / \"_logs\"\n",
    "SYNC_DIR        = PROJECT_ROOT / \"_sync\"\n",
    "MANIFEST_DIR    = PROJECT_ROOT / \"_manifest\"\n",
    "QUARANTINE_DIR  = PROJECT_ROOT / \"_quarantine\"\n",
    "SNAPSHOT_DIR    = PROJECT_ROOT / \"_snapshots\"   # optional; not required\n",
    "\n",
    "# rclone executable (set to \"rclone\" if in PATH)\n",
    "RCLONE_EXE = \"rclone\"  # or r\"C:\\Tools\\rclone\\rclone.exe\"\n",
    "\n",
    "# Dropbox remote name (configured via `rclone config`)\n",
    "DROPBOX_REMOTE = \"dropbox:MomentumSystem\"  # you can change the folder name in Dropbox\n",
    "\n",
    "REMOTE_LATEST  = f\"{DROPBOX_REMOTE}/latest\"\n",
    "REMOTE_CHANGES = f\"{DROPBOX_REMOTE}/_changes\"\n",
    "\n",
    "# What to sync\n",
    "INCLUDE_EXTS = {\".parquet\", \".csv\", \".json\", \".log\", \".txt\"}\n",
    "\n",
    "# Exclude temp/lock\n",
    "EXCLUDE_SUFFIXES = {\".tmp\", \".lock\"}\n",
    "\n",
    "# Stability gate: file must be unchanged for N seconds to be \"safe\"\n",
    "STABLE_SECONDS = 10\n",
    "\n",
    "# Optional verification (can be slow)\n",
    "DO_RCLONE_CHECK = False\n",
    "\n",
    "# Optional backup retention in Dropbox changes folder (days). Set None to disable.\n",
    "CHANGES_RETENTION_DAYS = 60\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cc1c444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using RCLONE_EXE = C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE\n",
      ">>> C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE version\n",
      "rclone v1.72.1\n",
      "- os/version: Microsoft Windows 11 Home 24H2 24H2 (64 bit)\n",
      "- os/kernel: 10.0.26100.7462 (x86_64)\n",
      "- os/type: windows\n",
      "- os/arch: amd64\n",
      "- go/version: go1.25.5\n",
      "- go/linking: static\n",
      "- go/tags: cmount\n",
      "\n",
      ">>> C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE mkdir dropbox:MomentumSystem\n",
      ">>> C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE mkdir dropbox:MomentumSystem/latest\n",
      ">>> C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE mkdir dropbox:MomentumSystem/_changes\n",
      "Filter file: C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_sync\\rclone_filters.txt\n"
     ]
    }
   ],
   "source": [
    "def ensure_dirs():\n",
    "    for p in [PUBLISH_ROOT, LOG_DIR, SYNC_DIR, MANIFEST_DIR, QUARANTINE_DIR]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "    # snapshots optional\n",
    "    SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    print(\">>>\", \" \".join(cmd))\n",
    "    p = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if p.stdout:\n",
    "        print(p.stdout)\n",
    "    if p.returncode != 0:\n",
    "        if p.stderr:\n",
    "            print(p.stderr)\n",
    "        raise RuntimeError(f\"Command failed (exit {p.returncode}): {' '.join(cmd)}\")\n",
    "    return p.stdout\n",
    "\n",
    "def ensure_rclone():\n",
    "    # sanity check: rclone present\n",
    "    run_cmd([RCLONE_EXE, \"version\"])\n",
    "\n",
    "def ensure_remote_dirs():\n",
    "    run_cmd([RCLONE_EXE, \"mkdir\", DROPBOX_REMOTE])   # dropbox:MomentumSystem\n",
    "    run_cmd([RCLONE_EXE, \"mkdir\", REMOTE_LATEST])    # dropbox:MomentumSystem/latest\n",
    "    run_cmd([RCLONE_EXE, \"mkdir\", REMOTE_CHANGES])   # dropbox:MomentumSystem/_changes\n",
    "  \n",
    "import os, shutil, subprocess\n",
    "\n",
    "def refresh_windows_path_into_python():\n",
    "    \"\"\"Pull Machine+User PATH from Windows and set it in this Python process.\"\"\"\n",
    "    cmd = [\n",
    "        \"powershell\", \"-NoProfile\", \"-Command\",\n",
    "        \"[System.Environment]::GetEnvironmentVariable('Path','Machine') + ';' + \" +\n",
    "        \"[System.Environment]::GetEnvironmentVariable('Path','User')\"\n",
    "    ]\n",
    "    new_path = subprocess.check_output(cmd, text=True).strip()\n",
    "    # prepend so it's definitely used\n",
    "    os.environ[\"PATH\"] = new_path + \";\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "def resolve_rclone_exe():\n",
    "    \"\"\"Return an executable name/path that subprocess can run.\"\"\"\n",
    "    # 1) try plain 'rclone' in current PATH\n",
    "    p = shutil.which(\"rclone\")\n",
    "    if p:\n",
    "        return p\n",
    "\n",
    "    # 2) refresh PATH from Windows registry, try again\n",
    "    refresh_windows_path_into_python()\n",
    "    p = shutil.which(\"rclone\")\n",
    "    if p:\n",
    "        return p\n",
    "\n",
    "    # 3) last resort: ask PowerShell where rclone is and use the absolute path\n",
    "    cmd = [\n",
    "        \"powershell\", \"-NoProfile\", \"-Command\",\n",
    "        \"(Get-Command rclone -ErrorAction Stop).Source\"\n",
    "    ]\n",
    "    try:\n",
    "        p = subprocess.check_output(cmd, text=True).strip()\n",
    "        if p and os.path.exists(p):\n",
    "            return p\n",
    "    except subprocess.CalledProcessError:\n",
    "        pass\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"Jupyter still cannot locate rclone. Close/reopen Jupyter (or restart the kernel) \"\n",
    "        \"after installing rclone, or set RCLONE_EXE to the full path of rclone.exe.\"\n",
    "    )\n",
    "\n",
    "# IMPORTANT: overwrite your RCLONE_EXE setting here\n",
    "RCLONE_EXE = resolve_rclone_exe()\n",
    "print(\"Using RCLONE_EXE =\", RCLONE_EXE)\n",
    "\n",
    "\n",
    "def write_rclone_filter():\n",
    "    \"\"\"\n",
    "    Keep filters in _sync so it's operational/config stuff.\n",
    "    \"\"\"\n",
    "    filter_path = SYNC_DIR / \"rclone_filters.txt\"\n",
    "    rules = []\n",
    "    # include desired extensions\n",
    "    for ext in sorted(INCLUDE_EXTS):\n",
    "        rules.append(f\"+ *{ext}\")\n",
    "    # exclude temp/locks\n",
    "    for suf in sorted(EXCLUDE_SUFFIXES):\n",
    "        rules.append(f\"- *{suf}\")\n",
    "    # exclude junk\n",
    "    rules += [\n",
    "        \"- **/.git/**\",\n",
    "        \"- **/__pycache__/**\",\n",
    "        \"- **/~*\",\n",
    "        \"- **/*.bak\",\n",
    "    ]\n",
    "    # exclude everything else\n",
    "    rules.append(\"- *\")\n",
    "\n",
    "    filter_path.write_text(\"\\n\".join(rules) + \"\\n\", encoding=\"utf-8\")\n",
    "    return filter_path\n",
    "\n",
    "LOCK_FILE = SYNC_DIR / \"sync_lock.json\"\n",
    "\n",
    "def acquire_lock(max_age_minutes=30):\n",
    "    \"\"\"Acquire lock, but auto-clear if stale (older than max_age_minutes).\"\"\"\n",
    "    if LOCK_FILE.exists():\n",
    "        try:\n",
    "            lock_data = json.loads(LOCK_FILE.read_text(encoding=\"utf-8\"))\n",
    "            created = datetime.fromisoformat(lock_data[\"created\"])\n",
    "            age_minutes = (datetime.now() - created).total_seconds() / 60\n",
    "            \n",
    "            if age_minutes > max_age_minutes:\n",
    "                print(f\"⚠ Stale lock detected ({age_minutes:.1f} min old, PID {lock_data.get('pid')}). Auto-removing.\")\n",
    "                LOCK_FILE.unlink()\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    f\"Lock exists: {LOCK_FILE}. \"\n",
    "                    f\"Created {age_minutes:.1f} minutes ago (PID {lock_data.get('pid')}). \"\n",
    "                    \"Another run may be in progress. \"\n",
    "                    f\"Wait {max_age_minutes - age_minutes:.1f} more minutes or manually delete if crashed.\"\n",
    "                )\n",
    "        except (json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "            print(f\"⚠ Corrupted lock file. Removing it. Error: {e}\")\n",
    "            LOCK_FILE.unlink()\n",
    "    \n",
    "    LOCK_FILE.write_text(json.dumps({\n",
    "        \"created\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"pid\": os.getpid(),\n",
    "    }, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"✓ Lock acquired (PID {os.getpid()})\")\n",
    "\n",
    "def release_lock():\n",
    "    if LOCK_FILE.exists():\n",
    "        LOCK_FILE.unlink()\n",
    "\n",
    "ensure_dirs()\n",
    "ensure_rclone()\n",
    "FILTER_FILE = write_rclone_filter()\n",
    "ensure_remote_dirs()\n",
    "print(\"Filter file:\", FILTER_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9446b11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Publishing C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\13-match_trade_generator_output_regression_insp500_spyfilter_cap15 -> C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\13-match_trade_generator_output_regression_insp500_spyfilter_cap15\n",
      "   {'copied': 5, 'skipped': 0, 'unstable': 0}\n",
      "\n",
      "Publishing C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\13-trading_output_regression_insp500_spyfilter_cap15 -> C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\13-trading_output_regression_insp500_spyfilter_cap15\n",
      "   {'copied': 4, 'skipped': 0, 'unstable': 0}\n",
      "\n",
      "Publishing C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\27a-2G_live_trading -> C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\27a-2G_live_trading\n",
      "   {'copied': 8, 'skipped': 0, 'unstable': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2026-01-09_105908',\n",
       " 'project_root': 'C:\\\\TWS API\\\\source\\\\pythonclient\\\\TradingIdeas\\\\MomentumSystem',\n",
       " 'published': {'13-match_trade_generator_output_regression_insp500_spyfilter_cap15': {'copied': 5,\n",
       "   'skipped': 0,\n",
       "   'unstable': 0},\n",
       "  '13-trading_output_regression_insp500_spyfilter_cap15': {'copied': 4,\n",
       "   'skipped': 0,\n",
       "   'unstable': 0},\n",
       "  '27a-2G_live_trading': {'copied': 8, 'skipped': 0, 'unstable': 0}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_candidate_file(path: Path) -> bool:\n",
    "    if not path.is_file():\n",
    "        return False\n",
    "    if path.suffix.lower() not in INCLUDE_EXTS:\n",
    "        return False\n",
    "    lname = path.name.lower()\n",
    "    return not any(lname.endswith(suf) for suf in EXCLUDE_SUFFIXES)\n",
    "\n",
    "def file_signature(path: Path):\n",
    "    st = path.stat()\n",
    "    return (st.st_size, st.st_mtime)\n",
    "\n",
    "def wait_until_stable(path: Path, stable_seconds=STABLE_SECONDS, poll=1.0) -> bool:\n",
    "    if not path.exists():\n",
    "        return False\n",
    "    sig0 = file_signature(path)\n",
    "    t0 = time.time()\n",
    "    while True:\n",
    "        time.sleep(poll)\n",
    "        if not path.exists():\n",
    "            return False\n",
    "        sig1 = file_signature(path)\n",
    "        if sig1 != sig0:\n",
    "            sig0 = sig1\n",
    "            t0 = time.time()\n",
    "        if (time.time() - t0) >= stable_seconds:\n",
    "            return True\n",
    "\n",
    "def needs_copy(src: Path, dst: Path) -> bool:\n",
    "    if not dst.exists():\n",
    "        return True\n",
    "    return file_signature(src) != file_signature(dst)\n",
    "\n",
    "def publish_one_folder(src_root: Path, dst_root: Path):\n",
    "    copied = skipped = unstable = 0\n",
    "    for root, _, files in os.walk(src_root):\n",
    "        rootp = Path(root)\n",
    "        for f in files:\n",
    "            src = rootp / f\n",
    "            if not is_candidate_file(src):\n",
    "                continue\n",
    "            ok = wait_until_stable(src)\n",
    "            rel = src.relative_to(src_root)\n",
    "            if not ok:\n",
    "                # quarantine a reference copy (optional)\n",
    "                qdst = QUARANTINE_DIR / src_root.name / rel\n",
    "                qdst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                try:\n",
    "                    shutil.copy2(src, qdst)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                unstable += 1\n",
    "                continue\n",
    "            \n",
    "            # IMPORTANT: Normalize path separators to forward slashes for cross-platform compatibility\n",
    "            # Convert Windows backslashes to forward slashes so rclone treats paths consistently\n",
    "            rel_posix = Path(str(rel).replace('\\\\', '/'))\n",
    "            dst = dst_root / rel_posix\n",
    "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            if needs_copy(src, dst):\n",
    "                shutil.copy2(src, dst)\n",
    "                copied += 1\n",
    "            else:\n",
    "                skipped += 1\n",
    "    return {\"copied\": copied, \"skipped\": skipped, \"unstable\": unstable}\n",
    "\n",
    "def publish_all():\n",
    "    summary = {}\n",
    "    for folder in SOURCE_FOLDERS:\n",
    "        src = PROJECT_ROOT / folder\n",
    "        dst = PUBLISH_ROOT / folder\n",
    "\n",
    "        if not src.exists():\n",
    "            raise FileNotFoundError(f\"Missing source folder: {src}\")\n",
    "\n",
    "        dst.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\nPublishing {src} -> {dst}\")\n",
    "        summary[folder] = publish_one_folder(src, dst)\n",
    "        print(\"  \", summary[folder])\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    manifest = {\n",
    "        \"timestamp\": ts,\n",
    "        \"project_root\": str(PROJECT_ROOT),\n",
    "        \"published\": summary\n",
    "    }\n",
    "\n",
    "    (MANIFEST_DIR / f\"manifest_{ts}.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    (PUBLISH_ROOT / \"RUN_COMPLETE.txt\").write_text(ts + \"\\n\", encoding=\"utf-8\")\n",
    "    return manifest\n",
    "\n",
    "manifest = publish_all()\n",
    "manifest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56cc7b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Lock acquired (PID 30688)\n",
      "\n",
      "SYNC C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\13-match_trade_generator_output_regression_insp500_spyfilter_cap15 -> dropbox:MomentumSystem/latest/13-match_trade_generator_output_regression_insp500_spyfilter_cap15\n",
      ">>> C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE sync C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\13-match_trade_generator_output_regression_insp500_spyfilter_cap15 dropbox:MomentumSystem/latest/13-match_trade_generator_output_regression_insp500_spyfilter_cap15 --filter-from C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_sync\\rclone_filters.txt --backup-dir dropbox:MomentumSystem/_changes/2026-01-09_105908/13-match_trade_generator_output_regression_insp500_spyfilter_cap15 --retries 5 --low-level-retries 20 --log-level INFO --log-file C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_logs\\rclone_sync_13-match_trade_generator_output_regression_insp500_spyfilter_cap15_2026-01-09_105908.log\n",
      "\n",
      "SYNC C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\13-trading_output_regression_insp500_spyfilter_cap15 -> dropbox:MomentumSystem/latest/13-trading_output_regression_insp500_spyfilter_cap15\n",
      ">>> C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE sync C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\13-trading_output_regression_insp500_spyfilter_cap15 dropbox:MomentumSystem/latest/13-trading_output_regression_insp500_spyfilter_cap15 --filter-from C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_sync\\rclone_filters.txt --backup-dir dropbox:MomentumSystem/_changes/2026-01-09_105908/13-trading_output_regression_insp500_spyfilter_cap15 --retries 5 --low-level-retries 20 --log-level INFO --log-file C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_logs\\rclone_sync_13-trading_output_regression_insp500_spyfilter_cap15_2026-01-09_105908.log\n",
      "\n",
      "SYNC C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\27a-2G_live_trading -> dropbox:MomentumSystem/latest/27a-2G_live_trading\n",
      ">>> C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE sync C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_publish\\27a-2G_live_trading dropbox:MomentumSystem/latest/27a-2G_live_trading --filter-from C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_sync\\rclone_filters.txt --backup-dir dropbox:MomentumSystem/_changes/2026-01-09_105908/27a-2G_live_trading --retries 5 --low-level-retries 20 --log-level INFO --log-file C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_logs\\rclone_sync_27a-2G_live_trading_2026-01-09_105908.log\n",
      "Sync complete.\n"
     ]
    }
   ],
   "source": [
    "def rclone_sync(local_dir: Path, remote_dir: str, backup_dir: str, log_path: Path):\n",
    "    cmd = [\n",
    "        RCLONE_EXE, \"sync\",\n",
    "        str(local_dir),\n",
    "        remote_dir,\n",
    "        \"--filter-from\", str(FILTER_FILE),\n",
    "        \"--backup-dir\", backup_dir,\n",
    "        \"--retries\", \"5\",\n",
    "        \"--low-level-retries\", \"20\",\n",
    "        \"--log-level\", \"INFO\",\n",
    "        \"--log-file\", str(log_path),\n",
    "    ]\n",
    "    run_cmd(cmd)\n",
    "\n",
    "def rclone_check(local_dir: Path, remote_dir: str, log_path: Path):\n",
    "    cmd = [\n",
    "        RCLONE_EXE, \"check\",\n",
    "        str(local_dir),\n",
    "        remote_dir,\n",
    "        \"--filter-from\", str(FILTER_FILE),\n",
    "        \"--log-level\", \"INFO\",\n",
    "        \"--log-file\", str(log_path),\n",
    "    ]\n",
    "    run_cmd(cmd)\n",
    "\n",
    "def sync_all():\n",
    "    marker = PUBLISH_ROOT / \"RUN_COMPLETE.txt\"\n",
    "    if not marker.exists():\n",
    "        raise RuntimeError(f\"RUN_COMPLETE.txt not found: {marker}. Publish step may not have completed.\")\n",
    "\n",
    "    run_ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "    for folder in SOURCE_FOLDERS:\n",
    "        local_dir  = PUBLISH_ROOT / folder\n",
    "        remote_dir = f\"{REMOTE_LATEST}/{folder}\"\n",
    "        backup_dir = f\"{REMOTE_CHANGES}/{run_ts}/{folder}\"\n",
    "\n",
    "        log_sync = LOG_DIR / f\"rclone_sync_{folder}_{run_ts}.log\"\n",
    "        print(f\"\\nSYNC {local_dir} -> {remote_dir}\")\n",
    "        rclone_sync(local_dir, remote_dir, backup_dir, log_sync)\n",
    "\n",
    "        if DO_RCLONE_CHECK:\n",
    "            log_check = LOG_DIR / f\"rclone_check_{folder}_{run_ts}.log\"\n",
    "            print(f\"CHECK {local_dir} <-> {remote_dir}\")\n",
    "            rclone_check(local_dir, remote_dir, log_check)\n",
    "\n",
    "acquire_lock()\n",
    "try:\n",
    "    sync_all()\n",
    "finally:\n",
    "    release_lock()\n",
    "\n",
    "print(\"Sync complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40c237a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> C:\\Users\\farty\\AppData\\Local\\Microsoft\\WinGet\\Links\\rclone.EXE delete dropbox:MomentumSystem/_changes --min-age 60d --log-level INFO --log-file C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_logs\\rclone_delete_changes_2026-01-09_105922.log\n"
     ]
    }
   ],
   "source": [
    "def cleanup_old_changes(days: int):\n",
    "    if not days:\n",
    "        print(\"Retention cleanup disabled.\")\n",
    "        return\n",
    "\n",
    "    # If folder doesn't exist yet, skip cleanly\n",
    "    p = subprocess.run([RCLONE_EXE, \"lsf\", REMOTE_CHANGES], capture_output=True, text=True)\n",
    "    if p.returncode != 0:\n",
    "        print(f\"Skip cleanup: remote path not found yet: {REMOTE_CHANGES}\")\n",
    "        return\n",
    "\n",
    "    run_ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    log_del = LOG_DIR / f\"rclone_delete_changes_{run_ts}.log\"\n",
    "\n",
    "    cmd = [\n",
    "        RCLONE_EXE, \"delete\",\n",
    "        REMOTE_CHANGES,\n",
    "        \"--min-age\", f\"{days}d\",\n",
    "        \"--log-level\", \"INFO\",\n",
    "        \"--log-file\", str(log_del),\n",
    "    ]\n",
    "    run_cmd(cmd)\n",
    "\n",
    "cleanup_old_changes(CHANGES_RETENTION_DAYS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92fe3478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026/01/02 12:56:31 ERROR : error listing: directory not found\n",
      "2026/01/02 12:56:31 ERROR : Attempt 1/3 failed with 2 errors and: directory not found\n",
      "2026/01/02 12:56:31 ERROR : error listing: directory not found\n",
      "2026/01/02 12:56:31 ERROR : Attempt 2/3 failed with 2 errors and: directory not found\n",
      "2026/01/02 12:56:32 ERROR : error listing: directory not found\n",
      "2026/01/02 12:56:32 ERROR : Attempt 3/3 failed with 2 errors and: directory not found\n",
      "2026/01/02 12:56:32 INFO  : Dropbox root 'MomentumSystem/_changes': Committing uploads - please wait...\n",
      "2026/01/02 12:56:32 NOTICE: Failed to delete with 2 errors: last error was: directory not found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(Path(r\"C:\\TWS API\\source\\pythonclient\\TradingIdeas\\MomentumSystem\\_logs\\rclone_delete_changes_2026-01-02_125631.log\").read_text(errors=\"ignore\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19742feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FOLDER: 13-match_trade_generator_output_regression_insp500_spyfilter_cap15\n",
      "================================================================================\n",
      "\n",
      "LOCAL FILES (_publish):\n",
      "  2026-01-08 19:05:35         492 bytes  13-all_planned_trades.csv\n",
      "  2026-01-08 19:05:35       3,039 bytes  13-match_equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:35      10,790 bytes  13-match_trades_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:35      12,525 bytes  13-match_weekly_rankings_pre_filter_cap15.parquet\n",
      "  2026-01-08 19:05:35         492 bytes  planned_trades_LATEST.csv\n",
      "\n",
      "DROPBOX FILES:\n",
      "  2026-01-08 19:05:36.000000000         492 bytes  13-all_planned_trades.csv\n",
      "  2026-01-08 19:05:36.000000000        3039 bytes  13-match_equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:36.000000000       10790 bytes  13-match_trades_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:36.000000000       12525 bytes  13-match_weekly_rankings_pre_filter_cap15.parquet\n",
      "  2026-01-08 19:05:36.000000000         492 bytes  planned_trades_LATEST.csv\n",
      "\n",
      "COMPARISON:\n",
      "  ✓ SAME: 13-all_planned_trades.csv\n",
      "      Local:   2026-01-08 19:05:35\n",
      "      Dropbox: 2026-01-08 19:05:36.000000000\n",
      "  ✓ SAME: 13-match_equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "      Local:   2026-01-08 19:05:35\n",
      "      Dropbox: 2026-01-08 19:05:36.000000000\n",
      "  ✓ SAME: 13-match_trades_regression_insp500_spyfilter_cap15.parquet\n",
      "      Local:   2026-01-08 19:05:35\n",
      "      Dropbox: 2026-01-08 19:05:36.000000000\n",
      "  ✓ SAME: 13-match_weekly_rankings_pre_filter_cap15.parquet\n",
      "      Local:   2026-01-08 19:05:35\n",
      "      Dropbox: 2026-01-08 19:05:36.000000000\n",
      "  ✓ SAME: planned_trades_LATEST.csv\n",
      "      Local:   2026-01-08 19:05:35\n",
      "      Dropbox: 2026-01-08 19:05:36.000000000\n",
      "\n",
      "================================================================================\n",
      "FOLDER: 13-trading_output_regression_insp500_spyfilter_cap15\n",
      "================================================================================\n",
      "\n",
      "LOCAL FILES (_publish):\n",
      "  2026-01-08 19:05:59     136,839 bytes  13-equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:59     262,458 bytes  13-trades_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:59   2,757,721 bytes  13-weekly_rankings_pre_filter_cap15.parquet\n",
      "  2026-01-06 10:23:26   1,005,390 bytes  equity_curve_with_cash_returns.csv\n",
      "\n",
      "DROPBOX FILES:\n",
      "  2026-01-08 19:06:00.000000000      136839 bytes  13-equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:06:00.000000000      262458 bytes  13-trades_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:06:00.000000000     2757721 bytes  13-weekly_rankings_pre_filter_cap15.parquet\n",
      "  2026-01-06 10:23:26.000000000     1005390 bytes  equity_curve_with_cash_returns.csv\n",
      "\n",
      "COMPARISON:\n",
      "  ✓ SAME: 13-equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "      Local:   2026-01-08 19:05:59\n",
      "      Dropbox: 2026-01-08 19:06:00.000000000\n",
      "  ✓ SAME: 13-trades_regression_insp500_spyfilter_cap15.parquet\n",
      "      Local:   2026-01-08 19:05:59\n",
      "      Dropbox: 2026-01-08 19:06:00.000000000\n",
      "  ✓ SAME: 13-weekly_rankings_pre_filter_cap15.parquet\n",
      "      Local:   2026-01-08 19:05:59\n",
      "      Dropbox: 2026-01-08 19:06:00.000000000\n",
      "  ✓ SAME: equity_curve_with_cash_returns.csv\n",
      "      Local:   2026-01-06 10:23:26\n",
      "      Dropbox: 2026-01-06 10:23:26.000000000\n",
      "\n",
      "================================================================================\n",
      "FOLDER: 27a-2G_live_trading\n",
      "================================================================================\n",
      "\n",
      "LOCAL FILES (_publish):\n",
      "  2026-01-09 09:38:40         618 bytes  broker_fills_manual.csv\n",
      "  2026-01-09 09:44:13       1,239 bytes  executed_trades.csv\n",
      "  2026-01-09 09:44:13         267 bytes  live_portfolio.csv\n",
      "  2026-01-09 09:40:58       6,339 bytes  master_rankings.csv\n",
      "  2026-01-09 09:40:58         998 bytes  master_trades.csv\n",
      "  2026-01-09 09:44:13       1,239 bytes  reconciliation_log.csv\n",
      "  2026-01-09 09:40:58       6,339 bytes  weekly_rankings\\weekly_rankings_signal_20260107.csv\n",
      "  2026-01-09 09:40:58         998 bytes  weekly_trades\\weekly_trades_signal_20260107.csv\n",
      "\n",
      "DROPBOX FILES:\n",
      "  2026-01-09 09:38:40.000000000         618 bytes  broker_fills_manual.csv\n",
      "  2026-01-09 09:44:13.000000000        1239 bytes  executed_trades.csv\n",
      "  2026-01-09 09:44:13.000000000         267 bytes  live_portfolio.csv\n",
      "  2026-01-09 09:40:58.000000000        6339 bytes  master_rankings.csv\n",
      "  2026-01-09 09:40:58.000000000         998 bytes  master_trades.csv\n",
      "  2026-01-09 09:44:13.000000000        1239 bytes  reconciliation_log.csv\n",
      "  2026-01-09 09:40:58.000000000        6339 bytes  weekly_rankings/weekly_rankings_signal_20260107.csv\n",
      "  2026-01-09 09:40:58.000000000         998 bytes  weekly_trades/weekly_trades_signal_20260107.csv\n",
      "\n",
      "COMPARISON:\n",
      "  ✓ SAME: broker_fills_manual.csv\n",
      "      Local:   2026-01-09 09:38:40\n",
      "      Dropbox: 2026-01-09 09:38:40.000000000\n",
      "  ✓ SAME: executed_trades.csv\n",
      "      Local:   2026-01-09 09:44:13\n",
      "      Dropbox: 2026-01-09 09:44:13.000000000\n",
      "  ✓ SAME: live_portfolio.csv\n",
      "      Local:   2026-01-09 09:44:13\n",
      "      Dropbox: 2026-01-09 09:44:13.000000000\n",
      "  ✓ SAME: master_rankings.csv\n",
      "      Local:   2026-01-09 09:40:58\n",
      "      Dropbox: 2026-01-09 09:40:58.000000000\n",
      "  ✓ SAME: master_trades.csv\n",
      "      Local:   2026-01-09 09:40:58\n",
      "      Dropbox: 2026-01-09 09:40:58.000000000\n",
      "  ✓ SAME: reconciliation_log.csv\n",
      "      Local:   2026-01-09 09:44:13\n",
      "      Dropbox: 2026-01-09 09:44:13.000000000\n",
      "  ⚠️  weekly_rankings/weekly_rankings_signal_20260107.csv: Only in Dropbox\n",
      "  ⚠️  weekly_rankings\\weekly_rankings_signal_20260107.csv: Only in local (NOT SYNCED!)\n",
      "  ⚠️  weekly_trades/weekly_trades_signal_20260107.csv: Only in Dropbox\n",
      "  ⚠️  weekly_trades\\weekly_trades_signal_20260107.csv: Only in local (NOT SYNCED!)\n"
     ]
    }
   ],
   "source": [
    "# Check Dropbox contents\n",
    "import subprocess\n",
    "\n",
    "# Compare file timestamps with dates\n",
    "def compare_with_dates():\n",
    "    for folder in SOURCE_FOLDERS:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"FOLDER: {folder}\")\n",
    "        print('='*80)\n",
    "        \n",
    "        local_dir = PUBLISH_ROOT / folder\n",
    "        \n",
    "        # List local files with timestamps\n",
    "        print(\"\\nLOCAL FILES (_publish):\")\n",
    "        local_files = {}\n",
    "        for f in sorted(local_dir.rglob(\"*\")):\n",
    "            if f.is_file() and is_candidate_file(f):\n",
    "                mtime = datetime.fromtimestamp(f.stat().st_mtime)\n",
    "                size = f.stat().st_size\n",
    "                rel = f.relative_to(local_dir)\n",
    "                local_files[str(rel)] = mtime\n",
    "                print(f\"  {mtime.strftime('%Y-%m-%d %H:%M:%S')}  {size:>10,} bytes  {rel}\")\n",
    "        \n",
    "        # List Dropbox files with timestamps (rclone lsl format)\n",
    "        print(\"\\nDROPBOX FILES:\")\n",
    "        remote_path = f\"{REMOTE_LATEST}/{folder}\"\n",
    "        cmd = [RCLONE_EXE, \"lsl\", remote_path]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        dropbox_files = {}\n",
    "        if result.returncode == 0 and result.stdout.strip():\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                if line.strip():\n",
    "                    # rclone lsl format: \"    SIZE YYYY-MM-DD HH:MM:SS.mmm FILENAME\"\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 4:\n",
    "                        size = parts[0]\n",
    "                        date = parts[1]\n",
    "                        time = parts[2]\n",
    "                        filename = ' '.join(parts[3:])\n",
    "                        dropbox_files[filename] = f\"{date} {time}\"\n",
    "                        print(f\"  {date} {time}  {size:>10} bytes  {filename}\")\n",
    "        else:\n",
    "            print(f\"  (empty or error)\")\n",
    "        \n",
    "        # Compare\n",
    "        print(\"\\nCOMPARISON:\")\n",
    "        all_files = set(local_files.keys()) | set(dropbox_files.keys())\n",
    "        for fname in sorted(all_files):\n",
    "            local_time = local_files.get(fname, \"MISSING\")\n",
    "            dropbox_time = dropbox_files.get(fname, \"MISSING\")\n",
    "            \n",
    "            if local_time == \"MISSING\":\n",
    "                print(f\"  ⚠️  {fname}: Only in Dropbox\")\n",
    "            elif dropbox_time == \"MISSING\":\n",
    "                print(f\"  ⚠️  {fname}: Only in local (NOT SYNCED!)\")\n",
    "            else:\n",
    "                # Compare\n",
    "                local_dt = local_time\n",
    "                dropbox_dt = datetime.strptime(dropbox_time.split('.')[0], '%Y-%m-%d %H:%M:%S')\n",
    "                \n",
    "                diff_seconds = (local_dt - dropbox_dt).total_seconds()\n",
    "                if abs(diff_seconds) < 2:\n",
    "                    status = \"✓ SAME\"\n",
    "                elif diff_seconds > 0:\n",
    "                    status = f\"⚠️ LOCAL NEWER by {diff_seconds:.0f}s\"\n",
    "                else:\n",
    "                    status = f\"⚠️ DROPBOX NEWER by {-diff_seconds:.0f}s\"\n",
    "                \n",
    "                print(f\"  {status}: {fname}\")\n",
    "                print(f\"      Local:   {local_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "                print(f\"      Dropbox: {dropbox_time}\")\n",
    "\n",
    "compare_with_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a83c7530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOG: rclone_sync_27a-2G_live_trading_2026-01-09_105908.log\n",
      "================================================================================\n",
      "2026/01/09 10:59:15 INFO  : weekly_rankings/weekly_rankings_signal_20251217.csv: Moved (server-side)\n",
      "2026/01/09 10:59:15 INFO  : weekly_rankings/weekly_rankings_signal_20251217.csv: Moved into backup dir\n",
      "2026/01/09 10:59:16 INFO  : weekly_trades/weekly_trades_signal_20251231.csv: Moved (server-side)\n",
      "2026/01/09 10:59:16 INFO  : weekly_trades/weekly_trades_signal_20251231.csv: Moved into backup dir\n",
      "2026/01/09 10:59:18 INFO  : weekly_rankings/weekly_rankings_signal_20251224.csv: Moved (server-side)\n",
      "2026/01/09 10:59:18 INFO  : weekly_rankings/weekly_rankings_signal_20251224.csv: Moved into backup dir\n",
      "2026/01/09 10:59:19 INFO  : weekly_rankings/weekly_rankings_signal_20251231.csv: Moved (server-side)\n",
      "2026/01/09 10:59:19 INFO  : weekly_rankings/weekly_rankings_signal_20251231.csv: Moved into backup dir\n",
      "2026/01/09 10:59:20 INFO  : weekly_trades/weekly_trades_signal_20251224.csv: Moved (server-side)\n",
      "2026/01/09 10:59:20 INFO  : weekly_trades/weekly_trades_signal_20251224.csv: Moved into backup dir\n",
      "2026/01/09 10:59:21 INFO  : weekly_trades/weekly_trades_signal_20251217.csv: Moved (server-side)\n",
      "2026/01/09 10:59:21 INFO  : weekly_trades/weekly_trades_signal_20251217.csv: Moved into backup dir\n",
      "2026/01/09 10:59:21 INFO  : There was nothing to transfer\n",
      "2026/01/09 10:59:21 INFO  : \n",
      "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Checks:                20 / 20, 100%, Listed 26\n",
      "Deleted:                6 (files), 0 (dirs), 20.639 KiB (freed)\n",
      "Renamed:                6\n",
      "Server Side Moves:      6 @ 20.639 KiB\n",
      "Elapsed time:         9.1s\n",
      "\n",
      "2026/01/09 10:59:21 INFO  : Dropbox root 'MomentumSystem/latest/27a-2G_live_trading': Committing uploads - please wait...\n",
      "2026/01/09 10:59:21 INFO  : Dropbox root 'MomentumSystem/_changes/2026-01-09_105908/27a-2G_live_trading': Committing uploads - please wait...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LOG: rclone_sync_27a-2G_live_trading_2026-01-09_103859.log\n",
      "================================================================================\n",
      "2026/01/09 10:39:17 INFO  : reconciliation_log.csv: Moved (server-side)\n",
      "2026/01/09 10:39:17 INFO  : master_rankings.csv: Moved (server-side)\n",
      "2026/01/09 10:39:18 INFO  : executed_trades.csv: Moved (server-side)\n",
      "2026/01/09 10:39:19 INFO  : weekly_rankings/weekly_rankings_signal_20260107.csv: Copied (new)\n",
      "2026/01/09 10:39:20 INFO  : master_trades.csv: Moved (server-side)\n",
      "2026/01/09 10:39:20 INFO  : weekly_trades/weekly_trades_signal_20260107.csv: Copied (new)\n",
      "2026/01/09 10:39:20 INFO  : reconciliation_log.csv: Copied (new)\n",
      "2026/01/09 10:39:20 INFO  : master_rankings.csv: Copied (new)\n",
      "2026/01/09 10:39:21 INFO  : broker_fills_manual.csv: Moved (server-side)\n",
      "2026/01/09 10:39:22 INFO  : executed_trades.csv: Copied (new)\n",
      "2026/01/09 10:39:22 INFO  : live_portfolio.csv: Moved (server-side)\n",
      "2026/01/09 10:39:23 INFO  : master_trades.csv: Copied (new)\n",
      "2026/01/09 10:39:24 INFO  : broker_fills_manual.csv: Copied (new)\n",
      "2026/01/09 10:39:25 INFO  : live_portfolio.csv: Copied (new)\n",
      "2026/01/09 10:39:25 INFO  : \n",
      "Transferred:   \t   17.614 KiB / 17.614 KiB, 100%, 1.761 KiB/s, ETA 0s\n",
      "Checks:                18 / 18, 100%, Listed 30\n",
      "Renamed:                6\n",
      "Transferred:            8 / 8, 100%\n",
      "Server Side Moves:      6 @ 24.905 KiB\n",
      "Elapsed time:        10.1s\n",
      "\n",
      "2026/01/09 10:39:25 INFO  : Dropbox root 'MomentumSystem/latest/27a-2G_live_trading': Committing uploads - please wait...\n",
      "2026/01/09 10:39:25 INFO  : Dropbox root 'MomentumSystem/_changes/2026-01-09_103859/27a-2G_live_trading': Committing uploads - please wait...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LOG: rclone_sync_27a-2G_live_trading_2026-01-05_122600.log\n",
      "================================================================================\n",
      "2026/01/05 12:26:15 INFO  : There was nothing to transfer\n",
      "2026/01/05 12:26:15 INFO  : \n",
      "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
      "Checks:                12 / 12, 100%, Listed 28\n",
      "Elapsed time:         0.6s\n",
      "\n",
      "2026/01/05 12:26:15 INFO  : Dropbox root 'MomentumSystem/latest/27a-2G_live_trading': Committing uploads - please wait...\n",
      "2026/01/05 12:26:15 INFO  : Dropbox root 'MomentumSystem/_changes/2026-01-05_122600/27a-2G_live_trading': Committing uploads - please wait...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the most recent sync logs\n",
    "import glob\n",
    "\n",
    "log_files = sorted(glob.glob(str(LOG_DIR / \"rclone_sync_*.log\")), reverse=True)[:3]\n",
    "\n",
    "for log_file in log_files:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"LOG: {Path(log_file).name}\")\n",
    "    print('='*80)\n",
    "    with open(log_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        # Show just the summary or key lines\n",
    "        if content.strip():\n",
    "            print(content)\n",
    "        else:\n",
    "            print(\"(empty log)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95dca56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FOLDER: 13-match_trade_generator_output_regression_insp500_spyfilter_cap15\n",
      "================================================================================\n",
      "\n",
      "LOCAL FILES:\n",
      "  2026-01-08 19:05:35 - 13-all_planned_trades.csv\n",
      "  2026-01-08 19:05:35 - 13-match_equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:35 - 13-match_trades_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:35 - 13-match_weekly_rankings_pre_filter_cap15.parquet\n",
      "  2026-01-08 19:05:35 - planned_trades_LATEST.csv\n",
      "\n",
      "DROPBOX FILES:\n",
      "  492 2026-01-08 19:05:36.000000000 13-all_planned_trades.csv\n",
      "       3039 2026-01-08 19:05:36.000000000 13-match_equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "      10790 2026-01-08 19:05:36.000000000 13-match_trades_regression_insp500_spyfilter_cap15.parquet\n",
      "      12525 2026-01-08 19:05:36.000000000 13-match_weekly_rankings_pre_filter_cap15.parquet\n",
      "        492 2026-01-08 19:05:36.000000000 planned_trades_LATEST.csv\n",
      "\n",
      "================================================================================\n",
      "FOLDER: 13-trading_output_regression_insp500_spyfilter_cap15\n",
      "================================================================================\n",
      "\n",
      "LOCAL FILES:\n",
      "  2026-01-08 19:05:59 - 13-equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:59 - 13-trades_regression_insp500_spyfilter_cap15.parquet\n",
      "  2026-01-08 19:05:59 - 13-weekly_rankings_pre_filter_cap15.parquet\n",
      "  2026-01-06 10:23:26 - equity_curve_with_cash_returns.csv\n",
      "\n",
      "DROPBOX FILES:\n",
      "  136839 2026-01-08 19:06:00.000000000 13-equity_curve_regression_insp500_spyfilter_cap15.parquet\n",
      "     262458 2026-01-08 19:06:00.000000000 13-trades_regression_insp500_spyfilter_cap15.parquet\n",
      "    2757721 2026-01-08 19:06:00.000000000 13-weekly_rankings_pre_filter_cap15.parquet\n",
      "    1005390 2026-01-06 10:23:26.000000000 equity_curve_with_cash_returns.csv\n",
      "\n",
      "================================================================================\n",
      "FOLDER: 27a-2G_live_trading\n",
      "================================================================================\n",
      "\n",
      "LOCAL FILES:\n",
      "  2026-01-09 09:38:40 - broker_fills_manual.csv\n",
      "  2026-01-09 09:44:13 - executed_trades.csv\n",
      "  2026-01-09 09:44:13 - live_portfolio.csv\n",
      "  2026-01-09 09:40:58 - master_rankings.csv\n",
      "  2026-01-09 09:40:58 - master_trades.csv\n",
      "  2026-01-09 09:44:13 - reconciliation_log.csv\n",
      "  2026-01-09 09:40:58 - weekly_rankings\\weekly_rankings_signal_20260107.csv\n",
      "  2026-01-09 09:40:58 - weekly_trades\\weekly_trades_signal_20260107.csv\n",
      "\n",
      "DROPBOX FILES:\n",
      "  618 2026-01-09 09:38:40.000000000 broker_fills_manual.csv\n",
      "       1239 2026-01-09 09:44:13.000000000 executed_trades.csv\n",
      "        267 2026-01-09 09:44:13.000000000 live_portfolio.csv\n",
      "       6339 2026-01-09 09:40:58.000000000 master_rankings.csv\n",
      "        998 2026-01-09 09:40:58.000000000 master_trades.csv\n",
      "       1239 2026-01-09 09:44:13.000000000 reconciliation_log.csv\n",
      "       6339 2026-01-09 09:40:58.000000000 weekly_rankings/weekly_rankings_signal_20260107.csv\n",
      "        998 2026-01-09 09:40:58.000000000 weekly_trades/weekly_trades_signal_20260107.csv\n"
     ]
    }
   ],
   "source": [
    "# Compare file timestamps: local _publish vs Dropbox\n",
    "def compare_timestamps():\n",
    "    for folder in SOURCE_FOLDERS:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"FOLDER: {folder}\")\n",
    "        print('='*80)\n",
    "        \n",
    "        local_dir = PUBLISH_ROOT / folder\n",
    "        \n",
    "        # List local files with timestamps\n",
    "        print(\"\\nLOCAL FILES:\")\n",
    "        for f in sorted(local_dir.rglob(\"*\")):\n",
    "            if f.is_file() and is_candidate_file(f):\n",
    "                mtime = datetime.fromtimestamp(f.stat().st_mtime)\n",
    "                rel = f.relative_to(local_dir)\n",
    "                print(f\"  {mtime.strftime('%Y-%m-%d %H:%M:%S')} - {rel}\")\n",
    "        \n",
    "        # List Dropbox files with timestamps\n",
    "        print(\"\\nDROPBOX FILES:\")\n",
    "        remote_path = f\"{REMOTE_LATEST}/{folder}\"\n",
    "        cmd = [RCLONE_EXE, \"lsl\", remote_path]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                if line.strip():\n",
    "                    print(f\"  {line}\")\n",
    "        else:\n",
    "            print(f\"  Error: {result.stderr}\")\n",
    "\n",
    "compare_timestamps()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_quant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
